{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b180a672",
   "metadata": {},
   "source": [
    "\n",
    "# LO2 with **Datalog** â€” Watchlist + Likes/Dislikes (No `film_genre/3`)\n",
    "\n",
    "This version **avoids** the `film_genre/3` and `director_fact/3` predicates inside Datalog\n",
    "(by **materializing** the boosts/penalties in Python and asserting them as facts).\n",
    "This sidesteps the `Predicate without definition: film_genre/3` error.\n",
    "\n",
    "**Datalog facts asserted:**\n",
    "- `watched_fact(U,N,Y)`\n",
    "- `candidateFor(U,N,Y)`\n",
    "- `onWatchlist(U,N,Y)`\n",
    "- `genreBoost(U,N,Y)`  (precomputed in Python)\n",
    "- `dirBoost(U,N,Y)`    (precomputed in Python)\n",
    "- `genrePenalty(U,N,Y)` (precomputed in Python)\n",
    "- `dirPenalty(U,N,Y)`   (precomputed in Python)\n",
    "\n",
    "**Rules:**\n",
    "```\n",
    "recommendedBase(U,N,Y) <= candidateFor(U,N,Y) & ~watched_fact(U,N,Y)\n",
    "recommended(U,N,Y)     <= recommendedBase(U,N,Y)\n",
    "watchBoost(U,N,Y)      <= recommendedBase(U,N,Y) & onWatchlist(U,N,Y)\n",
    "```\n",
    "Scoring is done in Python from the flags.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "717a89b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T20:17:52.584171Z",
     "start_time": "2025-09-06T20:17:52.249716Z"
    }
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "import ast, re\n",
    "from pathlib import Path\n",
    "\n",
    "# Auto-detect project root\n",
    "here = Path.cwd()\n",
    "candidate = here\n",
    "while candidate != candidate.parent and not (candidate / \"data\").exists():\n",
    "    candidate = candidate.parent\n",
    "project_root = candidate if (candidate / \"data\").exists() else Path(\"../logical\")\n",
    "print(\"Detected project_root:\", project_root.resolve())\n",
    "\n",
    "# Paths\n",
    "watched_path   = project_root / \"data\" / \"letterboxd_export\" / \"watched.csv\"\n",
    "watchlist_path = project_root / \"data\" / \"letterboxd_export\" / \"watchlist.csv\"\n",
    "candidates_path= project_root / \"data\" / \"kg\" / \"tmdb_rerank_with_embedding_results_movies_only.csv\"\n",
    "\n",
    "# enriched-merged uploaded in this session:\n",
    "enriched_uploaded = Path(\"/mnt/data/0bf2f757-dc8c-43d8-9f82-d2705737b4fe.csv\")\n",
    "enriched_local = project_root / \"data\" / \"enriched_merged.csv\"\n",
    "enriched_path = enriched_uploaded if enriched_uploaded.exists() else enriched_local\n",
    "print(\"Using enriched file:\", enriched_path)\n",
    "\n",
    "out_csv = project_root / \"data\" / \"kg\" / \"rerank_LO2_watchlist_likes_dislikes_NO_FILMGENRE.csv\"\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected project_root: /Users/tschaffel/PycharmProjects/letterboxd-KG\n",
      "Using enriched file: /Users/tschaffel/PycharmProjects/letterboxd-KG/data/enriched_merged.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "f19bc475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T20:17:54.214745Z",
     "start_time": "2025-09-06T20:17:54.135904Z"
    }
   },
   "source": [
    "\n",
    "# Load data\n",
    "watched_df = pd.read_csv(watched_path)\n",
    "watchlist_df = pd.read_csv(watchlist_path)\n",
    "recs_df = pd.read_csv(candidates_path)\n",
    "enriched_df = pd.read_csv(enriched_path)\n",
    "\n",
    "# Normalize column names\n",
    "for df in (watched_df, watchlist_df, recs_df, enriched_df):\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "def pick(colnames, options):\n",
    "    for o in options:\n",
    "        if o in colnames:\n",
    "            return o\n",
    "    return None\n",
    "\n",
    "# Columns\n",
    "watched_name_col = pick(watched_df.columns, [\"name\",\"film name\",\"title\"])\n",
    "watched_year_col = pick(watched_df.columns, [\"year\",\"release year\",\"release_year\"])\n",
    "watch_name_col   = pick(watchlist_df.columns, [\"name\",\"film name\",\"title\",\"candidate_title\",\"movie\",\"movie_title\",\"original_title\"])\n",
    "watch_year_col   = pick(watchlist_df.columns, [\"year\",\"release year\",\"release_year\",\"releaseyear\"])\n",
    "recs_name_col    = pick(recs_df.columns, [\"candidate_title\",\"name\",\"title\",\"movie_title\",\"original_title\"])\n",
    "recs_year_col    = pick(recs_df.columns, [\"year\",\"release_year\",\"candidate_year\",\"releaseyear\",\"year_x\",\"year_y\"])\n",
    "\n",
    "en_title_col = pick(enriched_df.columns, [\"title\",\"name\"])\n",
    "en_year_col  = pick(enriched_df.columns, [\"year\",\"release_year\"])\n",
    "en_rating_col= pick(enriched_df.columns, [\"rating\",\"myrating\",\"rating10\",\"rating_10\"])\n",
    "en_genres_col= pick(enriched_df.columns, [\"genres\",\"genre\",\"tmdb_genres\"])\n",
    "en_dir_col   = pick(enriched_df.columns, [\"director\",\"directors\",\"tmdb_directors\"])\n",
    "\n",
    "assert all([watched_name_col, watched_year_col, watch_name_col, watch_year_col, recs_name_col, recs_year_col, en_title_col, en_year_col, en_rating_col, en_genres_col, en_dir_col]), \"Missing required columns\"\n",
    "\n",
    "def norm_name(s): return s.astype(str).str.strip().str.lower()\n",
    "def norm_year(s): \n",
    "    return s.astype(str).str.extract(r\"(\\d{4})\", expand=False).fillna(s.astype(str).str.strip())\n",
    "\n",
    "for df_, ncol, ycol in [(watched_df, watched_name_col, watched_year_col),\n",
    "                        (watchlist_df, watch_name_col, watch_year_col),\n",
    "                        (recs_df, recs_name_col, recs_year_col),\n",
    "                        (enriched_df, en_title_col, en_year_col)]:\n",
    "    df_[\"name_norm\"] = norm_name(df_[ncol])\n",
    "    df_[\"year_str\"]  = norm_year(df_[ycol])\n",
    "\n",
    "# Parse lists\n",
    "def parse_list_of_colon_pairs(cell):\n",
    "    if pd.isna(cell): return []\n",
    "    txt = str(cell)\n",
    "    try:\n",
    "        lst = ast.literal_eval(txt)\n",
    "        out = []\n",
    "        for it in lst if isinstance(lst, list) else []:\n",
    "            if isinstance(it, str):\n",
    "                out.append(it.split(':',1)[0].strip())\n",
    "        return out\n",
    "    except Exception:\n",
    "        return re.findall(r\"'([^':]+):\", txt)\n",
    "\n",
    "enriched_df[\"genre_list\"] = enriched_df[en_genres_col].apply(parse_list_of_colon_pairs)\n",
    "enriched_df[\"director_list\"] = enriched_df[en_dir_col].apply(parse_list_of_colon_pairs)\n",
    "\n",
    "# Aggregate per (name_norm, year_str)\n",
    "def set_union(series_of_lists):\n",
    "    s = set()\n",
    "    for lst in series_of_lists:\n",
    "        if isinstance(lst, list):\n",
    "            s.update(lst)\n",
    "    return sorted(s)\n",
    "\n",
    "agg_meta = (enriched_df\n",
    "            .groupby([\"name_norm\",\"year_str\"], as_index=False)\n",
    "            .agg(genre_list=(\"genre_list\", set_union),\n",
    "                 director_list=(\"director_list\", set_union)))\n",
    "\n",
    "recs_df = recs_df.merge(agg_meta, on=[\"name_norm\",\"year_str\"], how=\"left\")\n",
    "\n",
    "watched_pairs   = set(zip(watched_df[\"name_norm\"], watched_df[\"year_str\"]))\n",
    "watchlist_pairs = set(zip(watchlist_df[\"name_norm\"], watchlist_df[\"year_str\"]))\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "29d1b4c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T20:18:16.562275Z",
     "start_time": "2025-09-06T20:18:16.546898Z"
    }
   },
   "source": [
    "\n",
    "# Compute likes & dislikes from ratings\n",
    "rated = enriched_df.dropna(subset=[en_rating_col]).copy()\n",
    "rmax = rated[en_rating_col].max()\n",
    "scale = 10.0 if rmax > 5 else 5.0\n",
    "like_threshold = 7.0 if scale == 10.0 else 3.5\n",
    "dislike_threshold = 3.0 if scale == 10.0 else 1.5\n",
    "min_count = 2\n",
    "\n",
    "genres_long = rated.explode(\"genre_list\").dropna(subset=[\"genre_list\"])\n",
    "dirs_long   = rated.explode(\"director_list\").dropna(subset=[\"director_list\"])\n",
    "\n",
    "g_stats = (genres_long.groupby(\"genre_list\")[en_rating_col]\n",
    "           .agg(['mean','count']).reset_index().rename(columns={'genre_list':'genre'}))\n",
    "d_stats = (dirs_long.groupby(\"director_list\")[en_rating_col]\n",
    "           .agg(['mean','count']).reset_index().rename(columns={'director_list':'director'}))\n",
    "\n",
    "liked_genres    = set(g_stats[(g_stats['mean']>=like_threshold)    & (g_stats['count']>=min_count)]['genre'])\n",
    "disliked_genres = set(g_stats[(g_stats['mean']<=dislike_threshold) & (g_stats['count']>=min_count)]['genre'])\n",
    "\n",
    "liked_dirs      = set(d_stats[(d_stats['mean']>=like_threshold)    & (d_stats['count']>=min_count)]['director'])\n",
    "disliked_dirs   = set(d_stats[(d_stats['mean']<=dislike_threshold) & (d_stats['count']>=min_count)]['director'])\n",
    "\n",
    "print(\"Scale:\", scale, \"| like_threshold:\", like_threshold, \"| dislike_threshold:\", dislike_threshold)\n",
    "print(\"liked genres (n):\", len(liked_genres), \"| disliked genres (n):\", len(disliked_genres))\n",
    "print(\"liked directors (n):\", len(liked_dirs), \"| disliked directors (n):\", len(disliked_dirs))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale: 5.0 | like_threshold: 3.5 | dislike_threshold: 1.5\n",
      "liked genres (n): 17 | disliked genres (n): 0\n",
      "liked directors (n): 40 | disliked directors (n): 0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "44d2ec68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T20:19:00.606586Z",
     "start_time": "2025-09-06T20:19:00.543549Z"
    }
   },
   "source": [
    "\n",
    "# Precompute boosts/penalties per candidate (name_norm, year_str)\n",
    "def has_any(lst, S): \n",
    "    return any(x in S for x in (lst or []))\n",
    "\n",
    "recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\n",
    "recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\n",
    "recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\n",
    "recs_df[\"director_penalty\"]= recs_df[\"director_list\"].apply(lambda lst: has_any(lst, disliked_dirs))\n",
    "\n",
    "# We'll assert these as facts in Datalog later.\n"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mhas_any\u001B[39m(lst, S): \n\u001B[32m      3\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28many\u001B[39m(x \u001B[38;5;129;01min\u001B[39;00m S \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m (lst \u001B[38;5;129;01mor\u001B[39;00m []))\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m recs_df[\u001B[33m\"\u001B[39m\u001B[33mgenre_boost\u001B[39m\u001B[33m\"\u001B[39m]     = recs_df[\u001B[33m\"\u001B[39m\u001B[33mgenre_list\u001B[39m\u001B[33m\"\u001B[39m].apply(\u001B[38;5;28;01mlambda\u001B[39;00m lst: has_any(lst, liked_genres))\n\u001B[32m      6\u001B[39m recs_df[\u001B[33m\"\u001B[39m\u001B[33mdirector_boost\u001B[39m\u001B[33m\"\u001B[39m]  = recs_df[\u001B[33m\"\u001B[39m\u001B[33mdirector_list\u001B[39m\u001B[33m\"\u001B[39m].apply(\u001B[38;5;28;01mlambda\u001B[39;00m lst: has_any(lst, liked_dirs))\n\u001B[32m      7\u001B[39m recs_df[\u001B[33m\"\u001B[39m\u001B[33mgenre_penalty\u001B[39m\u001B[33m\"\u001B[39m]   = recs_df[\u001B[33m\"\u001B[39m\u001B[33mgenre_list\u001B[39m\u001B[33m\"\u001B[39m].apply(\u001B[38;5;28;01mlambda\u001B[39;00m lst: has_any(lst, disliked_genres))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/series.py:4924\u001B[39m, in \u001B[36mSeries.apply\u001B[39m\u001B[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[39m\n\u001B[32m   4789\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mapply\u001B[39m(\n\u001B[32m   4790\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   4791\u001B[39m     func: AggFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m   4796\u001B[39m     **kwargs,\n\u001B[32m   4797\u001B[39m ) -> DataFrame | Series:\n\u001B[32m   4798\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   4799\u001B[39m \u001B[33;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[32m   4800\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   4915\u001B[39m \u001B[33;03m    dtype: float64\u001B[39;00m\n\u001B[32m   4916\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m   4917\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m SeriesApply(\n\u001B[32m   4918\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   4919\u001B[39m         func,\n\u001B[32m   4920\u001B[39m         convert_dtype=convert_dtype,\n\u001B[32m   4921\u001B[39m         by_row=by_row,\n\u001B[32m   4922\u001B[39m         args=args,\n\u001B[32m   4923\u001B[39m         kwargs=kwargs,\n\u001B[32m-> \u001B[39m\u001B[32m4924\u001B[39m     ).apply()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001B[39m, in \u001B[36mSeriesApply.apply\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1424\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_compat()\n\u001B[32m   1426\u001B[39m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1427\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_standard()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001B[39m, in \u001B[36mSeriesApply.apply_standard\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1501\u001B[39m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[32m   1502\u001B[39m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[32m   1503\u001B[39m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[32m   1504\u001B[39m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[32m   1505\u001B[39m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[32m   1506\u001B[39m action = \u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj.dtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1507\u001B[39m mapped = obj._map_values(\n\u001B[32m   1508\u001B[39m     mapper=curried, na_action=action, convert=\u001B[38;5;28mself\u001B[39m.convert_dtype\n\u001B[32m   1509\u001B[39m )\n\u001B[32m   1511\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[32m0\u001B[39m], ABCSeries):\n\u001B[32m   1512\u001B[39m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[32m   1513\u001B[39m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[32m   1514\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj._constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index=obj.index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/base.py:921\u001B[39m, in \u001B[36mIndexOpsMixin._map_values\u001B[39m\u001B[34m(self, mapper, na_action, convert)\u001B[39m\n\u001B[32m    918\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[32m    919\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m arr.map(mapper, na_action=na_action)\n\u001B[32m--> \u001B[39m\u001B[32m921\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001B[39m, in \u001B[36mmap_array\u001B[39m\u001B[34m(arr, mapper, na_action, convert)\u001B[39m\n\u001B[32m   1741\u001B[39m values = arr.astype(\u001B[38;5;28mobject\u001B[39m, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1742\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1743\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m lib.map_infer(values, mapper, convert=convert)\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1745\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m lib.map_infer_mask(\n\u001B[32m   1746\u001B[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001B[32m   1747\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mlib.pyx:2972\u001B[39m, in \u001B[36mpandas._libs.lib.map_infer\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 5\u001B[39m, in \u001B[36m<lambda>\u001B[39m\u001B[34m(lst)\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mhas_any\u001B[39m(lst, S): \n\u001B[32m      3\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28many\u001B[39m(x \u001B[38;5;129;01min\u001B[39;00m S \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m (lst \u001B[38;5;129;01mor\u001B[39;00m []))\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m recs_df[\u001B[33m\"\u001B[39m\u001B[33mgenre_boost\u001B[39m\u001B[33m\"\u001B[39m]     = recs_df[\u001B[33m\"\u001B[39m\u001B[33mgenre_list\u001B[39m\u001B[33m\"\u001B[39m].apply(\u001B[38;5;28;01mlambda\u001B[39;00m lst: has_any(lst, liked_genres))\n\u001B[32m      6\u001B[39m recs_df[\u001B[33m\"\u001B[39m\u001B[33mdirector_boost\u001B[39m\u001B[33m\"\u001B[39m]  = recs_df[\u001B[33m\"\u001B[39m\u001B[33mdirector_list\u001B[39m\u001B[33m\"\u001B[39m].apply(\u001B[38;5;28;01mlambda\u001B[39;00m lst: has_any(lst, liked_dirs))\n\u001B[32m      7\u001B[39m recs_df[\u001B[33m\"\u001B[39m\u001B[33mgenre_penalty\u001B[39m\u001B[33m\"\u001B[39m]   = recs_df[\u001B[33m\"\u001B[39m\u001B[33mgenre_list\u001B[39m\u001B[33m\"\u001B[39m].apply(\u001B[38;5;28;01mlambda\u001B[39;00m lst: has_any(lst, disliked_genres))\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 3\u001B[39m, in \u001B[36mhas_any\u001B[39m\u001B[34m(lst, S)\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mhas_any\u001B[39m(lst, S): \n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28many\u001B[39m(x \u001B[38;5;129;01min\u001B[39;00m S \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m (lst \u001B[38;5;129;01mor\u001B[39;00m []))\n",
      "\u001B[31mTypeError\u001B[39m: 'float' object is not iterable"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "d18dc726",
   "metadata": {},
   "source": [
    "## Datalog: assert facts and apply core rules"
   ]
  },
  {
   "cell_type": "code",
   "id": "53b50f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T20:19:07.170029Z",
     "start_time": "2025-09-06T20:19:06.231318Z"
    }
   },
   "source": [
    "\n",
    "use_pyDatalog = False\n",
    "try:\n",
    "    from pyDatalog import pyDatalog\n",
    "    use_pyDatalog = True\n",
    "    print(\"pyDatalog is available â€” using it.\")\n",
    "except Exception as e:\n",
    "    print(\"pyDatalog not available, fallback will be used:\", e)\n",
    "\n",
    "USER = \"tobias\"\n",
    "\n",
    "if use_pyDatalog:\n",
    "    pyDatalog.clear()\n",
    "    pyDatalog.create_terms('watched_fact, candidateFor, onWatchlist, '\n",
    "                           'genreBoost, dirBoost, genrePenalty, dirPenalty, '\n",
    "                           'recommendedBase, recommended, watchBoost, U,N,Y')\n",
    "\n",
    "    for n,y in watched_pairs:   +watched_fact(USER,n,y)\n",
    "    for n,y in watchlist_pairs: +onWatchlist(USER,n,y)\n",
    "    for _,row in recs_df.iterrows():\n",
    "        +candidateFor(USER,row[\"name_norm\"],row[\"year_str\"])\n",
    "\n",
    "    # Assert boosts/penalties as *facts* (no inner predicates needed)\n",
    "    for _,row in recs_df[recs_df[\"genre_boost\"]==True].iterrows():\n",
    "        +genreBoost(USER,row[\"name_norm\"],row[\"year_str\"])\n",
    "    for _,row in recs_df[recs_df[\"director_boost\"]==True].iterrows():\n",
    "        +dirBoost(USER,row[\"name_norm\"],row[\"year_str\"])\n",
    "    for _,row in recs_df[recs_df[\"genre_penalty\"]==True].iterrows():\n",
    "        +genrePenalty(USER,row[\"name_norm\"],row[\"year_str\"])\n",
    "    for _,row in recs_df[recs_df[\"director_penalty\"]==True].iterrows():\n",
    "        +dirPenalty(USER,row[\"name_norm\"],row[\"year_str\"])\n",
    "\n",
    "    # Rules\n",
    "    recommendedBase(U,N,Y) <= candidateFor(U,N,Y) & ~watched_fact(U,N,Y)\n",
    "    recommended(U,N,Y)     <= recommendedBase(U,N,Y)\n",
    "    watchBoost(U,N,Y)      <= recommendedBase(U,N,Y) & onWatchlist(U,N,Y)\n",
    "\n",
    "    def qset(s): \n",
    "        ans = pyDatalog.ask(s); \n",
    "        return set(tuple(x) for x in (ans.answers if ans else []))\n",
    "\n",
    "    all_pairs   = qset(f'recommended(\"{USER}\", N, Y)')\n",
    "    watch_pairs = qset(f'watchBoost(\"{USER}\", N, Y)')\n",
    "    g_like      = qset(f'genreBoost(\"{USER}\", N, Y)')\n",
    "    d_like      = qset(f'dirBoost(\"{USER}\", N, Y)')\n",
    "    g_bad       = qset(f'genrePenalty(\"{USER}\", N, Y)')\n",
    "    d_bad       = qset(f'dirPenalty(\"{USER}\", N, Y)')\n",
    "\n",
    "    if all_pairs:\n",
    "        rec_df = pd.DataFrame(list(all_pairs), columns=[\"name_norm\",\"year_str\"])\n",
    "        out = recs_df.merge(rec_df, on=[\"name_norm\",\"year_str\"], how=\"inner\")\n",
    "    else:\n",
    "        out = recs_df.iloc[0:0].copy()\n",
    "\n",
    "    def flag(df, S, col):\n",
    "        df[col] = list(map(lambda p: p in S, zip(df[\"name_norm\"], df[\"year_str\"])))\n",
    "    flag(out, watch_pairs, \"watchlist_priority\")\n",
    "    flag(out, g_like, \"genre_boost\")\n",
    "    flag(out, d_like, \"director_boost\")\n",
    "    flag(out, g_bad,  \"genre_penalty\")\n",
    "    flag(out, d_bad,  \"director_penalty\")\n",
    "\n",
    "else:\n",
    "    # Pure pandas fallback\n",
    "    cand_pairs = list(zip(recs_df[\"name_norm\"], recs_df[\"year_str\"]))\n",
    "    keep_mask = [pair not in watched_pairs for pair in cand_pairs]\n",
    "    out = recs_df.loc[keep_mask].copy()\n",
    "    out[\"watchlist_priority\"] = list(map(lambda p: p in watchlist_pairs, zip(out[\"name_norm\"], out[\"year_str\"])))\n",
    "    out[\"genre_boost\"] = recs_df[\"genre_boost\"]\n",
    "    out[\"director_boost\"] = recs_df[\"director_boost\"]\n",
    "    out[\"genre_penalty\"] = recs_df[\"genre_penalty\"]\n",
    "    out[\"director_penalty\"] = recs_df[\"director_penalty\"]\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyDatalog is available â€” using it.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'genre_boost'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3804\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3805\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._engine.get_loc(casted_key)\n\u001B[32m   3806\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'genre_boost'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 23\u001B[39m\n\u001B[32m     20\u001B[39m     +candidateFor(USER,row[\u001B[33m\"\u001B[39m\u001B[33mname_norm\u001B[39m\u001B[33m\"\u001B[39m],row[\u001B[33m\"\u001B[39m\u001B[33myear_str\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# Assert boosts/penalties as *facts* (no inner predicates needed)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _,row \u001B[38;5;129;01min\u001B[39;00m recs_df[recs_df[\u001B[33m\"\u001B[39m\u001B[33mgenre_boost\u001B[39m\u001B[33m\"\u001B[39m]==\u001B[38;5;28;01mTrue\u001B[39;00m].iterrows():\n\u001B[32m     24\u001B[39m     +genreBoost(USER,row[\u001B[33m\"\u001B[39m\u001B[33mname_norm\u001B[39m\u001B[33m\"\u001B[39m],row[\u001B[33m\"\u001B[39m\u001B[33myear_str\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _,row \u001B[38;5;129;01min\u001B[39;00m recs_df[recs_df[\u001B[33m\"\u001B[39m\u001B[33mdirector_boost\u001B[39m\u001B[33m\"\u001B[39m]==\u001B[38;5;28;01mTrue\u001B[39;00m].iterrows():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4100\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4101\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4102\u001B[39m indexer = \u001B[38;5;28mself\u001B[39m.columns.get_loc(key)\n\u001B[32m   4103\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4104\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3807\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3808\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3809\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3810\u001B[39m     ):\n\u001B[32m   3811\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3814\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3815\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3816\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3817\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'genre_boost'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "91ea689f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T20:19:15.006930Z",
     "start_time": "2025-09-06T20:19:14.978978Z"
    }
   },
   "source": [
    "\n",
    "# Score and save\n",
    "w_watch, w_glike, w_dlike, w_gbad, w_dbad = 2, 1, 2, 1, 2\n",
    "out[\"score\"] = (out[\"watchlist_priority\"].astype(int)*w_watch +\n",
    "                out[\"genre_boost\"].astype(int)*w_glike +\n",
    "                out[\"director_boost\"].astype(int)*w_dlike -\n",
    "                out[\"genre_penalty\"].astype(int)*w_gbad -\n",
    "                out[\"director_penalty\"].astype(int)*w_dbad)\n",
    "\n",
    "sort_cols, ascending = [\"score\"], [False]\n",
    "if \"rank\" in out.columns: sort_cols.append(\"rank\"); ascending.append(True)\n",
    "\n",
    "out_sorted = out.sort_values(by=sort_cols, ascending=ascending).reset_index(drop=True)\n",
    "out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_sorted.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv.resolve())\n",
    "\n",
    "summary = {\n",
    "    \"candidates_total\": int(len(recs_df)),\n",
    "    \"recommended_total\": int(len(out_sorted)),\n",
    "    \"watchlist_priority_true\": int(out_sorted[\"watchlist_priority\"].sum()),\n",
    "    \"genre_boost_true\": int(out_sorted[\"genre_boost\"].sum()),\n",
    "    \"director_boost_true\": int(out_sorted[\"director_boost\"].sum()),\n",
    "    \"genre_penalty_true\": int(out_sorted[\"genre_penalty\"].sum()),\n",
    "    \"director_penalty_true\": int(out_sorted[\"director_penalty\"].sum()),\n",
    "}\n",
    "summary\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Score and save\u001B[39;00m\n\u001B[32m      2\u001B[39m w_watch, w_glike, w_dlike, w_gbad, w_dbad = \u001B[32m2\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m out[\u001B[33m\"\u001B[39m\u001B[33mscore\u001B[39m\u001B[33m\"\u001B[39m] = (out[\u001B[33m\"\u001B[39m\u001B[33mwatchlist_priority\u001B[39m\u001B[33m\"\u001B[39m].astype(\u001B[38;5;28mint\u001B[39m)*w_watch +\n\u001B[32m      4\u001B[39m                 out[\u001B[33m\"\u001B[39m\u001B[33mgenre_boost\u001B[39m\u001B[33m\"\u001B[39m].astype(\u001B[38;5;28mint\u001B[39m)*w_glike +\n\u001B[32m      5\u001B[39m                 out[\u001B[33m\"\u001B[39m\u001B[33mdirector_boost\u001B[39m\u001B[33m\"\u001B[39m].astype(\u001B[38;5;28mint\u001B[39m)*w_dlike -\n\u001B[32m      6\u001B[39m                 out[\u001B[33m\"\u001B[39m\u001B[33mgenre_penalty\u001B[39m\u001B[33m\"\u001B[39m].astype(\u001B[38;5;28mint\u001B[39m)*w_gbad -\n\u001B[32m      7\u001B[39m                 out[\u001B[33m\"\u001B[39m\u001B[33mdirector_penalty\u001B[39m\u001B[33m\"\u001B[39m].astype(\u001B[38;5;28mint\u001B[39m)*w_dbad)\n\u001B[32m      9\u001B[39m sort_cols, ascending = [\u001B[33m\"\u001B[39m\u001B[33mscore\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[38;5;28;01mFalse\u001B[39;00m]\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mrank\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m out.columns: sort_cols.append(\u001B[33m\"\u001B[39m\u001B[33mrank\u001B[39m\u001B[33m\"\u001B[39m); ascending.append(\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mNameError\u001B[39m: name 'out' is not defined"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
