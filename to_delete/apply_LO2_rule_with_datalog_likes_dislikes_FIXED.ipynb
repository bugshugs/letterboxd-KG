{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e184170",
   "metadata": {},
   "source": [
    "\n",
    "# LO2 with **Datalog** â€” Likes & Dislikes (Fixed list aggregation)\n",
    "\n",
    "This version fixes the error `TypeError: unhashable type: 'list'` by aggregating\n",
    "`genre_list` and `director_list` per `(name_norm, year_str)` using set-union,\n",
    "instead of calling `drop_duplicates()` on list-typed columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "0c879e22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T20:13:37.934493Z",
     "start_time": "2025-09-06T20:13:37.667426Z"
    }
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "import ast, re\n",
    "from pathlib import Path\n",
    "\n",
    "# Auto-detect project root\n",
    "here = Path.cwd()\n",
    "candidate = here\n",
    "while candidate != candidate.parent and not (candidate / \"data\").exists():\n",
    "    candidate = candidate.parent\n",
    "project_root = candidate if (candidate / \"data\").exists() else Path(\"../logical\")\n",
    "print(\"Detected project_root:\", project_root.resolve())\n",
    "\n",
    "# Paths\n",
    "watched_path   = project_root / \"data\" / \"letterboxd_export\" / \"watched.csv\"\n",
    "watchlist_path = project_root / \"data\" / \"letterboxd_export\" / \"watchlist.csv\"\n",
    "candidates_path= project_root / \"data\" / \"kg\" / \"tmdb_rerank_with_embedding_results_movies_only.csv\"\n",
    "\n",
    "# Uploaded enriched-merged.csv from chat session:\n",
    "enriched_uploaded = Path(\"/mnt/data/0bf2f757-dc8c-43d8-9f82-d2705737b4fe.csv\")\n",
    "enriched_local = project_root / \"data\" / \"enriched_merged.csv\"\n",
    "enriched_path = enriched_uploaded if enriched_uploaded.exists() else enriched_local\n",
    "print(\"Using enriched file:\", enriched_path)\n",
    "\n",
    "out_csv = project_root / \"data\" / \"kg\" / \"rerank_LO2_watchlist_genre_dir_likes_dislikes_FIXED.csv\"\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected project_root: /Users/tschaffel/PycharmProjects/letterboxd-KG\n",
      "Using enriched file: /Users/tschaffel/PycharmProjects/letterboxd-KG/data/enriched_merged.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "7d186662",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T20:13:39.716282Z",
     "start_time": "2025-09-06T20:13:39.622296Z"
    }
   },
   "source": [
    "\n",
    "# Load data\n",
    "watched_df = pd.read_csv(watched_path)\n",
    "watchlist_df = pd.read_csv(watchlist_path)\n",
    "recs_df = pd.read_csv(candidates_path)\n",
    "enriched_df = pd.read_csv(enriched_path)\n",
    "\n",
    "# Normalize columns\n",
    "for df in (watched_df, watchlist_df, recs_df, enriched_df):\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "def pick(colnames, options):\n",
    "    for o in options:\n",
    "        if o in colnames:\n",
    "            return o\n",
    "    return None\n",
    "\n",
    "watched_name_col = pick(watched_df.columns, [\"name\",\"film name\",\"title\"])\n",
    "watched_year_col = pick(watched_df.columns, [\"year\",\"release year\",\"release_year\"])\n",
    "\n",
    "watch_name_col = pick(watchlist_df.columns, [\"name\",\"film name\",\"title\",\"candidate_title\",\"movie\",\"movie_title\",\"original_title\"])\n",
    "watch_year_col = pick(watchlist_df.columns, [\"year\",\"release year\",\"release_year\",\"releaseyear\"])\n",
    "\n",
    "recs_name_col = pick(recs_df.columns, [\"candidate_title\",\"name\",\"title\",\"movie_title\",\"original_title\"])\n",
    "recs_year_col = pick(recs_df.columns, [\"year\",\"release_year\",\"candidate_year\",\"releaseyear\",\"year_x\",\"year_y\"])\n",
    "\n",
    "en_title_col = pick(enriched_df.columns, [\"title\",\"name\"])\n",
    "en_year_col  = pick(enriched_df.columns, [\"year\",\"release_year\"])\n",
    "en_rating_col= pick(enriched_df.columns, [\"rating\",\"myrating\",\"rating10\",\"rating_10\"])\n",
    "en_genres_col= pick(enriched_df.columns, [\"genres\",\"genre\",\"tmdb_genres\"])\n",
    "en_dir_col   = pick(enriched_df.columns, [\"director\",\"directors\",\"tmdb_directors\"])\n",
    "\n",
    "assert watched_name_col and watched_year_col\n",
    "assert watch_name_col and watch_year_col\n",
    "assert recs_name_col and recs_year_col\n",
    "assert en_title_col and en_year_col and en_rating_col and en_genres_col and en_dir_col\n",
    "\n",
    "def norm_name(s): return s.astype(str).str.strip().str.lower()\n",
    "def norm_year(s): \n",
    "    return s.astype(str).str.extract(r\"(\\d{4})\", expand=False).fillna(s.astype(str).str.strip())\n",
    "\n",
    "for df_, ncol, ycol in [(watched_df, watched_name_col, watched_year_col),\n",
    "                        (watchlist_df, watch_name_col, watch_year_col),\n",
    "                        (recs_df, recs_name_col, recs_year_col),\n",
    "                        (enriched_df, en_title_col, en_year_col)]:\n",
    "    df_[\"name_norm\"] = norm_name(df_[ncol])\n",
    "    df_[\"year_str\"]  = norm_year(df_[ycol])\n",
    "\n",
    "# Parse list-like genre/director columns into Python lists of names\n",
    "def parse_list_of_colon_pairs(cell):\n",
    "    if pd.isna(cell): return []\n",
    "    txt = str(cell)\n",
    "    try:\n",
    "        lst = ast.literal_eval(txt)\n",
    "        out = []\n",
    "        for it in lst if isinstance(lst, list) else []:\n",
    "            if isinstance(it, str):\n",
    "                out.append(it.split(':',1)[0].strip())\n",
    "        return out\n",
    "    except Exception:\n",
    "        return re.findall(r\"'([^':]+):\", txt)\n",
    "\n",
    "enriched_df[\"genre_list\"] = enriched_df[en_genres_col].apply(parse_list_of_colon_pairs)\n",
    "enriched_df[\"director_list\"] = enriched_df[en_dir_col].apply(parse_list_of_colon_pairs)\n",
    "\n",
    "# Aggregate per (name_norm, year_str) with set-union to avoid unhashable lists\n",
    "def set_union(series_of_lists):\n",
    "    s = set()\n",
    "    for lst in series_of_lists:\n",
    "        if isinstance(lst, list):\n",
    "            s.update(lst)\n",
    "    return sorted(s)\n",
    "\n",
    "agg_meta = (enriched_df\n",
    "            .groupby([\"name_norm\",\"year_str\"], as_index=False)\n",
    "            .agg(genre_list=(\"genre_list\", set_union),\n",
    "                 director_list=(\"director_list\", set_union)))\n",
    "\n",
    "# Merge aggregated metadata into candidates\n",
    "recs_df = recs_df.merge(agg_meta, on=[\"name_norm\",\"year_str\"], how=\"left\")\n",
    "\n",
    "watched_pairs   = set(zip(watched_df[\"name_norm\"], watched_df[\"year_str\"]))\n",
    "watchlist_pairs = set(zip(watchlist_df[\"name_norm\"], watchlist_df[\"year_str\"]))\n",
    "\n",
    "print(\"Watched pairs:\", len(watched_pairs))\n",
    "print(\"Watchlist pairs:\", len(watchlist_pairs))\n",
    "print(\"Candidates:\", len(recs_df))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watched pairs: 754\n",
      "Watchlist pairs: 732\n",
      "Candidates: 100\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "3a64a292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T20:13:43.420872Z",
     "start_time": "2025-09-06T20:13:43.404456Z"
    }
   },
   "source": [
    "\n",
    "# Compute likes & dislikes from ratings\n",
    "rated = enriched_df.dropna(subset=[en_rating_col]).copy()\n",
    "rmax = rated[en_rating_col].max()\n",
    "scale = 10.0 if rmax > 5 else 5.0\n",
    "like_threshold = 7.0 if scale == 10.0 else 3.5\n",
    "dislike_threshold = 3.0 if scale == 10.0 else 1.5\n",
    "min_count = 2\n",
    "\n",
    "genres_long = rated.explode(\"genre_list\").dropna(subset=[\"genre_list\"])\n",
    "dirs_long   = rated.explode(\"director_list\").dropna(subset=[\"director_list\"])\n",
    "\n",
    "g_stats = (genres_long.groupby(\"genre_list\")[en_rating_col]\n",
    "           .agg(['mean','count']).reset_index().rename(columns={'genre_list':'genre'}))\n",
    "d_stats = (dirs_long.groupby(\"director_list\")[en_rating_col]\n",
    "           .agg(['mean','count']).reset_index().rename(columns={'director_list':'director'}))\n",
    "\n",
    "liked_genres    = set(g_stats[(g_stats['mean']>=like_threshold)    & (g_stats['count']>=min_count)]['genre'])\n",
    "disliked_genres = set(g_stats[(g_stats['mean']<=dislike_threshold) & (g_stats['count']>=min_count)]['genre'])\n",
    "\n",
    "liked_dirs      = set(d_stats[(d_stats['mean']>=like_threshold)    & (d_stats['count']>=min_count)]['director'])\n",
    "disliked_dirs   = set(d_stats[(d_stats['mean']<=dislike_threshold) & (d_stats['count']>=min_count)]['director'])\n",
    "\n",
    "print(\"Scale:\", scale, \"| like_threshold:\", like_threshold, \"| dislike_threshold:\", dislike_threshold)\n",
    "print(\"Liked genres (n):\", len(liked_genres), \"| Disliked genres (n):\", len(disliked_genres))\n",
    "print(\"Liked directors (n):\", len(liked_dirs), \"| Disliked directors (n):\", len(disliked_dirs))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale: 5.0 | like_threshold: 3.5 | dislike_threshold: 1.5\n",
      "Liked genres (n): 17 | Disliked genres (n): 0\n",
      "Liked directors (n): 40 | Disliked directors (n): 0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "e7a217b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T20:14:21.301908Z",
     "start_time": "2025-09-06T20:14:21.180896Z"
    }
   },
   "source": [
    "\n",
    "# Apply rules (pyDatalog if available, else fallback)\n",
    "use_pyDatalog = False\n",
    "try:\n",
    "    from pyDatalog import pyDatalog\n",
    "    use_pyDatalog = True\n",
    "    print(\"pyDatalog is available â€” using it.\")\n",
    "except Exception as e:\n",
    "    print(\"pyDatalog not available, fallback:\", e)\n",
    "\n",
    "USER = \"tobias\"\n",
    "\n",
    "if use_pyDatalog:\n",
    "    pyDatalog.clear()\n",
    "    pyDatalog.create_terms('watched_fact, candidateFor, onWatchlist, film_genre, director_fact, '\n",
    "                           'likesGenreFact, likesDirectorFact, dislikesGenreFact, dislikesDirectorFact, '\n",
    "                           'recommendedBase, watchBoost, genreBoost, dirBoost, '\n",
    "                           'genrePenalty, dirPenalty, recommended, U,N,Y,G,D')\n",
    "\n",
    "    for n,y in watched_pairs:    +watched_fact(USER,n,y)\n",
    "    for n,y in watchlist_pairs:  +onWatchlist(USER,n,y)\n",
    "    for _,row in recs_df.iterrows():\n",
    "        +candidateFor(USER,row[\"name_norm\"],row[\"year_str\"])\n",
    "\n",
    "    for _,row in recs_df.dropna(subset=[\"genre_list\"]).iterrows():\n",
    "        for g in row[\"genre_list\"]: +film_genre(row[\"name_norm\"], row[\"year_str\"], g)\n",
    "    for _,row in recs_df.dropna(subset=[\"director_list\"]).iterrows():\n",
    "        for d in row[\"director_list\"]: +director_fact(row[\"name_norm\"], row[\"year_str\"], d)\n",
    "\n",
    "    for g in liked_genres:       +likesGenreFact(USER,g)\n",
    "    for d in liked_dirs:         +likesDirectorFact(USER,d)\n",
    "    for g in disliked_genres:    +dislikesGenreFact(USER,g)\n",
    "    for d in disliked_dirs:      +dislikesDirectorFact(USER,d)\n",
    "\n",
    "    recommendedBase(U,N,Y) <= candidateFor(U,N,Y) & ~watched_fact(U,N,Y)\n",
    "    watchBoost(U,N,Y)      <= recommendedBase(U,N,Y) & onWatchlist(U,N,Y)\n",
    "    genreBoost(U,N,Y)      <= recommendedBase(U,N,Y) & film_genre(N,Y,G) & likesGenreFact(U,G)\n",
    "    dirBoost(U,N,Y)        <= recommendedBase(U,N,Y) & director_fact(N,Y,D) & likesDirectorFact(U,D)\n",
    "    genrePenalty(U,N,Y)    <= recommendedBase(U,N,Y) & film_genre(N,Y,G) & dislikesGenreFact(U,G)\n",
    "    dirPenalty(U,N,Y)      <= recommendedBase(U,N,Y) & director_fact(N,Y,D) & dislikesDirectorFact(U,D)\n",
    "    recommended(U,N,Y)     <= recommendedBase(U,N,Y)\n",
    "\n",
    "    def qset(s): \n",
    "        ans = pyDatalog.ask(s); \n",
    "        return set(tuple(x) for x in (ans.answers if ans else []))\n",
    "\n",
    "    all_pairs   = qset(f'recommended(\"{USER}\", N, Y)')\n",
    "    watch_pairs = qset(f'watchBoost(\"{USER}\", N, Y)')\n",
    "    g_like      = qset(f'genreBoost(\"{USER}\", N, Y)')\n",
    "    d_like      = qset(f'dirBoost(\"{USER}\", N, Y)')\n",
    "    g_bad       = qset(f'genrePenalty(\"{USER}\", N, Y)')\n",
    "    d_bad       = qset(f'dirPenalty(\"{USER}\", N, Y)')\n",
    "\n",
    "    if all_pairs:\n",
    "        rec_df = pd.DataFrame(list(all_pairs), columns=[\"name_norm\",\"year_str\"])\n",
    "        out = recs_df.merge(rec_df, on=[\"name_norm\",\"year_str\"], how=\"inner\")\n",
    "    else:\n",
    "        out = recs_df.iloc[0:0].copy()\n",
    "\n",
    "    def flag(df, S, col):\n",
    "        df[col] = list(map(lambda p: p in S, zip(df[\"name_norm\"], df[\"year_str\"])))\n",
    "    flag(out, watch_pairs, \"watchlist_priority\")\n",
    "    flag(out, g_like, \"genre_boost\")\n",
    "    flag(out, d_like, \"director_boost\")\n",
    "    flag(out, g_bad,  \"genre_penalty\")\n",
    "    flag(out, d_bad,  \"director_penalty\")\n",
    "\n",
    "else:\n",
    "    # Fallback\n",
    "    cand_pairs = list(zip(recs_df[\"name_norm\"], recs_df[\"year_str\"]))\n",
    "    keep_mask = [pair not in watched_pairs for pair in cand_pairs]\n",
    "    out = recs_df.loc[keep_mask].copy()\n",
    "    out[\"watchlist_priority\"] = list(map(lambda p: p in watchlist_pairs, zip(out[\"name_norm\"], out[\"year_str\"])))\n",
    "\n",
    "    def any_in(small, big): return any(x in small for x in (big or []))\n",
    "\n",
    "    out[\"genre_boost\"]     = out[\"genre_list\"].apply(lambda lst: any_in(liked_genres, lst))\n",
    "    out[\"director_boost\"]  = out[\"director_list\"].apply(lambda lst: any_in(liked_dirs, lst))\n",
    "    out[\"genre_penalty\"]   = out[\"genre_list\"].apply(lambda lst: any_in(disliked_genres, lst))\n",
    "    out[\"director_penalty\"]= out[\"director_list\"].apply(lambda lst: any_in(disliked_dirs, lst))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyDatalog is available â€” using it.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Predicate without definition (or error in resolver): film_genre/3",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 48\u001B[39m\n\u001B[32m     46\u001B[39m all_pairs   = qset(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mrecommended(\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mUSER\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\u001B[33m, N, Y)\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     47\u001B[39m watch_pairs = qset(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mwatchBoost(\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mUSER\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\u001B[33m, N, Y)\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m g_like      = qset(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mgenreBoost(\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mUSER\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\u001B[33m, N, Y)\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     49\u001B[39m d_like      = qset(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mdirBoost(\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mUSER\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\u001B[33m, N, Y)\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     50\u001B[39m g_bad       = qset(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mgenrePenalty(\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mUSER\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\u001B[33m, N, Y)\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 43\u001B[39m, in \u001B[36mqset\u001B[39m\u001B[34m(s)\u001B[39m\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mqset\u001B[39m(s): \n\u001B[32m---> \u001B[39m\u001B[32m43\u001B[39m     ans = pyDatalog.ask(s); \n\u001B[32m     44\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mset\u001B[39m(\u001B[38;5;28mtuple\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m (ans.answers \u001B[38;5;28;01mif\u001B[39;00m ans \u001B[38;5;28;01melse\u001B[39;00m []))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyDatalog.py:111\u001B[39m, in \u001B[36mask\u001B[39m\u001B[34m(code)\u001B[39m\n\u001B[32m    109\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mask\u001B[39m(code):\n\u001B[32m    110\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"returns the result of the query contained in the code string\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m111\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m pyParser.ask(code)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:841\u001B[39m, in \u001B[36mask\u001B[39m\u001B[34m(code)\u001B[39m\n\u001B[32m    839\u001B[39m add_symbols(code.co_names, newglobals)\n\u001B[32m    840\u001B[39m parsed_code = \u001B[38;5;28meval\u001B[39m(code, newglobals)\n\u001B[32m--> \u001B[39m\u001B[32m841\u001B[39m a = parsed_code.ask()\n\u001B[32m    842\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m Answer.make(a)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:577\u001B[39m, in \u001B[36mQuery.ask\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    576\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mask\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m577\u001B[39m     \u001B[38;5;28mself\u001B[39m._data = Body(\u001B[38;5;28mself\u001B[39m.pre_calculations, \u001B[38;5;28mself\u001B[39m).ask()\n\u001B[32m    578\u001B[39m     \u001B[38;5;28mself\u001B[39m.todo = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    579\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._data\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:693\u001B[39m, in \u001B[36mBody.ask\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    691\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\" resolve the query and determine the values of its variables\"\"\"\u001B[39;00m\n\u001B[32m    692\u001B[39m literal = \u001B[38;5;28mself\u001B[39m.literal()\n\u001B[32m--> \u001B[39m\u001B[32m693\u001B[39m \u001B[38;5;28mself\u001B[39m._data = literal.lua.ask()\n\u001B[32m    694\u001B[39m literal.todo, \u001B[38;5;28mself\u001B[39m.todo = \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    695\u001B[39m - (literal <= \u001B[38;5;28mself\u001B[39m) \u001B[38;5;66;03m# delete the temporary clause\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:513\u001B[39m, in \u001B[36mLiteral.ask\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    511\u001B[39m todo, arg = (SEARCH, (Ts.Goal, ))\n\u001B[32m    512\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m todo:\n\u001B[32m--> \u001B[39m\u001B[32m513\u001B[39m     todo, arg = todo(*arg)\n\u001B[32m    515\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m Ts.Goal.facts \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m    516\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:812\u001B[39m, in \u001B[36mSubgoal.search\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    808\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m util.DatalogError(\u001B[33m\"\u001B[39m\u001B[33mError: right hand side of comparison must be bound: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m \n\u001B[32m    809\u001B[39m                             % literal.pred.id, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    810\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.next_step()\n\u001B[32m--> \u001B[39m\u001B[32m812\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mPredicate without definition (or error in resolver): \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m % literal.pred.id)\n",
      "\u001B[31mAttributeError\u001B[39m: Predicate without definition (or error in resolver): film_genre/3"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "b3cac889",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T20:14:06.810757Z",
     "start_time": "2025-09-06T20:14:06.786147Z"
    }
   },
   "source": [
    "\n",
    "# Scoring and save\n",
    "w_watch, w_glike, w_dlike, w_gbad, w_dbad = 2, 1, 2, 1, 2\n",
    "\n",
    "out[\"score\"] = (out[\"watchlist_priority\"].astype(int)*w_watch +\n",
    "                out[\"genre_boost\"].astype(int)*w_glike +\n",
    "                out[\"director_boost\"].astype(int)*w_dlike -\n",
    "                out[\"genre_penalty\"].astype(int)*w_gbad -\n",
    "                out[\"director_penalty\"].astype(int)*w_dbad)\n",
    "\n",
    "sort_cols, ascending = [\"score\"], [False]\n",
    "if \"rank\" in out.columns: sort_cols.append(\"rank\"); ascending.append(True)\n",
    "\n",
    "out_sorted = out.sort_values(by=sort_cols, ascending=ascending).reset_index(drop=True)\n",
    "\n",
    "out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_sorted.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv.resolve())\n",
    "\n",
    "summary = {\n",
    "    \"candidates_total\": int(len(recs_df)),\n",
    "    \"recommended_total\": int(len(out_sorted)),\n",
    "    \"watchlist_priority_true\": int(out_sorted[\"watchlist_priority\"].sum()),\n",
    "    \"genre_boost_true\": int(out_sorted[\"genre_boost\"].sum()),\n",
    "    \"director_boost_true\": int(out_sorted[\"director_boost\"].sum()),\n",
    "    \"genre_penalty_true\": int(out_sorted[\"genre_penalty\"].sum()),\n",
    "    \"director_penalty_true\": int(out_sorted[\"director_penalty\"].sum()),\n",
    "}\n",
    "summary\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Scoring and save\u001B[39;00m\n\u001B[32m      2\u001B[39m w_watch, w_glike, w_dlike, w_gbad, w_dbad = \u001B[32m2\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m out[\u001B[33m\"\u001B[39m\u001B[33mscore\u001B[39m\u001B[33m\"\u001B[39m] = (out[\u001B[33m\"\u001B[39m\u001B[33mwatchlist_priority\u001B[39m\u001B[33m\"\u001B[39m].astype(\u001B[38;5;28mint\u001B[39m)*w_watch +\n\u001B[32m      5\u001B[39m                 out[\u001B[33m\"\u001B[39m\u001B[33mgenre_boost\u001B[39m\u001B[33m\"\u001B[39m].astype(\u001B[38;5;28mint\u001B[39m)*w_glike +\n\u001B[32m      6\u001B[39m                 out[\u001B[33m\"\u001B[39m\u001B[33mdirector_boost\u001B[39m\u001B[33m\"\u001B[39m].astype(\u001B[38;5;28mint\u001B[39m)*w_dlike -\n\u001B[32m      7\u001B[39m                 out[\u001B[33m\"\u001B[39m\u001B[33mgenre_penalty\u001B[39m\u001B[33m\"\u001B[39m].astype(\u001B[38;5;28mint\u001B[39m)*w_gbad -\n\u001B[32m      8\u001B[39m                 out[\u001B[33m\"\u001B[39m\u001B[33mdirector_penalty\u001B[39m\u001B[33m\"\u001B[39m].astype(\u001B[38;5;28mint\u001B[39m)*w_dbad)\n\u001B[32m     10\u001B[39m sort_cols, ascending = [\u001B[33m\"\u001B[39m\u001B[33mscore\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[38;5;28;01mFalse\u001B[39;00m]\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mrank\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m out.columns: sort_cols.append(\u001B[33m\"\u001B[39m\u001B[33mrank\u001B[39m\u001B[33m\"\u001B[39m); ascending.append(\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mNameError\u001B[39m: name 'out' is not defined"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
