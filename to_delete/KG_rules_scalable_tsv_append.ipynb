{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decb4356",
   "metadata": {},
   "source": [
    "# Film-KG (RDF) — scalable pipeline + TSV-Append\n",
    "\n",
    "Dieses Notebook:\n",
    "1) Kanonisiert `schema:character`, mintet Character-URIs `ex:char/<slug>`, verknüpft Filme via `ex:featuresCharacter`.\n",
    "2) Leitet `ex:SAME_UNIVERSE` via Self-Join über Character ab, schreibt **batchweise** `.nt`.\n",
    "3) Bildet `ex:CREATIVE_PAIR` (Director×Actor ≥2), ebenfalls **batchweise** `.nt`.\n",
    "4) **Hängt** alle neuen Kanten zusätzlich **als TSV** an deine bestehende `movie_kg_triples.tsv` **nach Backup** an."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219252d",
   "metadata": {},
   "source": [
    "## 0) Setup & Konfiguration"
   ]
  },
  {
   "cell_type": "code",
   "id": "15b12b73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:41:28.381864Z",
     "start_time": "2025-09-15T00:41:27.974566Z"
    }
   },
   "source": [
    "!python -c \"import rdflib\" 2>/dev/null || pip -q install rdflib==7.0.0\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import shutil, re\n",
    "from datetime import datetime\n",
    "\n",
    "DATA_PATH = Path(\"../data/kg/triples/movie_kg_triples.tsv\")  # bestehende KG-Datei (TSV)\n",
    "OUT_DIR = Path(\"../data/kg/triples\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BATCH_SIZE = 50000  # Tripel je Ausgabedatei\n",
    "\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "EX     = Namespace(\"http://example.org/\")\n",
    "CHAR_NS = Namespace(str(EX) + \"char/\")\n",
    "\n",
    "print(\"Data:\", DATA_PATH.resolve())\n",
    "print(\"Output:\", OUT_DIR.resolve())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: /Users/tschaffel/PycharmProjects/letterboxd-KG/data/kg/triples/movie_kg_triples.tsv\n",
      "Output: /Users/tschaffel/PycharmProjects/letterboxd-KG/data/kg/triples\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "f1081150",
   "metadata": {},
   "source": [
    "## 1) Daten laden (robuster TSV-Parser)"
   ]
  },
  {
   "cell_type": "code",
   "id": "a0bfc20b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:41:29.234037Z",
     "start_time": "2025-09-15T00:41:28.411048Z"
    }
   },
   "source": [
    "g = Graph(); g.bind(\"schema\", SCHEMA); g.bind(\"ex\", EX); g.bind(\"rdf\", RDF)\n",
    "prefix_map = {\"schema\": str(SCHEMA), \"rdf\": str(RDF), \"rdfs\": str(RDFS), \"xsd\": str(XSD), \"ex\": str(EX)}\n",
    "\n",
    "def parse_term(term: str):\n",
    "    term = term.strip()\n",
    "    if len(term) >= 2 and term[0] == '\"' and term[-1] == '\"':\n",
    "        return Literal(term[1:-1])\n",
    "    if term.startswith(\"http://\") or term.startswith(\"https://\"):\n",
    "        return URIRef(term)\n",
    "    if \":\" in term:\n",
    "        pfx, local = term.split(\":\", 1)\n",
    "        if pfx in prefix_map:\n",
    "            return URIRef(prefix_map[pfx] + local)\n",
    "    return Literal(term)\n",
    "\n",
    "count = 0\n",
    "with DATA_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        parts = line.split(\"\\t\")\n",
    "        if len(parts) != 3:\n",
    "            continue\n",
    "        s, p, o = map(parse_term, parts)\n",
    "        g.add((s, p, o))\n",
    "        count += 1\n",
    "print(\"Geladene Tripel:\", count)\n",
    "print(\"Beispiel-Tripel:\")\n",
    "for i, (s,p,o) in enumerate(g):\n",
    "    print(\"-\", s, p, o)\n",
    "    if i >= 4: break\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geladene Tripel: 58601\n",
      "Beispiel-Tripel:\n",
      "- company77208 http://schema.org/name Gama Entertainment Partners\n",
      "- movie590223 http://schema.org/actor person1576672\n",
      "- movie120 http://example.org/timesWatched timesWatched_nan\n",
      "- person2969804 http://www.w3.org/1999/02/22-rdf-syntax-ns#type http://schema.org/Person\n",
      "- company195260 http://example.org/country GB\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "ec8a51cc",
   "metadata": {},
   "source": [
    "## 2) Backup & TSV-Append-Helfer"
   ]
  },
  {
   "cell_type": "code",
   "id": "7485b1d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:41:29.276215Z",
     "start_time": "2025-09-15T00:41:29.269270Z"
    }
   },
   "source": [
    "BACKUP_DIR = OUT_DIR / \"backups\"; BACKUP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BACKUP_PATH = BACKUP_DIR / f\"movie_kg_triples_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.tsv\"\n",
    "\n",
    "# Backup anlegen\n",
    "shutil.copy2(DATA_PATH, BACKUP_PATH)\n",
    "print(\"Backup gespeichert:\", BACKUP_PATH)\n",
    "\n",
    "def term_to_str(term):\n",
    "    if isinstance(term, URIRef):\n",
    "        # Versuche Prefix-Kurzform\n",
    "        for pfx, ns in prefix_map.items():\n",
    "            if str(term).startswith(ns):\n",
    "                return f\"{pfx}:{str(term)[len(ns):]}\"\n",
    "        return str(term)\n",
    "    elif isinstance(term, Literal):\n",
    "        s = str(term).replace('\"', '\\\"')\n",
    "        return f'\"{s}\"'\n",
    "    else:\n",
    "        return str(term)\n",
    "\n",
    "def append_triples_tsv(triples):\n",
    "    with DATA_PATH.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        for (s,p,o) in triples:\n",
    "            f.write(term_to_str(s) + \"\\t\" + term_to_str(p) + \"\\t\" + term_to_str(o) + \"\\n\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup gespeichert: ../data/kg/triples/backups/movie_kg_triples_backup_20250915_024129.tsv\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "64754453",
   "metadata": {},
   "source": [
    "## 3) Vorverarbeitung: Character-Knoten & `ex:featuresCharacter`"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb583841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:41:29.564123Z",
     "start_time": "2025-09-15T00:41:29.340444Z"
    }
   },
   "source": [
    "canon_re = re.compile(r\"\\s*\\([^)]*\\)\")\n",
    "def canonize(text: str) -> str:\n",
    "    s = canon_re.sub(\"\", text)\n",
    "    return s.strip().lower()\n",
    "\n",
    "def slugify(text: str) -> str:\n",
    "    t = re.sub(r\"[^a-z0-9]+\", \"-\", text)\n",
    "    t = re.sub(r\"-+\", \"-\", t).strip(\"-\")\n",
    "    return t or \"x\"\n",
    "\n",
    "char_uri_by_canon = {}\n",
    "added_nodes = 0; added_edges = 0\n",
    "\n",
    "new_feature_triples = []  # für optionales Mitschreiben in TSV\n",
    "\n",
    "for f, _, ch in g.triples((None, SCHEMA.character, None)):\n",
    "    c = canonize(str(ch))\n",
    "    if not c:\n",
    "        continue\n",
    "    uri = char_uri_by_canon.get(c)\n",
    "    if uri is None:\n",
    "        uri = URIRef(CHAR_NS + slugify(c))\n",
    "        char_uri_by_canon[c] = uri\n",
    "        if (uri, RDF.type, EX.Character) not in g:\n",
    "            g.add((uri, RDF.type, EX.Character))\n",
    "            g.add((uri, EX.canonName, Literal(c)))\n",
    "            new_feature_triples.append((uri, RDF.type, EX.Character))\n",
    "            new_feature_triples.append((uri, EX.canonName, Literal(c)))\n",
    "            added_nodes += 1\n",
    "    if (f, EX.featuresCharacter, uri) not in g:\n",
    "        g.add((f, EX.featuresCharacter, uri))\n",
    "        new_feature_triples.append((f, EX.featuresCharacter, uri))\n",
    "        added_edges += 1\n",
    "\n",
    "print(\"Neue Character-Knoten:\", added_nodes)\n",
    "print(\"Neue featuresCharacter-Kanten:\", added_edges)\n",
    "\n",
    "# Optional: diese neuen Vorverarbeitungs-Tripel direkt ins TSV anhängen\n",
    "#if new_feature_triples:\n",
    "#    append_triples_tsv(new_feature_triples)\n",
    "#    print(\"Vorverarbeitungs-Tripel ins TSV angehängt:\", len(new_feature_triples))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neue Character-Knoten: 5392\n",
      "Neue featuresCharacter-Kanten: 6645\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "0233f0c1",
   "metadata": {},
   "source": [
    "## 4) SAME_UNIVERSE ableiten (Self-Join über Character) — Batch + TSV-Append"
   ]
  },
  {
   "cell_type": "code",
   "id": "45bbb369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:41:29.592316Z",
     "start_time": "2025-09-15T00:41:29.572110Z"
    }
   },
   "source": [
    "from itertools import combinations\n",
    "\n",
    "films_by_char = defaultdict(list)\n",
    "for f, _, c in g.triples((None, EX.featuresCharacter, None)):\n",
    "    films_by_char[c].append(f)\n",
    "\n",
    "new_su_triples = []\n",
    "seen = set()\n",
    "\n",
    "for char_uri, films in films_by_char.items():\n",
    "    if len(films) < 2:\n",
    "        continue\n",
    "    films_sorted = sorted(set(films), key=str)\n",
    "    for f1, f2 in combinations(films_sorted, 2):\n",
    "        key = (str(f1), str(f2))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        new_su_triples.append((f1, EX.sameUniverse, f2))\n",
    "\n",
    "append_triples_tsv(new_su_triples)\n",
    "print(\"SAME_UNIVERSE Tripel angehängt:\", len(new_su_triples))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAME_UNIVERSE Tripel angehängt: 1576\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "0f902548",
   "metadata": {},
   "source": [
    "## 5) CREATIVE_PAIR (Director×Actor ≥2) — Batch + TSV-Append"
   ]
  },
  {
   "cell_type": "code",
   "id": "c32a46dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:41:29.646217Z",
     "start_time": "2025-09-15T00:41:29.614917Z"
    }
   },
   "source": [
    "pair_counts = defaultdict(int)\n",
    "for f, _, d in g.triples((None, SCHEMA.director, None)):\n",
    "    for _, _, a in g.triples((f, SCHEMA.actor, None)):\n",
    "        pair_counts[(d, a)] += 1\n",
    "\n",
    "new_cp_triples = []\n",
    "for (d, a), n in pair_counts.items():\n",
    "    if n >= 2:\n",
    "        new_cp_triples.append((d, EX.creativePair, a))\n",
    "        new_cp_triples.append((d, EX.creativePairRoles, Literal(\"Director,Actor\")))\n",
    "        new_cp_triples.append((d, EX.creativePairCount, Literal(n)))\n",
    "\n",
    "append_triples_tsv(new_cp_triples)\n",
    "print(\"CREATIVE_PAIR Tripel angehängt:\", len(new_cp_triples))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATIVE_PAIR Tripel angehängt: 1644\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "fe38adaa",
   "metadata": {},
   "source": [
    "## 6) Export: Basisgraph (mit featuresCharacter)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6b73d1fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:41:30.644080Z",
     "start_time": "2025-09-15T00:41:29.661746Z"
    }
   },
   "source": [
    "merged_path = OUT_DIR / \"graph_with_features.ttl\"\n",
    "g.serialize(destination=str(merged_path), format=\"turtle\")\n",
    "print(\"Basisgraph (inkl. featuresCharacter) gespeichert:\", merged_path)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basisgraph (inkl. featuresCharacter) gespeichert: ../data/kg/triples/graph_with_features.ttl\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "ad362dac",
   "metadata": {},
   "source": [
    "### Hinweise\n",
    "- Backup wurde vor jedem TSV-Append erstellt (Ordner: `outputs/backups`).\n",
    "- Die `.nt`-Batches eignen sich für Bulk-Loader (Fuseki/GraphDB/Stardog/Blazegraph).\n",
    "- TSV-Append nutzt Kurz-Prefixe wo möglich und quotet Literale.\n",
    "- Passe `BATCH_SIZE` nach Bedarf an (RAM/IO)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
