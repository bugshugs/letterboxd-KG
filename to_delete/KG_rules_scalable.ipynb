{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e587aea",
   "metadata": {},
   "source": [
    "# Film-KG (RDF) — scalable pipeline\n",
    "\n",
    "Dieses Notebook implementiert eine performante Pipeline:\n",
    "\n",
    "1) **Vorverarbeitung**: Kanonisiert `schema:character` Werte, mintet **Character-Knoten** unter `ex:char/<slug>` und verknüpft Filme mit `ex:featuresCharacter`.\n",
    "2) **SAME_UNIVERSE**: Ableitung als Self-Join über **denselben Character-Knoten** (ohne Regex/Global-Join) und **Batch-Serialisierung** (50 000 Tripel je Datei).\n",
    "3) **CREATIVE_PAIR (Director×Actor)**: Zählt gemeinsame Filme in Python, materialisiert ab `≥2`, ebenfalls **Batch-Serialisierung**.\n",
    "\n",
    "Optional kannst du die resultierenden `.nt`/`.ttl` Files in einen Triplestore (Fuseki, Blazegraph, GraphDB, Stardog) laden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efbdb76",
   "metadata": {},
   "source": [
    "## 0) Setup & Konfiguration"
   ]
  },
  {
   "cell_type": "code",
   "id": "04356841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:16:13.922619Z",
     "start_time": "2025-09-15T00:16:13.504569Z"
    }
   },
   "source": [
    "!python -c \"import rdflib\" 2>/dev/null || pip -q install rdflib==7.0.0\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import re, math\n",
    "\n",
    "DATA_PATH = Path(\"../data/kg/triples/movie_kg_triples.tsv\")  # Pfad ggf. anpassen\n",
    "OUT_DIR = Path(\"outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BATCH_SIZE = 50000  # Tripel je Ausgabedatei\n",
    "\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "EX     = Namespace(\"http://example.org/\")\n",
    "CHAR_NS = Namespace(str(EX) + \"char/\")\n",
    "\n",
    "print(\"Data:\", DATA_PATH.resolve())\n",
    "print(\"Output:\", OUT_DIR.resolve())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: /Users/tschaffel/PycharmProjects/letterboxd-KG/data/kg/triples/movie_kg_triples.tsv\n",
      "Output: /Users/tschaffel/PycharmProjects/letterboxd-KG/data/kg/outputs\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "ce7aecf3",
   "metadata": {},
   "source": [
    "## 1) Daten laden (robuste Parser-Logik)"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b9962e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:16:51.392604Z",
     "start_time": "2025-09-15T00:16:50.570266Z"
    }
   },
   "source": [
    "g = Graph(); g.bind(\"schema\", SCHEMA); g.bind(\"ex\", EX); g.bind(\"rdf\", RDF)\n",
    "prefix_map = {\"schema\": str(SCHEMA), \"rdf\": str(RDF), \"rdfs\": str(RDFS), \"xsd\": str(XSD)}\n",
    "\n",
    "def parse_term(term: str):\n",
    "    term = term.strip()\n",
    "    # Explizites Literal\n",
    "    if len(term) >= 2 and term[0] == '\"' and term[-1] == '\"':\n",
    "        return Literal(term[1:-1])\n",
    "    # Absolute URI\n",
    "    if term.startswith(\"http://\") or term.startswith(\"https://\"):\n",
    "        return URIRef(term)\n",
    "    # QName\n",
    "    if \":\" in term:\n",
    "        pfx, local = term.split(\":\", 1)\n",
    "        if pfx in prefix_map:\n",
    "            return URIRef(prefix_map[pfx] + local)\n",
    "    # sonst Literal (z. B. Namen ohne Quotes)\n",
    "    return Literal(term)\n",
    "\n",
    "count = 0\n",
    "with DATA_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        parts = line.split(\"\\t\")\n",
    "        if len(parts) != 3:\n",
    "            continue\n",
    "        s, p, o = map(parse_term, parts)\n",
    "        g.add((s, p, o))\n",
    "        count += 1\n",
    "print(\"Geladene Tripel:\", count)\n",
    "print(\"Beispiel-Tripel:\")\n",
    "for i, (s,p,o) in enumerate(g):\n",
    "    print(\"-\", s, p, o)\n",
    "    if i >= 4: break\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geladene Tripel: 58601\n",
      "Beispiel-Tripel:\n",
      "- movie10527 http://schema.org/genre genre12\n",
      "- company114130 http://www.w3.org/1999/02/22-rdf-syntax-ns#type http://schema.org/Company\n",
      "- movie8852 http://schema.org/aggregateRating avgVote_6.8\n",
      "- movie50357 http://schema.org/productionCompany company7405\n",
      "- movie315162 ex:timesWatched timesWatched_1\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "f0a0c54f",
   "metadata": {},
   "source": [
    "## 2) Vorverarbeitung: Character-Knoten & Kanten `ex:featuresCharacter`\n",
    "Wir kanonisieren Charakternamen (Klammerzusätze entfernen, trimmen, lower-case) und minten URIs `ex:char/<slug>`."
   ]
  },
  {
   "cell_type": "code",
   "id": "97f701f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:17:26.145695Z",
     "start_time": "2025-09-15T00:17:25.829192Z"
    }
   },
   "source": [
    "canon_re = re.compile(r\"\\s*\\([^)]*\\)\")\n",
    "def canonize(text: str) -> str:\n",
    "    s = canon_re.sub(\"\", text)\n",
    "    return s.strip().lower()\n",
    "\n",
    "def slugify(text: str) -> str:\n",
    "    t = re.sub(r\"[^a-z0-9]+\", \"-\", text)\n",
    "    t = re.sub(r\"-+\", \"-\", t).strip(\"-\")\n",
    "    return t or \"x\"\n",
    "\n",
    "char_uri_by_canon = {}\n",
    "added_nodes = 0; added_edges = 0\n",
    "\n",
    "for f, _, ch in g.triples((None, SCHEMA.character, None)):\n",
    "    if isinstance(ch, Literal):\n",
    "        c = canonize(str(ch))\n",
    "    else:\n",
    "        c = canonize(str(ch))\n",
    "    if not c:\n",
    "        continue\n",
    "    uri = char_uri_by_canon.get(c)\n",
    "    if uri is None:\n",
    "        uri = URIRef(CHAR_NS + slugify(c))\n",
    "        char_uri_by_canon[c] = uri\n",
    "        g.add((uri, RDF.type, EX.Character))\n",
    "        g.add((uri, EX.canonName, Literal(c)))\n",
    "        added_nodes += 1\n",
    "    if (f, EX.featuresCharacter, uri) not in g:\n",
    "        g.add((f, EX.featuresCharacter, uri))\n",
    "        added_edges += 1\n",
    "\n",
    "print(\"Neue Character-Knoten:\", added_nodes)\n",
    "print(\"Neue featuresCharacter-Kanten:\", added_edges)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neue Character-Knoten: 5395\n",
      "Neue featuresCharacter-Kanten: 6645\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "b8b0763c",
   "metadata": {},
   "source": [
    "## 3) SAME_UNIVERSE ableiten (Self-Join über Character) — **Batch** schreiben"
   ]
  },
  {
   "cell_type": "code",
   "id": "05cb6922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:19:21.164308Z",
     "start_time": "2025-09-15T00:19:21.125958Z"
    }
   },
   "source": [
    "# === Batching: SAME_UNIVERSE als N-Triples manuell schreiben ===\n",
    "from itertools import combinations\n",
    "\n",
    "films_by_char = defaultdict(list)\n",
    "for f, _, c in g.triples((None, EX.featuresCharacter, None)):\n",
    "    films_by_char[c].append(f)\n",
    "\n",
    "su_out_prefix = OUT_DIR / \"same_universe_part\"\n",
    "batch = []\n",
    "file_index = 1\n",
    "created = 0\n",
    "\n",
    "def nt_line(s, p, o) -> str:\n",
    "    # rdflib-Terms sauber zu N-Triples serialisieren\n",
    "    return f\"{s.n3()} {p.n3()} {o.n3()} .\\n\"\n",
    "\n",
    "def flush_batch():\n",
    "    global batch, file_index\n",
    "    if not batch:\n",
    "        return\n",
    "    path = Path(f\"{su_out_prefix}_{file_index:04d}.nt\")\n",
    "    with path.open(\"w\", encoding=\"utf-8\", newline=\"\\n\") as fh:\n",
    "        for (s, p, o) in batch:\n",
    "            fh.write(nt_line(s, p, o))\n",
    "    print(\"geschrieben:\", path.name, \"Tripel:\", len(batch))\n",
    "    batch = []\n",
    "    file_index += 1\n",
    "\n",
    "# Generate SAME_UNIVERSE edges\n",
    "seen = set()\n",
    "for char_uri, films in films_by_char.items():\n",
    "    if len(films) < 2:\n",
    "        continue\n",
    "    films_sorted = sorted(set(films), key=str)\n",
    "    for f1, f2 in combinations(films_sorted, 2):\n",
    "        key = (str(f1), str(f2))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        batch.append((f1, EX.SAME_UNIVERSE, f2))\n",
    "        created += 1\n",
    "        if len(batch) >= BATCH_SIZE:\n",
    "            flush_batch()\n",
    "\n",
    "flush_batch()\n",
    "print(\"SAME_UNIVERSE erzeugt (gesamt):\", created)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geschrieben: same_universe_part_0001.nt Tripel: 1576\n",
      "SAME_UNIVERSE erzeugt (gesamt): 1576\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "70fb8dfa",
   "metadata": {},
   "source": [
    "## 4) CREATIVE_PAIR (Director×Actor ≥2) — **Batch** schreiben"
   ]
  },
  {
   "cell_type": "code",
   "id": "ef95e6e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:19:47.287847Z",
     "start_time": "2025-09-15T00:19:47.234307Z"
    }
   },
   "source": [
    "# === Batching: CREATIVE_PAIR als N-Triples manuell schreiben ===\n",
    "pair_counts = defaultdict(int)\n",
    "for f, _, d in g.triples((None, SCHEMA.director, None)):\n",
    "    for _, _, a in g.triples((f, SCHEMA.actor, None)):\n",
    "        pair_counts[(d, a)] += 1\n",
    "\n",
    "cp_out_prefix = OUT_DIR / \"creative_pair_part\"\n",
    "batch = []\n",
    "file_index = 1\n",
    "created = 0\n",
    "\n",
    "def flush_cp():\n",
    "    global batch, file_index\n",
    "    if not batch:\n",
    "        return\n",
    "    path = Path(f\"{cp_out_prefix}_{file_index:04d}.nt\")\n",
    "    with path.open(\"w\", encoding=\"utf-8\", newline=\"\\n\") as fh:\n",
    "        for (s, p, o) in batch:\n",
    "            fh.write(nt_line(s, p, o))\n",
    "    print(\"geschrieben:\", path.name, \"Tripel:\", len(batch))\n",
    "    batch = []\n",
    "    file_index += 1\n",
    "\n",
    "for (d, a), n in pair_counts.items():\n",
    "    if n >= 2:\n",
    "        batch.append((d, EX.CREATIVE_PAIR, a))\n",
    "        batch.append((d, EX.creativePairRoles, Literal(\"Director,Actor\")))\n",
    "        batch.append((d, EX.creativePairCount, Literal(n)))\n",
    "        created += 3\n",
    "        if len(batch) >= BATCH_SIZE:\n",
    "            flush_cp()\n",
    "\n",
    "flush_cp()\n",
    "print(\"CREATIVE_PAIR Tripel erzeugt (gesamt):\", created)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geschrieben: creative_pair_part_0001.nt Tripel: 1644\n",
      "CREATIVE_PAIR Tripel erzeugt (gesamt): 1644\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "08581a0a",
   "metadata": {},
   "source": [
    "## 5) Export: Basisgraph (mit featuresCharacter) speichern & Tipps für Triplestores"
   ]
  },
  {
   "cell_type": "code",
   "id": "f5dbacd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:20:07.010867Z",
     "start_time": "2025-09-15T00:20:06.073419Z"
    }
   },
   "source": [
    "merged_path = OUT_DIR / \"graph_with_features.ttl\"\n",
    "g.serialize(destination=str(merged_path), format=\"turtle\")\n",
    "print(\"Basisgraph (inkl. featuresCharacter) gespeichert:\", merged_path)\n",
    "print(\"\\nLaden in Triplestores:\")\n",
    "print(\"- Fuseki (TDB2): tdb2.tdbloader --loc DB graph_with_features.ttl same_universe_part_*.nt creative_pair_part_*.nt\")\n",
    "print(\"- GraphDB/Blazegraph/Stardog: UI/CLI-Bulk-Loader; .nt-Batches sind optimal.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basisgraph (inkl. featuresCharacter) gespeichert: ../data/kg/outputs/graph_with_features.ttl\n",
      "\n",
      "Laden in Triplestores:\n",
      "- Fuseki (TDB2): tdb2.tdbloader --loc DB graph_with_features.ttl same_universe_part_*.nt creative_pair_part_*.nt\n",
      "- GraphDB/Blazegraph/Stardog: UI/CLI-Bulk-Loader; .nt-Batches sind optimal.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "fb13ee19",
   "metadata": {},
   "source": [
    "### Hinweise\n",
    "- **Self-Join**: `SAME_UNIVERSE` entsteht über denselben Character-Knoten — keine Regex/Global-Join-Explosion.\n",
    "- **Batching**: Dateien `same_universe_part_*.nt` & `creative_pair_part_*.nt` (je ≤50k Tripel) sind für Bulk-Loader optimiert.\n",
    "- **Erweiterbar**: Weitere Regeln (Actor×Actor etc.) können analog erzeugt und gebatcht werden.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
