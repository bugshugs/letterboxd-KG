{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2393886",
   "metadata": {},
   "source": [
    "\n",
    "# LO2 with **Datalog** — Robust (Patched)\n",
    "We keep Datalog for the **core logic** (exclude watched, mark watchlist),\n",
    "and compute **genre/director likes/dislikes** directly in Python (stable).\n",
    "\n",
    "**Datalog:** `recommendedBase(U,N,Y) :- candidateFor(U,N,Y) ∧ not watched_fact(U,N,Y)`\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "55b60b11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T20:21:47.293506Z",
     "start_time": "2025-09-13T20:21:47.210121Z"
    }
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "import ast, re\n",
    "from pathlib import Path\n",
    "\n",
    "# Auto-detect project root\n",
    "here = Path.cwd()\n",
    "candidate = here\n",
    "while candidate != candidate.parent and not (candidate / \"data\").exists():\n",
    "    candidate = candidate.parent\n",
    "project_root = candidate if (candidate / \"data\").exists() else Path(\"../logical\")\n",
    "print(\"Detected project_root:\", project_root.resolve())\n",
    "\n",
    "# Paths\n",
    "watched_path   = project_root / \"data\" / \"letterboxd_export\" / \"watched.csv\"\n",
    "watchlist_path = project_root / \"data\" / \"letterboxd_export\" / \"watchlist.csv\"\n",
    "candidates_path= project_root / \"data\" / \"kg\" / \"rerank_with_embedding_results.csv\"\n",
    "\n",
    "# enriched-merged uploaded in this session or local fallback\n",
    "enriched_uploaded = Path(\"/mnt/data/0bf2f757-dc8c-43d8-9f82-d2705737b4fe.csv\")\n",
    "enriched_local = project_root / \"data\" / \"enriched_merged.csv\"\n",
    "enriched_path = enriched_uploaded if enriched_uploaded.exists() else enriched_local\n",
    "print(\"Using enriched file:\", enriched_path)\n",
    "\n",
    "out_csv = project_root / \"data\" / \"kg\" / \"rerank_by_logical_rules.csv\"\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected project_root: /Users/tschaffel/PycharmProjects/letterboxd-KG\n",
      "Using enriched file: /Users/tschaffel/PycharmProjects/letterboxd-KG/data/enriched_merged.csv\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "97ca30489b1f42c1",
   "metadata": {},
   "source": [
    "## Enrich candidates with TMDB data"
   ]
  },
  {
   "cell_type": "code",
   "id": "bae4f07fe26edb74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T20:24:29.205429Z",
     "start_time": "2025-09-13T20:21:47.321842Z"
    }
   },
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "TMDB_API_TOKEN = os.getenv('TMDB_API_TOKEN')\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": \"Bearer \" + TMDB_API_TOKEN,\n",
    "    \"Content-Type\": \"application/json;charset=utf-8\"\n",
    "}\n",
    "\n",
    "recs_df = pd.read_csv(candidates_path)\n",
    "\n",
    "def normalize_title(title):\n",
    "    if not title:\n",
    "        return \"\"\n",
    "    # Unicode normalize, convert to ASCII-compatible\n",
    "    title = unicodedata.normalize(\"NFKC\", title)\n",
    "\n",
    "    # Replace common visually similar characters\n",
    "    substitutions = {\n",
    "        \"–\": \"-\",  # en dash\n",
    "        \"—\": \"-\",  # em dash\n",
    "        \"−\": \"-\",  # minus\n",
    "        \"×\": \"x\",  # multiplication sign\n",
    "        \"’\": \"'\",  # curly apostrophe\n",
    "        \"“\": '\"',\n",
    "        \"”\": '\"',\n",
    "        \"…\": \"...\",\n",
    "        \"&\": \"and\",  # optional\n",
    "    }\n",
    "\n",
    "    for orig, repl in substitutions.items():\n",
    "        title = title.replace(orig, repl)\n",
    "\n",
    "    # Collapse multiple spaces and lowercase\n",
    "    title = re.sub(r\"\\s+\", \" \", title).strip().lower()\n",
    "    return title\n",
    "\n",
    "def search_exact_match(results, search_title):\n",
    "    norm_search = normalize_title(search_title)\n",
    "    for r in results:\n",
    "        tmdb_title = r.get(\"title\") or r.get(\"name\") or \"\"\n",
    "        if normalize_title(tmdb_title) == norm_search:\n",
    "            return r\n",
    "    return None\n",
    "\n",
    "def search_movie_or_tv(title, year=None):\n",
    "    # First: try movie search\n",
    "    movie_url = \"https://api.themoviedb.org/3/search/movie\"\n",
    "    params = {\"query\": title}\n",
    "    if year:\n",
    "        params[\"year\"] = year\n",
    "\n",
    "    response = requests.get(movie_url, headers=HEADERS, params=params)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json().get(\"results\", [])\n",
    "        match = search_exact_match(results, title)\n",
    "        if match:\n",
    "            match[\"media_type\"] = \"movie\"\n",
    "            return match\n",
    "\n",
    "    # Second: try TV search\n",
    "    tv_url = \"https://api.themoviedb.org/3/search/tv\"\n",
    "    params = {\"query\": title}\n",
    "    if year:\n",
    "        params[\"first_air_date_year\"] = year\n",
    "\n",
    "    response = requests.get(tv_url, headers=HEADERS, params=params)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json().get(\"results\", [])\n",
    "        match = search_exact_match(results, title)\n",
    "        if match:\n",
    "            match[\"media_type\"] = \"tv\"\n",
    "            return match\n",
    "    return None\n",
    "\n",
    "def get_details(tmdb_id, media_type):\n",
    "    url = f\"https://api.themoviedb.org/3/{media_type}/{tmdb_id}\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    return response.json() if response.status_code == 200 else None\n",
    "\n",
    "def get_credits(tmdb_id, media_type):\n",
    "    url = f\"https://api.themoviedb.org/3/{media_type}/{tmdb_id}/credits\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    return response.json() if response.status_code == 200 else None\n",
    "\n",
    "def enrich_dataframe(df):\n",
    "    tmdb_media_base_url = \"https://www.themoviedb.org/\"\n",
    "    tmdb_poster_base_url = \"https://image.tmdb.org/t/p/\"\n",
    "    tmdb_person_base_url = \"http://www.themoviedb.org/person/\"\n",
    "    tmdb_genre_base_url = \"https://www.themoviedb.org/genre/\"\n",
    "    tmdb_company_base_url = \"https://www.themoviedb.org/company/\"\n",
    "    size = \"original\"\n",
    "\n",
    "    # Create empty columns for TMDB data\n",
    "    df[\"tmdb_url\"] = None\n",
    "    df[\"overview\"] = None\n",
    "    df[\"genres\"] = None\n",
    "    df[\"runtime\"] = None\n",
    "    df[\"vote_average\"] = None\n",
    "    df[\"poster_url\"] = None\n",
    "    df[\"media_type\"] = None\n",
    "    df[\"director\"] = None\n",
    "    df[\"actors\"] = None\n",
    "    df[\"characters\"] = None\n",
    "    df[\"origin_country\"] = None # from here\n",
    "    df[\"original_language\"] = None\n",
    "    df[\"popularity\"] = None\n",
    "    df[\"production_companies\"] = None\n",
    "    df[\"production_countries\"] = None\n",
    "    df[\"spoken_languages\"] = None\n",
    "\n",
    "    total = len(df)\n",
    "    print(f\"Starting enrichment for {total} titles using TMDB data...\\n\")\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        title = row[\"candidate_title\"]\n",
    "        year = row.get(\"year\", None)\n",
    "\n",
    "        print(f\"[{idx+1}/{total}] Searching: '{title}' ({year})\", end=\"\")\n",
    "\n",
    "        result = search_movie_or_tv(title, year)\n",
    "        if result:\n",
    "            print(\" ✅ Match found\")\n",
    "            media_type = result[\"media_type\"]\n",
    "            tmdb_id = result[\"id\"]\n",
    "\n",
    "            details = get_details(tmdb_id, media_type)\n",
    "            credits = get_credits(tmdb_id, media_type)\n",
    "\n",
    "            if details:\n",
    "                df.at[idx, \"media_type\"] = media_type\n",
    "                df.at[idx, \"tmdb_url\"] = tmdb_media_base_url + f\"{media_type}/\" + str(tmdb_id)\n",
    "                df.at[idx, \"overview\"] = details.get(\"overview\")\n",
    "                df.at[idx, \"genres\"] = [str(g[\"name\"]) + \":\" + tmdb_genre_base_url + str(g[\"id\"]) for g in details.get(\"genres\", [])]\n",
    "                df.at[idx, \"vote_average\"] = details.get(\"vote_average\")\n",
    "                df.at[idx, \"origin_country\"] = details.get(\"origin_country\")\n",
    "                df.at[idx, \"original_language\"] = details.get(\"original_language\")\n",
    "                df.at[idx, \"popularity\"] = details.get(\"popularity\")\n",
    "                df.at[idx, \"production_companies\"] = [str(p[\"name\"]) + \":\" + tmdb_company_base_url + str(p[\"id\"]) + \":\" + str(p[\"origin_country\"]) for p in details.get(\"production_companies\", [])]\n",
    "                df.at[idx, \"production_countries\"] = [str(p[\"name\"]) + \":\" + str(p[\"iso_3166_1\"]) for p in details.get(\"production_countries\", [])]\n",
    "                df.at[idx, \"spoken_languages\"] = [str(s[\"english_name\"]) + \":\" + str(s[\"iso_639_1\"]) for s in details.get(\"spoken_languages\", [])]\n",
    "\n",
    "                if media_type == \"movie\":\n",
    "                    df.at[idx, \"runtime\"] = details.get(\"runtime\")\n",
    "                else:\n",
    "                    df.at[idx, \"runtime\"] = None\n",
    "\n",
    "                poster_path = details.get(\"poster_path\")\n",
    "                if poster_path:\n",
    "                    df.at[idx, \"poster_url\"] = tmdb_poster_base_url + size + poster_path\n",
    "\n",
    "            if credits:\n",
    "                # Directors (may be multiple)\n",
    "                crew = credits.get(\"crew\", [])\n",
    "                directors = [str(p[\"name\"]) + \":\" + tmdb_person_base_url + str(p[\"id\"]) for p in crew if p.get(\"job\") == \"Director\"]\n",
    "                df.at[idx, \"director\"] = directors if directors else None\n",
    "\n",
    "                # Top 5 actors and their characters\n",
    "                cast = credits.get(\"cast\", [])[:10]\n",
    "                actor_names = [str(a[\"name\"]) + \":\" + tmdb_person_base_url + str(a[\"id\"]) for a in cast]\n",
    "                character_names = [a[\"character\"] for a in cast]\n",
    "                df.at[idx, \"actors\"] = actor_names if actor_names else None\n",
    "                df.at[idx, \"characters\"] = character_names if character_names else None\n",
    "        else:\n",
    "            print(\" ❌ No exact match found\")\n",
    "\n",
    "        sleep(0.25)\n",
    "\n",
    "    print(\"\\n✔️  Enrichment completed.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "recs_df = enrich_dataframe(recs_df)\n",
    "# recs_df.to_csv(\"../data/enriched_merged.csv\", index=False)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting enrichment for 200 titles using TMDB data...\n",
      "\n",
      "[1/200] Searching: 'Godzilla' (1998.0) ✅ Match found\n",
      "[2/200] Searching: 'Fright Night' (1985.0) ✅ Match found\n",
      "[3/200] Searching: 'Trio' (1997.0) ✅ Match found\n",
      "[4/200] Searching: 'Dracula' (1958.0) ✅ Match found\n",
      "[5/200] Searching: 'Teenage Mutant Ninja Turtles' (1990.0) ✅ Match found\n",
      "[6/200] Searching: 'The Avengers' (1998.0) ✅ Match found\n",
      "[7/200] Searching: 'Superman' (1978.0) ✅ Match found\n",
      "[8/200] Searching: 'A Close Shave' (1996.0) ✅ Match found\n",
      "[9/200] Searching: 'India' (1993.0) ✅ Match found\n",
      "[10/200] Searching: 'Miriam' (1957.0) ✅ Match found\n",
      "[11/200] Searching: 'Evangelion: 2.0 You Can (Not) Advance' (2009.0) ✅ Match found\n",
      "[12/200] Searching: 'Batman' (1966.0) ✅ Match found\n",
      "[13/200] Searching: 'Toy Story 2' (1999.0) ✅ Match found\n",
      "[14/200] Searching: 'The Brood' (1979.0) ✅ Match found\n",
      "[15/200] Searching: 'Uncle Frank' (2020.0) ✅ Match found\n",
      "[16/200] Searching: 'Shivers' (1975.0) ✅ Match found\n",
      "[17/200] Searching: 'Imagine Me & You' (2006.0) ✅ Match found\n",
      "[18/200] Searching: 'Spirited' (2022.0) ✅ Match found\n",
      "[19/200] Searching: 'Look Who's Talking Too' (1990.0) ✅ Match found\n",
      "[20/200] Searching: 'My Own Private Idaho' (1991.0) ✅ Match found\n",
      "[21/200] Searching: 'The Aristocats' (1970.0) ✅ Match found\n",
      "[22/200] Searching: 'Ro' (nan) ✅ Match found\n",
      "[23/200] Searching: 'Six Shooter' (2004.0) ✅ Match found\n",
      "[24/200] Searching: 'The Damned United' (2009.0) ✅ Match found\n",
      "[25/200] Searching: 'The Little Drummer Boy: Book II' (1976.0) ✅ Match found\n",
      "[26/200] Searching: 'Empire of the Sun' (1987.0) ✅ Match found\n",
      "[27/200] Searching: 'Last Days' (2005.0) ✅ Match found\n",
      "[28/200] Searching: 'The Kid' (1921.0) ✅ Match found\n",
      "[29/200] Searching: 'Shrek Forever After' (2010.0) ✅ Match found\n",
      "[30/200] Searching: 'Cats Don't Dance' (1997.0) ✅ Match found\n",
      "[31/200] Searching: 'Annie' (1999.0) ✅ Match found\n",
      "[32/200] Searching: 'The Little Mermaid' (1989.0) ✅ Match found\n",
      "[33/200] Searching: '25th Hour' (2002.0) ✅ Match found\n",
      "[34/200] Searching: 'Bedazzled' (2000.0) ✅ Match found\n",
      "[35/200] Searching: 'The BFG' (2016.0) ✅ Match found\n",
      "[36/200] Searching: 'Hollow Man' (2000.0) ✅ Match found\n",
      "[37/200] Searching: 'Mortal Kombat' (1995.0) ✅ Match found\n",
      "[38/200] Searching: 'The Hunt for Red October' (1990.0) ✅ Match found\n",
      "[39/200] Searching: 'Sunshine' (2007.0) ✅ Match found\n",
      "[40/200] Searching: 'Kicking and Screaming' (1995.0) ✅ Match found\n",
      "[41/200] Searching: 'The Mask of Zorro' (1998.0) ✅ Match found\n",
      "[42/200] Searching: 'The War of the Gargantuas' (1966.0) ✅ Match found\n",
      "[43/200] Searching: 'Uncle Buck' (1989.0) ✅ Match found\n",
      "[44/200] Searching: 'Ferris Bueller's Day Off' (1986.0) ✅ Match found\n",
      "[45/200] Searching: 'Death Proof' (2007.0) ✅ Match found\n",
      "[46/200] Searching: 'The Wedding Planner' (2001.0) ✅ Match found\n",
      "[47/200] Searching: 'The Chronicles of Narnia: The Voyage of the Dawn Treader' (2010.0) ✅ Match found\n",
      "[48/200] Searching: 'Justice League: Warworld' (2023.0) ✅ Match found\n",
      "[49/200] Searching: 'The Gold Rush' (1925.0) ✅ Match found\n",
      "[50/200] Searching: 'X-Men Origins: Wolverine' (2009.0) ✅ Match found\n",
      "[51/200] Searching: 'Garfield: A Tail of Two Kitties' (2006.0) ✅ Match found\n",
      "[52/200] Searching: 'Airplane II: The Sequel' (1982.0) ✅ Match found\n",
      "[53/200] Searching: 'Mobile Suit Gundam GQuuuuuuX -Beginning-' (2025.0) ✅ Match found\n",
      "[54/200] Searching: 'Blood Diamond' (2006.0) ✅ Match found\n",
      "[55/200] Searching: 'Dawn of the Dead' (2004.0) ✅ Match found\n",
      "[56/200] Searching: 'Wallace & Gromit: The Curse of the Were-Rabbit' (2005.0) ✅ Match found\n",
      "[57/200] Searching: 'History of the World: Part I' (1981.0) ✅ Match found\n",
      "[58/200] Searching: 'Impy's Island' (2006.0) ✅ Match found\n",
      "[59/200] Searching: 'Snow White' (2005.0) ✅ Match found\n",
      "[60/200] Searching: 'Silent Movie' (1976.0) ✅ Match found\n",
      "[61/200] Searching: 'The Little Mermaid II: Return to the Sea' (2000.0) ✅ Match found\n",
      "[62/200] Searching: 'Hook' (1991.0) ✅ Match found\n",
      "[63/200] Searching: 'Toy Story 3' (2010.0) ✅ Match found\n",
      "[64/200] Searching: 'Jack Frost' (1979.0) ✅ Match found\n",
      "[65/200] Searching: 'Mission: Impossible III' (2006.0) ✅ Match found\n",
      "[66/200] Searching: 'The Matrix Resurrections' (2021.0) ✅ Match found\n",
      "[67/200] Searching: 'Nestor, the Long-Eared Christmas Donkey' (1977.0) ✅ Match found\n",
      "[68/200] Searching: 'Bob the Builder: A Christmas to Remember - The Movie' (2001.0) ✅ Match found\n",
      "[69/200] Searching: 'Hard Target' (1993.0) ✅ Match found\n",
      "[70/200] Searching: 'Balto: Wolf Quest' (2002.0) ✅ Match found\n",
      "[71/200] Searching: 'Dog Day Afternoon' (1975.0) ✅ Match found\n",
      "[72/200] Searching: 'Superman II: The Richard Donner Cut' (2006.0) ✅ Match found\n",
      "[73/200] Searching: 'Maybe... Maybe Not' (1994.0) ✅ Match found\n",
      "[74/200] Searching: 'Crazy' (2000.0) ✅ Match found\n",
      "[75/200] Searching: 'Hammer: The 'Rootin' for Regen' story' (2017.0) ✅ Match found\n",
      "[76/200] Searching: 'Notting Hill' (1999.0) ✅ Match found\n",
      "[77/200] Searching: 'One Million B.C.' (1940.0) ✅ Match found\n",
      "[78/200] Searching: 'George Carlin: Jammin' in New York' (1992.0) ✅ Match found\n",
      "[79/200] Searching: 'Species' (1995.0) ✅ Match found\n",
      "[80/200] Searching: 'Planes, Trains and Automobiles' (1987.0) ✅ Match found\n",
      "[81/200] Searching: '300' (2007.0) ✅ Match found\n",
      "[82/200] Searching: 'Cameron Esposito: Four Pills' (2025.0) ✅ Match found\n",
      "[83/200] Searching: 'Aberdeen' (2000.0) ✅ Match found\n",
      "[84/200] Searching: 'New Life' (2016.0) ✅ Match found\n",
      "[85/200] Searching: 'My Left Foot: The Story of Christy Brown' (1989.0) ✅ Match found\n",
      "[86/200] Searching: 'Imaginary Heroes' (2004.0) ✅ Match found\n",
      "[87/200] Searching: 'Jackie Brown' (1997.0) ✅ Match found\n",
      "[88/200] Searching: 'The Puppet Masters' (1994.0) ✅ Match found\n",
      "[89/200] Searching: 'Druid Peak' (2014.0) ✅ Match found\n",
      "[90/200] Searching: 'Halloween' (1978.0) ✅ Match found\n",
      "[91/200] Searching: 'Fanfaren der Ehe' (1953.0) ✅ Match found\n",
      "[92/200] Searching: 'DodgeBall: A True Underdog Story' (2004.0) ✅ Match found\n",
      "[93/200] Searching: 'I Am Sam' (2001.0) ✅ Match found\n",
      "[94/200] Searching: 'Don't Look Up' (2021.0) ✅ Match found\n",
      "[95/200] Searching: 'The Abyss' (1989.0) ✅ Match found\n",
      "[96/200] Searching: 'This Is Spinal Tap' (1984.0) ✅ Match found\n",
      "[97/200] Searching: 'The Ref' (1994.0) ✅ Match found\n",
      "[98/200] Searching: 'Stick It' (2006.0) ✅ Match found\n",
      "[99/200] Searching: 'Dracula: Dead and Loving It' (1995.0) ✅ Match found\n",
      "[100/200] Searching: 'Tucker: The Man and His Dream' (1988.0) ✅ Match found\n",
      "[101/200] Searching: 'Marie Antoinette' (2006.0) ✅ Match found\n",
      "[102/200] Searching: 'Critters 2' (1988.0) ✅ Match found\n",
      "[103/200] Searching: 'Old Dogs' (2009.0) ✅ Match found\n",
      "[104/200] Searching: 'Bordello of Blood' (1996.0) ✅ Match found\n",
      "[105/200] Searching: 'The Evil of Frankenstein' (1964.0) ✅ Match found\n",
      "[106/200] Searching: 'Blood for Dracula' (1974.0) ✅ Match found\n",
      "[107/200] Searching: 'Stand by Me' (1986.0) ✅ Match found\n",
      "[108/200] Searching: 'The Pursuit of Happyness' (2006.0) ✅ Match found\n",
      "[109/200] Searching: 'New York Minute' (2004.0) ✅ Match found\n",
      "[110/200] Searching: 'Live Free or Die Hard' (2007.0) ✅ Match found\n",
      "[111/200] Searching: 'Smoke' (1995.0) ✅ Match found\n",
      "[112/200] Searching: 'She Said' (2022.0) ✅ Match found\n",
      "[113/200] Searching: 'Code 46' (2003.0) ✅ Match found\n",
      "[114/200] Searching: 'We Own the Night' (2007.0) ✅ Match found\n",
      "[115/200] Searching: 'Breakfast on Pluto' (2005.0) ✅ Match found\n",
      "[116/200] Searching: 'Earth' (2007.0) ✅ Match found\n",
      "[117/200] Searching: 'Inherit the Wind' (1960.0) ✅ Match found\n",
      "[118/200] Searching: 'Man on the Moon' (1999.0) ✅ Match found\n",
      "[119/200] Searching: 'Milk' (2008.0) ✅ Match found\n",
      "[120/200] Searching: 'EuroTrip' (2004.0) ✅ Match found\n",
      "[121/200] Searching: 'The Revenge of Frankenstein' (1958.0) ✅ Match found\n",
      "[122/200] Searching: 'Thank You for Smoking' (2005.0) ✅ Match found\n",
      "[123/200] Searching: 'Time to Leave' (2005.0) ✅ Match found\n",
      "[124/200] Searching: 'David Hockney: A Bigger Picture' (2009.0) ✅ Match found\n",
      "[125/200] Searching: 'White Men Can't Jump' (1992.0) ✅ Match found\n",
      "[126/200] Searching: 'The Talented Mr. Ripley' (1999.0) ✅ Match found\n",
      "[127/200] Searching: 'Secrets & Lies' (1996.0) ✅ Match found\n",
      "[128/200] Searching: 'Kramer vs. Kramer' (1979.0) ✅ Match found\n",
      "[129/200] Searching: 'Gorillas in the Mist' (1988.0) ✅ Match found\n",
      "[130/200] Searching: 'Lorenzo's Oil' (1992.0) ✅ Match found\n",
      "[131/200] Searching: 'Minority Report' (2002.0) ✅ Match found\n",
      "[132/200] Searching: 'Transylvania 6-5000' (1985.0) ✅ Match found\n",
      "[133/200] Searching: 'Private Parts' (1997.0) ✅ Match found\n",
      "[134/200] Searching: 'The Station Agent' (2003.0) ✅ Match found\n",
      "[135/200] Searching: 'Them!' (1954.0) ✅ Match found\n",
      "[136/200] Searching: 'TMNT' (2007.0) ✅ Match found\n",
      "[137/200] Searching: 'City Island' (2009.0) ✅ Match found\n",
      "[138/200] Searching: 'Saint Ralph' (2005.0) ✅ Match found\n",
      "[139/200] Searching: 'Thumbsucker' (2005.0) ✅ Match found\n",
      "[140/200] Searching: 'East of Eden' (1955.0) ✅ Match found\n",
      "[141/200] Searching: 'Office Space' (1999.0) ✅ Match found\n",
      "[142/200] Searching: 'Quatermass 2' (1957.0) ✅ Match found\n",
      "[143/200] Searching: 'The Departed' (2006.0) ✅ Match found\n",
      "[144/200] Searching: 'The Return of the Living Dead' (1985.0) ✅ Match found\n",
      "[145/200] Searching: 'The Legend of Zorro' (2005.0) ✅ Match found\n",
      "[146/200] Searching: 'Election' (1999.0) ✅ Match found\n",
      "[147/200] Searching: 'Ghost World' (2001.0) ✅ Match found\n",
      "[148/200] Searching: 'Human Traffic' (1999.0) ✅ Match found\n",
      "[149/200] Searching: 'A.rtificial I.mmortality' (2021.0) ✅ Match found\n",
      "[150/200] Searching: 'Disturbing Behavior' (1998.0) ✅ Match found\n",
      "[151/200] Searching: 'The Miracle Worker' (1962.0) ✅ Match found\n",
      "[152/200] Searching: 'Exorcist: The Beginning' (2004.0) ✅ Match found\n",
      "[153/200] Searching: 'SommerHundeSöhne' (2005.0) ✅ Match found\n",
      "[154/200] Searching: 'The Relic' (1997.0) ✅ Match found\n",
      "[155/200] Searching: 'Stuart Saves His Family' (1995.0) ✅ Match found\n",
      "[156/200] Searching: 'The Horror of Frankenstein' (1970.0) ✅ Match found\n",
      "[157/200] Searching: 'Great Expectations' (1998.0) ✅ Match found\n",
      "[158/200] Searching: 'Thir13en Ghosts' (2001.0) ✅ Match found\n",
      "[159/200] Searching: 'Moonstruck' (1987.0) ✅ Match found\n",
      "[160/200] Searching: 'The Mosquito Coast' (1986.0) ✅ Match found\n",
      "[161/200] Searching: 'The Texas Chainsaw Massacre' (2003.0) ✅ Match found\n",
      "[162/200] Searching: 'We Treat Women Too Well' (2024.0) ✅ Match found\n",
      "[163/200] Searching: 'Coded Bias' (2020.0) ✅ Match found\n",
      "[164/200] Searching: 'Some Girls Do' (1969.0) ✅ Match found\n",
      "[165/200] Searching: 'That Sinking Feeling' (1980.0) ✅ Match found\n",
      "[166/200] Searching: 'Asterix Conquers America' (1994.0) ✅ Match found\n",
      "[167/200] Searching: 'The Last King of Scotland' (2006.0) ✅ Match found\n",
      "[168/200] Searching: 'Lost in America' (1985.0) ✅ Match found\n",
      "[169/200] Searching: 'The Rescuers Down Under' (1990.0) ✅ Match found\n",
      "[170/200] Searching: 'Heathers' (1988.0) ✅ Match found\n",
      "[171/200] Searching: 'Don't Worry, He Won't Get Far on Foot' (2018.0) ✅ Match found\n",
      "[172/200] Searching: 'Dr. Dolittle: Tail to the Chief' (2008.0) ✅ Match found\n",
      "[173/200] Searching: 'Collateral' (2004.0) ✅ Match found\n",
      "[174/200] Searching: 'Surveillance' (2008.0) ✅ Match found\n",
      "[175/200] Searching: 'Jack the Giant Killer' (1962.0) ✅ Match found\n",
      "[176/200] Searching: 'Somebody Up There Likes Me' (1956.0) ✅ Match found\n",
      "[177/200] Searching: 'Follow the Fleet' (1936.0) ✅ Match found\n",
      "[178/200] Searching: 'Set It Off' (1996.0) ✅ Match found\n",
      "[179/200] Searching: 'Wonder Boys' (2000.0) ✅ Match found\n",
      "[180/200] Searching: 'Son of Frankenstein' (1939.0) ✅ Match found\n",
      "[181/200] Searching: 'Chopper' (2000.0) ✅ Match found\n",
      "[182/200] Searching: 'The Hand That Rocks the Cradle' (1992.0) ✅ Match found\n",
      "[183/200] Searching: 'White Wedding' (2009.0) ✅ Match found\n",
      "[184/200] Searching: 'Final Destination 2' (2003.0) ✅ Match found\n",
      "[185/200] Searching: 'Lifeforce' (1985.0) ✅ Match found\n",
      "[186/200] Searching: 'Tin Men' (1987.0) ✅ Match found\n",
      "[187/200] Searching: 'Me and You and Everyone We Know' (2005.0) ✅ Match found\n",
      "[188/200] Searching: 'The Fox and the Hound' (1981.0) ✅ Match found\n",
      "[189/200] Searching: 'Fools Rush In' (1997.0) ✅ Match found\n",
      "[190/200] Searching: 'Bound' (1996.0) ✅ Match found\n",
      "[191/200] Searching: 'Boys on the Side' (1995.0) ✅ Match found\n",
      "[192/200] Searching: 'Pieces of April' (2003.0) ✅ Match found\n",
      "[193/200] Searching: 'The Masque of the Red Death' (1964.0) ✅ Match found\n",
      "[194/200] Searching: 'The Child Remains' (2017.0) ✅ Match found\n",
      "[195/200] Searching: 'Evan Almighty' (2007.0) ✅ Match found\n",
      "[196/200] Searching: 'State of Grace' (1990.0) ✅ Match found\n",
      "[197/200] Searching: 'Fantastic Four: Rise of the Silver Surfer' (2007.0) ✅ Match found\n",
      "[198/200] Searching: 'Donnie Brasco' (1997.0) ✅ Match found\n",
      "[199/200] Searching: 'Fear and Loathing in Las Vegas' (1998.0) ✅ Match found\n",
      "[200/200] Searching: 'The Gay Divorcee' (1934.0) ✅ Match found\n",
      "\n",
      "✔️  Enrichment completed.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "98e12f65",
   "metadata": {},
   "source": [
    "## Load & Normalize"
   ]
  },
  {
   "cell_type": "code",
   "id": "644366e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T20:24:29.828818Z",
     "start_time": "2025-09-13T20:24:29.556079Z"
    }
   },
   "source": [
    "\n",
    "watched_df = pd.read_csv(watched_path)\n",
    "watchlist_df = pd.read_csv(watchlist_path)\n",
    "enriched_df = pd.read_csv(enriched_path)\n",
    "\n",
    "# lowercase columns\n",
    "for df in (watched_df, watchlist_df, recs_df, enriched_df):\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "def pick(cols, opts):\n",
    "    for o in opts:\n",
    "        if o in cols: return o\n",
    "    return None\n",
    "\n",
    "# pick columns\n",
    "watched_name_col = pick(watched_df.columns, [\"name\",\"film name\",\"title\"])\n",
    "watched_year_col = pick(watched_df.columns, [\"year\",\"release year\",\"release_year\"])\n",
    "watch_name_col   = pick(watchlist_df.columns, [\"name\",\"film name\",\"title\",\"candidate_title\",\"movie\",\"movie_title\",\"original_title\"])\n",
    "watch_year_col   = pick(watchlist_df.columns, [\"year\",\"release year\",\"release_year\",\"releaseyear\"])\n",
    "recs_name_col    = pick(recs_df.columns, [\"candidate_title\",\"name\",\"title\",\"movie_title\",\"original_title\"])\n",
    "recs_year_col    = pick(recs_df.columns, [\"year\",\"release_year\",\"candidate_year\",\"releaseyear\",\"year_x\",\"year_y\"])\n",
    "en_title_col     = pick(enriched_df.columns, [\"title\",\"name\"])\n",
    "en_year_col      = pick(enriched_df.columns, [\"year\",\"release_year\"])\n",
    "en_rating_col    = pick(enriched_df.columns, [\"rating\",\"myrating\",\"rating10\",\"rating_10\"])\n",
    "en_genres_col    = pick(enriched_df.columns, [\"genres\",\"genre\",\"tmdb_genres\"])\n",
    "en_dir_col       = pick(enriched_df.columns, [\"director\",\"directors\",\"tmdb_directors\"])\n",
    "\n",
    "assert all([watched_name_col, watched_year_col, watch_name_col, watch_year_col, recs_name_col, recs_year_col, en_title_col, en_year_col, en_rating_col, en_genres_col, en_dir_col])\n",
    "\n",
    "def norm_name(s): return s.astype(str).str.strip().str.lower()\n",
    "def norm_year(s):  return s.astype(str).str.extract(r\"(\\d{4})\", expand=False).fillna(s.astype(str).str.strip())\n",
    "\n",
    "for df_, ncol, ycol in [(watched_df, watched_name_col, watched_year_col),\n",
    "                        (watchlist_df, watch_name_col, watch_year_col),\n",
    "                        (recs_df, recs_name_col, recs_year_col),\n",
    "                        (enriched_df, en_title_col, en_year_col)]:\n",
    "    df_[\"name_norm\"] = norm_name(df_[ncol])\n",
    "    df_[\"year_str\"]  = norm_year(df_[ycol])\n",
    "\n",
    "# parse list-like fields to pure lists of names (strip URLs)\n",
    "def parse_list(cell):\n",
    "    if pd.isna(cell): return []\n",
    "    txt = str(cell)\n",
    "    try:\n",
    "        lst = ast.literal_eval(txt)\n",
    "        out = []\n",
    "        if isinstance(lst, list):\n",
    "            for it in lst:\n",
    "                if isinstance(it, str):\n",
    "                    out.append(it.split(':',1)[0].strip())\n",
    "                else:\n",
    "                    out.append(str(it))\n",
    "        return out\n",
    "    except Exception:\n",
    "        hits = re.findall(r\"'([^':]+):\", txt)\n",
    "        return [h.strip() for h in hits]\n",
    "\n",
    "enriched_df[\"genre_list\"]    = enriched_df[en_genres_col].apply(parse_list)\n",
    "enriched_df[\"director_list\"] = enriched_df[en_dir_col].apply(parse_list)\n",
    "\n",
    "# aggregate metadata per (name_norm, year_str)\n",
    "def set_union(series_of_lists):\n",
    "    s = set()\n",
    "    for lst in series_of_lists:\n",
    "        if isinstance(lst, list):\n",
    "            s.update(lst)\n",
    "        elif pd.isna(lst):\n",
    "            continue\n",
    "        else:\n",
    "            s.add(str(lst))\n",
    "    return sorted(s)\n",
    "\n",
    "agg_meta = (enriched_df\n",
    "            .groupby([\"name_norm\",\"year_str\"], as_index=False)\n",
    "            .agg(genre_list=(\"genre_list\", set_union),\n",
    "                 director_list=(\"director_list\", set_union)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "recs_df = recs_df.merge(agg_meta, on=[\"name_norm\",\"year_str\"], how=\"left\")\n",
    "\n",
    "# force to lists\n",
    "def ensure_list(x):\n",
    "    if isinstance(x, list): return x\n",
    "    if pd.isna(x): return []\n",
    "    return [str(x)]\n",
    "recs_df[\"genre_list\"] = recs_df[\"genre_list\"].apply(ensure_list)\n",
    "recs_df[\"director_list\"] = recs_df[\"director_list\"].apply(ensure_list)\n",
    "\n",
    "watched_pairs   = set(zip(watched_df[\"name_norm\"], watched_df[\"year_str\"]))\n",
    "watchlist_pairs = set(zip(watchlist_df[\"name_norm\"], watchlist_df[\"year_str\"]))\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Fix: populate `genre_list` / `director_list` from `genres` / `director` (names-only)\n",
    "This cell **does not change any other logic**. Run it after your DataFrame(s) are created and before you compute rule flags.\n"
   ],
   "id": "24d3dd1d56724788"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T20:24:30.078294Z",
     "start_time": "2025-09-13T20:24:29.850912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Populate genre_list/director_list from genres/director if they are empty or missing.\n",
    "# This cell auto-detects DataFrames that have those columns and fixes them in-place.\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "\n",
    "def names_only(list_like):\n",
    "    if isinstance(list_like, str):\n",
    "        try:\n",
    "            list_like = literal_eval(list_like)\n",
    "        except Exception:\n",
    "            return []\n",
    "    if not isinstance(list_like, list):\n",
    "        return []\n",
    "    out = []\n",
    "    for item in list_like:\n",
    "        if isinstance(item, str) and \":\" in item:\n",
    "            out.append(item.split(\":\", 1)[0].strip())\n",
    "    return out\n",
    "\n",
    "def coalesce_lists(df: pd.DataFrame, list_col: str, rich_col: str) -> pd.DataFrame:\n",
    "    # Ensure target column exists\n",
    "    if list_col not in df.columns and rich_col in df.columns:\n",
    "        df[list_col] = [[] for _ in range(len(df))]\n",
    "    if rich_col not in df.columns:\n",
    "        return df\n",
    "\n",
    "    def fixer(a, b):\n",
    "        val = a\n",
    "        # normalize existing list_col\n",
    "        if isinstance(val, str):\n",
    "            try:\n",
    "                v = literal_eval(val)\n",
    "                val = v if isinstance(v, list) else []\n",
    "            except Exception:\n",
    "                val = []\n",
    "        if isinstance(val, list) and len(val) > 0:\n",
    "            return val\n",
    "        # build from rich_col\n",
    "        return names_only(b)\n",
    "\n",
    "    df[list_col] = [fixer(a, b) for a, b in zip(df.get(list_col, []), df.get(rich_col, []))]\n",
    "    return df\n",
    "\n",
    "# Auto-detect likely DataFrames to fix\n",
    "_fixed_any = False\n",
    "for _name, _obj in list(globals().items()):\n",
    "    try:\n",
    "        if isinstance(_obj, pd.DataFrame):\n",
    "            cols = set(_obj.columns)\n",
    "            needs_genres   = (\"genres\" in cols) and (\"genre_list\" in cols)\n",
    "            needs_director = (\"director\" in cols) and (\"director_list\" in cols)\n",
    "            if needs_genres or needs_director:\n",
    "                df0 = _obj\n",
    "                if needs_genres:\n",
    "                    df0 = coalesce_lists(df0, \"genre_list\", \"genres\")\n",
    "                if needs_director:\n",
    "                    df0 = coalesce_lists(df0, \"director_list\", \"director\")\n",
    "                globals()[_name] = df0  # write back\n",
    "                print(f\"✅ Fixed genre/director lists in DataFrame: {_name}  (rows={len(df0)})\")\n",
    "                _fixed_any = True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if not _fixed_any:\n",
    "    print(\"ℹ️ No matching DataFrame found (expected columns: genres/director + genre_list/director_list). Run this cell after your DataFrame is created.\")"
   ],
   "id": "63afd562dffb292f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fixed genre/director lists in DataFrame: recs_df  (rows=200)\n",
      "✅ Fixed genre/director lists in DataFrame: enriched_df  (rows=754)\n",
      "✅ Fixed genre/director lists in DataFrame: df  (rows=754)\n",
      "✅ Fixed genre/director lists in DataFrame: df_  (rows=754)\n",
      "✅ Fixed genre/director lists in DataFrame: df0  (rows=754)\n",
      "✅ Fixed genre/director lists in DataFrame: rated  (rows=328)\n",
      "✅ Fixed genre/director lists in DataFrame: genres_long  (rows=844)\n",
      "✅ Fixed genre/director lists in DataFrame: dirs_long  (rows=336)\n",
      "✅ Fixed genre/director lists in DataFrame: out  (rows=200)\n",
      "✅ Fixed genre/director lists in DataFrame: out_sorted  (rows=200)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "b6ff1056",
   "metadata": {},
   "source": [
    "## Preferences (likes/dislikes) from ratings"
   ]
  },
  {
   "cell_type": "code",
   "id": "b76eb766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T20:24:30.159042Z",
     "start_time": "2025-09-13T20:24:30.124874Z"
    }
   },
   "source": [
    "\n",
    "rated = enriched_df.dropna(subset=[en_rating_col]).copy()\n",
    "rmax = rated[en_rating_col].max()\n",
    "scale = 10.0 if rmax > 5 else 5.0\n",
    "like_th = 7.0 if scale == 10.0 else 3.5\n",
    "dislike_th = 3.0 if scale == 10.0 else 2.5\n",
    "min_count = 2\n",
    "\n",
    "genres_long = rated.explode(\"genre_list\").dropna(subset=[\"genre_list\"])\n",
    "dirs_long   = rated.explode(\"director_list\").dropna(subset=[\"director_list\"])\n",
    "\n",
    "g_stats = genres_long.groupby(\"genre_list\")[en_rating_col].agg(['mean','count']).reset_index().rename(columns={'genre_list':'genre'})\n",
    "d_stats = dirs_long.groupby(\"director_list\")[en_rating_col].agg(['mean','count']).reset_index().rename(columns={'director_list':'director'})\n",
    "\n",
    "liked_genres    = set(g_stats[(g_stats['mean']>=like_th)    & (g_stats['count']>=min_count)]['genre'])\n",
    "disliked_genres = set(g_stats[(g_stats['mean']<=dislike_th) & (g_stats['count']>=min_count)]['genre'])\n",
    "liked_dirs      = set(d_stats[(d_stats['mean']>=like_th)    & (d_stats['count']>=min_count)]['director'])\n",
    "disliked_dirs   = set(d_stats[(d_stats['mean']<=dislike_th) & (d_stats['count']>=min_count)]['director'])\n",
    "\n",
    "print(\"Scale:\", scale, \"| like_th:\", like_th, \"| dislike_th:\", dislike_th)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale: 5.0 | like_th: 3.5 | dislike_th: 2.5\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "8c4026da",
   "metadata": {},
   "source": [
    "## Datalog core (only recommended & watchBoost)"
   ]
  },
  {
   "cell_type": "code",
   "id": "d32586e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T20:24:30.611342Z",
     "start_time": "2025-09-13T20:24:30.171136Z"
    }
   },
   "source": [
    "\n",
    "use_pyDatalog = False\n",
    "try:\n",
    "    from pyDatalog import pyDatalog\n",
    "    use_pyDatalog = True\n",
    "    print(\"pyDatalog is available — using it.\")\n",
    "except Exception as e:\n",
    "    print(\"pyDatalog not available, fallback will be used:\", e)\n",
    "\n",
    "USER = \"tobias\"\n",
    "\n",
    "\n",
    "if use_pyDatalog:\n",
    "    pyDatalog.clear()\n",
    "    pyDatalog.create_terms('watched_fact, candidateFor, onWatchlist, '\n",
    "                           'recommendedBase, recommended, watchBoost, U,N,Y')\n",
    "    for n,y in watched_pairs:   +watched_fact(USER,n,y)\n",
    "    for n,y in watchlist_pairs: +onWatchlist(USER,n,y)\n",
    "    for _,row in recs_df.iterrows():\n",
    "        +candidateFor(USER,row[\"name_norm\"],row[\"year_str\"])\n",
    "    recommendedBase(U,N,Y) <= candidateFor(U,N,Y) & ~watched_fact(U,N,Y)\n",
    "    recommended(U,N,Y)     <= recommendedBase(U,N,Y)\n",
    "    watchBoost(U,N,Y)      <= recommendedBase(U,N,Y) & onWatchlist(U,N,Y)\n",
    "\n",
    "    def qset(s):\n",
    "        ans = pyDatalog.ask(s)\n",
    "        return set(tuple(x) for x in (ans.answers if ans else []))\n",
    "\n",
    "    all_pairs   = qset(f'recommended(\"{USER}\", N, Y)')\n",
    "    watch_pairs = qset(f'watchBoost(\"{USER}\", N, Y)')\n",
    "\n",
    "    if all_pairs:\n",
    "        rec_df = pd.DataFrame(list(all_pairs), columns=[\"name_norm\",\"year_str\"])\n",
    "        out = recs_df.merge(rec_df, on=[\"name_norm\",\"year_str\"], how=\"inner\")\n",
    "    else:\n",
    "        out = recs_df.iloc[0:0].copy()\n",
    "\n",
    "    out[\"watchlist_priority\"] = list(map(lambda p: p in watch_pairs, zip(out[\"name_norm\"], out[\"year_str\"])))\n",
    "\n",
    "else:\n",
    "    # Fallback: pure pandas for 'recommended' and 'watchlist'\n",
    "    cand_pairs = list(zip(recs_df[\"name_norm\"], recs_df[\"year_str\"]))\n",
    "    keep_mask = [pair not in watched_pairs for pair in cand_pairs]\n",
    "    out = recs_df.loc[keep_mask].copy()\n",
    "    out[\"watchlist_priority\"] = list(map(lambda p: p in watchlist_pairs, zip(out[\"name_norm\"], out[\"year_str\"])))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyDatalog is available — using it.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "dc187a2a",
   "metadata": {},
   "source": [
    "## Compute boosts/penalties (Python) & Score"
   ]
  },
  {
   "cell_type": "code",
   "id": "e2150f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T20:24:30.640332Z",
     "start_time": "2025-09-13T20:24:30.628650Z"
    }
   },
   "source": [
    "\n",
    "def any_in(candidate_list, prefer_set):\n",
    "    try:\n",
    "        return any(x in prefer_set for x in (candidate_list or []))\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "out[\"genre_boost\"]      = out[\"genre_list\"].apply(lambda lst: any_in(lst, liked_genres))\n",
    "out[\"director_boost\"]   = out[\"director_list\"].apply(lambda lst: any_in(lst, liked_dirs))\n",
    "out[\"genre_penalty\"]    = out[\"genre_list\"].apply(lambda lst: any_in(lst, disliked_genres))\n",
    "out[\"director_penalty\"] = out[\"director_list\"].apply(lambda lst: any_in(lst, disliked_dirs))\n",
    "\n",
    "# Weights\n",
    "w_watch, w_glike, w_dlike, w_gbad, w_dbad = 2, 1, 2, 1, 2\n",
    "out[\"score\"] = (out[\"watchlist_priority\"].astype(int)*w_watch +\n",
    "                out[\"genre_boost\"].astype(int)*w_glike +\n",
    "                out[\"director_boost\"].astype(int)*w_dlike -\n",
    "                out[\"genre_penalty\"].astype(int)*w_gbad -\n",
    "                out[\"director_penalty\"].astype(int)*w_dbad)\n",
    "\n",
    "sort_cols, ascending = [\"score\"], [False]\n",
    "if \"rank\" in out.columns: sort_cols.append(\"rank\"); ascending.append(True)\n",
    "out_sorted = out.sort_values(by=sort_cols, ascending=ascending).reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "ad64c820",
   "metadata": {},
   "source": [
    "## Save & Summary"
   ]
  },
  {
   "cell_type": "code",
   "id": "d366c57f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T20:24:30.694639Z",
     "start_time": "2025-09-13T20:24:30.655357Z"
    }
   },
   "source": [
    "\n",
    "out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_sorted.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv.resolve())\n",
    "\n",
    "summary = {\n",
    "    \"candidates_total\": int(len(recs_df)),\n",
    "    \"recommended_total\": int(len(out_sorted)),\n",
    "    \"watchlist_priority_true\": int(out_sorted[\"watchlist_priority\"].sum()),\n",
    "    \"genre_boost_true\": int(out_sorted[\"genre_boost\"].sum()),\n",
    "    \"director_boost_true\": int(out_sorted[\"director_boost\"].sum()),\n",
    "    \"genre_penalty_true\": int(out_sorted[\"genre_penalty\"].sum()),\n",
    "    \"director_penalty_true\": int(out_sorted[\"director_penalty\"].sum()),\n",
    "    \"top5\": list(out_sorted.head(5).get(\"candidate_title\", out_sorted.head(5).get(\"name\")).astype(str))\n",
    "}\n",
    "summary\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/tschaffel/PycharmProjects/letterboxd-KG/data/kg/rerank_by_logical_rules.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'candidates_total': 200,\n",
       " 'recommended_total': 200,\n",
       " 'watchlist_priority_true': 18,\n",
       " 'genre_boost_true': 200,\n",
       " 'director_boost_true': 8,\n",
       " 'genre_penalty_true': 0,\n",
       " 'director_penalty_true': 3,\n",
       " 'top5': ['The Abyss',\n",
       "  'Death Proof',\n",
       "  'Kicking and Screaming',\n",
       "  \"Don't Look Up\",\n",
       "  'The Talented Mr. Ripley']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "93e70991153b3838",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T20:24:30.727724Z",
     "start_time": "2025-09-13T20:24:30.710098Z"
    }
   },
   "source": [
    "'''\n",
    "The code in the previous cells is in big parts AI generated by the free and paid version of ChatGPT and was afterwards heavily adapted by me. Since it is not possible to accurately say which parts were originaly AI generated by wich promt, I have included all prompts that were used on this file here.\n",
    "These following prompts were used:\n",
    "\n",
    "    \"\"Beispiel: Zeig, dass du mit Regeln ausschließen kannst, dass dir Filme empfohlen werden, die du schon gesehen hast – das ist eine logische Restriktion, kein Embedding-Thema.\" ich würde gern damit beginnen\"\n",
    "\n",
    "    \"ja bitte, mach das. bitte gib das notebook als .ipynb file\"\n",
    "\n",
    "    \"kannst du in dem jupyter notebook datalog für die anwendung der regeln verwenden?\"\n",
    "\n",
    "    \"Ja, Genre und Regisseur Regeln sollen auch noch rein. Dafür sollte ich zuerst erkennen, welche Regisseure und welche Genres in den Daten gut bewertet wurden, oder? Also dafür sollte ich wahrscheinlich mein Ebedding verwenden?\"\n",
    "\n",
    "    \"pyDatalog is available — using it.\n",
    "        ---------------------------------------------------------------------------\n",
    "        AttributeError                            Traceback (most recent call last)\n",
    "        Cell In[6], line 48\n",
    "             46 all_pairs   = qset(f'recommended(\"{USER}\", N, Y)')\n",
    "             47 watch_pairs = qset(f'watchBoost(\"{USER}\", N, Y)')\n",
    "        ---> 48 g_like      = qset(f'genreBoost(\"{USER}\", N, Y)')\n",
    "             49 d_like      = qset(f'dirBoost(\"{USER}\", N, Y)')\n",
    "             50 g_bad       = qset(f'genrePenalty(\"{USER}\", N, Y)')\n",
    "\n",
    "        Cell In[6], line 43, in qset(s)\n",
    "             42 def qset(s):\n",
    "        ---> 43     ans = pyDatalog.ask(s);\n",
    "             44     return set(tuple(x) for x in (ans.answers if ans else []))\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyDatalog.py:111, in ask(code)\n",
    "            109 def ask(code):\n",
    "            110     \"\"\"returns the result of the query contained in the code string\"\"\"\n",
    "        --> 111     return pyParser.ask(code)\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:841, in ask(code)\n",
    "            839 add_symbols(code.co_names, newglobals)\n",
    "            840 parsed_code = eval(code, newglobals)\n",
    "        --> 841 a = parsed_code.ask()\n",
    "            842 return Answer.make(a)\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:577, in Query.ask(self)\n",
    "            576 def ask(self):\n",
    "        --> 577     self._data = Body(self.pre_calculations, self).ask()\n",
    "            578     self.todo = None\n",
    "            579     return self._data\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:693, in Body.ask(self)\n",
    "            691 \"\"\" resolve the query and determine the values of its variables\"\"\"\n",
    "            692 literal = self.literal()\n",
    "        --> 693 self._data = literal.lua.ask()\n",
    "            694 literal.todo, self.todo = None, None\n",
    "            695 - (literal <= self) # delete the temporary clause\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:513, in Literal.ask(self)\n",
    "            511 todo, arg = (SEARCH, (Ts.Goal, ))\n",
    "            512 while todo:\n",
    "        --> 513     todo, arg = todo(*arg)\n",
    "            515 if Ts.Goal.facts is True:\n",
    "            516     return True\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:812, in Subgoal.search(self)\n",
    "            808         raise util.DatalogError(\"Error: right hand side of comparison must be bound: %s\"\n",
    "            809                             % literal.pred.id, None, None)\n",
    "            810     return self.next_step()\n",
    "        --> 812 raise AttributeError(\"Predicate without definition (or error in resolver): %s\" % literal.pred.id)\n",
    "\n",
    "        AttributeError: Predicate without definition (or error in resolver): film_genre/3\"\n",
    "\n",
    "    \"---------------------------------------------------------------------------\n",
    "        NameError                                 Traceback (most recent call last)\n",
    "        Cell In[3], line 5\n",
    "              2 def has_any(lst, S):\n",
    "              3     return any(x in S for x in (lst or []))\n",
    "        ----> 5 recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\n",
    "              6 recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\n",
    "              7 recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/series.py:4924, in Series.apply(self, func, convert_dtype, args, by_row, **kwargs)\n",
    "           4789 def apply(\n",
    "           4790     self,\n",
    "           4791     func: AggFuncType,\n",
    "           (...)   4796     **kwargs,\n",
    "           4797 ) -> DataFrame | Series:\n",
    "           4798     \"\"\"\n",
    "           4799     Invoke function on values of Series.\n",
    "           4800\n",
    "           (...)   4915     dtype: float64\n",
    "           4916     \"\"\"\n",
    "           4917     return SeriesApply(\n",
    "           4918         self,\n",
    "           4919         func,\n",
    "           4920         convert_dtype=convert_dtype,\n",
    "           4921         by_row=by_row,\n",
    "           4922         args=args,\n",
    "           4923         kwargs=kwargs,\n",
    "        -> 4924     ).apply()\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1427, in SeriesApply.apply(self)\n",
    "           1424     return self.apply_compat()\n",
    "           1426 # self.func is Callable\n",
    "        -> 1427 return self.apply_standard()\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1507, in SeriesApply.apply_standard(self)\n",
    "           1501 # row-wise access\n",
    "           1502 # apply doesn't have a na_action keyword and for backward compat reasons\n",
    "           1503 # we need to give na_action=\"ignore\" for categorical data.\n",
    "           1504 # TODO: remove the na_action=\"ignore\" when that default has been changed in\n",
    "           1505 #  Categorical (GH51645).\"\n",
    "\n",
    "    \"---------------------------------------------------------------------------\n",
    "        TypeError                                 Traceback (most recent call last)\n",
    "        Cell In[5], line 5\n",
    "              2 def has_any(lst, S):\n",
    "              3     return any(x in S for x in (lst or []))\n",
    "        ----> 5 recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\n",
    "              6 recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\n",
    "              7 recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/series.py:4924, in Series.apply(self, func, convert_dtype, args, by_row, **kwargs)\n",
    "           4789 def apply(\n",
    "           4790     self,\n",
    "           4791     func: AggFuncType,\n",
    "           (...)   4796     **kwargs,\n",
    "           4797 ) -> DataFrame | Series:\n",
    "           4798     \"\"\"\n",
    "           4799     Invoke function on values of Series.\n",
    "           4800\n",
    "           (...)   4915     dtype: float64\n",
    "           4916     \"\"\"\n",
    "           4917     return SeriesApply(\n",
    "           4918         self,\n",
    "           4919         func,\n",
    "           4920         convert_dtype=convert_dtype,\n",
    "           4921         by_row=by_row,\n",
    "           4922         args=args,\n",
    "           4923         kwargs=kwargs,\n",
    "        -> 4924     ).apply()\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1427, in SeriesApply.apply(self)\n",
    "           1424     return self.apply_compat()\n",
    "           1426 # self.func is Callable\n",
    "        -> 1427 return self.apply_standard()\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1507, in SeriesApply.apply_standard(self)\n",
    "           1501 # row-wise access\n",
    "           1502 # apply doesn't have a na_action keyword and for backward compat reasons\n",
    "           1503 # we need to give na_action=\"ignore\" for categorical data.\n",
    "           1504 # TODO: remove the na_action=\"ignore\" when that default has been changed in\n",
    "           1505 #  Categorical (GH51645).\n",
    "           1506 action = \"ignore\" if isinstance(obj.dtype, CategoricalDtype) else None\n",
    "        -> 1507 mapped = obj._map_values(\n",
    "           1508     mapper=curried, na_action=action, convert=self.convert_dtype\n",
    "           1509 )\n",
    "           1511 if len(mapped) and isinstance(mapped[0], ABCSeries):\n",
    "           1512     # GH#43986 Need to do list(mapped) in order to get treated as nested\n",
    "           1513     #  See also GH#25959 regarding EA support\n",
    "           1514     return obj._constructor_expanddim(list(mapped), index=obj.index)\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/base.py:921, in IndexOpsMixin._map_values(self, mapper, na_action, convert)\n",
    "            918 if isinstance(arr, ExtensionArray):\n",
    "            919     return arr.map(mapper, na_action=na_action)\n",
    "        --> 921 return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/algorithms.py:1743, in map_array(arr, mapper, na_action, convert)\n",
    "           1741 values = arr.astype(object, copy=False)\n",
    "           1742 if na_action is None:\n",
    "        -> 1743     return lib.map_infer(values, mapper, convert=convert)\n",
    "           1744 else:\n",
    "           1745     return lib.map_infer_mask(\n",
    "           1746         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n",
    "           1747     )\n",
    "\n",
    "        File lib.pyx:2972, in pandas._libs.lib.map_infer()\n",
    "\n",
    "        Cell In[5], line 5, in <lambda>(lst)\n",
    "              2 def has_any(lst, S):\n",
    "              3     return any(x in S for x in (lst or []))\n",
    "        ----> 5 recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\n",
    "              6 recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\n",
    "              7 recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\n",
    "\n",
    "        Cell In[5], line 3, in has_any(lst, S)\n",
    "              2 def has_any(lst, S):\n",
    "        ----> 3     return any(x in S for x in (lst or []))\n",
    "\n",
    "        TypeError: 'float' object is not iterable\"\n",
    "\n",
    "    \"---------------------------------------------------------------------------\n",
    "        AttributeError                            Traceback (most recent call last)\n",
    "        Cell In[5], line 41\n",
    "             39 all_pairs   = qset(f'recommended(\"{USER}\", N, Y)')\n",
    "             40 watch_pairs = qset(f'watchBoost(\"{USER}\", N, Y)')\n",
    "        ---> 41 g_like      = qset(f'genreBoost(\"{USER}\", N, Y)')\n",
    "             42 d_like      = qset(f'dirBoost(\"{USER}\", N, Y)')\n",
    "             43 g_bad       = qset(f'genrePenalty(\"{USER}\", N, Y)')\n",
    "\n",
    "        Cell In[5], line 36, in qset(s)\n",
    "             35 def qset(s):\n",
    "        ---> 36     ans = pyDatalog.ask(s)\n",
    "             37     return set(tuple(x) for x in (ans.answers if ans else []))\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyDatalog.py:111, in ask(code)\n",
    "            109 def ask(code):\n",
    "            110     \"\"\"returns the result of the query contained in the code string\"\"\"\n",
    "        --> 111     return pyParser.ask(code)\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:841, in ask(code)\n",
    "            839 add_symbols(code.co_names, newglobals)\n",
    "            840 parsed_code = eval(code, newglobals)\n",
    "        --> 841 a = parsed_code.ask()\n",
    "            842 return Answer.make(a)\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:577, in Query.ask(self)\n",
    "            576 def ask(self):\n",
    "        --> 577     self._data = Body(self.pre_calculations, self).ask()\n",
    "            578     self.todo = None\n",
    "            579     return self._data\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:693, in Body.ask(self)\n",
    "            691 \"\"\" resolve the query and determine the values of its variables\"\"\"\n",
    "            692 literal = self.literal()\n",
    "        --> 693 self._data = literal.lua.ask()\n",
    "            694 literal.todo, self.todo = None, None\n",
    "            695 - (literal <= self) # delete the temporary clause\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:513, in Literal.ask(self)\n",
    "            511 todo, arg = (SEARCH, (Ts.Goal, ))\"\n",
    "\n",
    "'''"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe code in the previous cells is in big parts AI generated by the free and paid version of ChatGPT and was afterwards heavily adapted by me. Since it is not possible to accurately say which parts were originaly AI generated by wich promt, I have included all prompts that were used on this file here.\\nThese following prompts were used:\\n\\n    \"\"Beispiel: Zeig, dass du mit Regeln ausschließen kannst, dass dir Filme empfohlen werden, die du schon gesehen hast – das ist eine logische Restriktion, kein Embedding-Thema.\" ich würde gern damit beginnen\"\\n\\n    \"ja bitte, mach das. bitte gib das notebook als .ipynb file\"\\n\\n    \"kannst du in dem jupyter notebook datalog für die anwendung der regeln verwenden?\"\\n\\n    \"Ja, Genre und Regisseur Regeln sollen auch noch rein. Dafür sollte ich zuerst erkennen, welche Regisseure und welche Genres in den Daten gut bewertet wurden, oder? Also dafür sollte ich wahrscheinlich mein Ebedding verwenden?\"\\n\\n    \"pyDatalog is available — using it.\\n        ---------------------------------------------------------------------------\\n        AttributeError                            Traceback (most recent call last)\\n        Cell In[6], line 48\\n             46 all_pairs   = qset(f\\'recommended(\"{USER}\", N, Y)\\')\\n             47 watch_pairs = qset(f\\'watchBoost(\"{USER}\", N, Y)\\')\\n        ---> 48 g_like      = qset(f\\'genreBoost(\"{USER}\", N, Y)\\')\\n             49 d_like      = qset(f\\'dirBoost(\"{USER}\", N, Y)\\')\\n             50 g_bad       = qset(f\\'genrePenalty(\"{USER}\", N, Y)\\')\\n\\n        Cell In[6], line 43, in qset(s)\\n             42 def qset(s):\\n        ---> 43     ans = pyDatalog.ask(s);\\n             44     return set(tuple(x) for x in (ans.answers if ans else []))\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyDatalog.py:111, in ask(code)\\n            109 def ask(code):\\n            110     \"\"\"returns the result of the query contained in the code string\"\"\"\\n        --> 111     return pyParser.ask(code)\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:841, in ask(code)\\n            839 add_symbols(code.co_names, newglobals)\\n            840 parsed_code = eval(code, newglobals)\\n        --> 841 a = parsed_code.ask()\\n            842 return Answer.make(a)\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:577, in Query.ask(self)\\n            576 def ask(self):\\n        --> 577     self._data = Body(self.pre_calculations, self).ask()\\n            578     self.todo = None\\n            579     return self._data\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:693, in Body.ask(self)\\n            691 \"\"\" resolve the query and determine the values of its variables\"\"\"\\n            692 literal = self.literal()\\n        --> 693 self._data = literal.lua.ask()\\n            694 literal.todo, self.todo = None, None\\n            695 - (literal <= self) # delete the temporary clause\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:513, in Literal.ask(self)\\n            511 todo, arg = (SEARCH, (Ts.Goal, ))\\n            512 while todo:\\n        --> 513     todo, arg = todo(*arg)\\n            515 if Ts.Goal.facts is True:\\n            516     return True\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:812, in Subgoal.search(self)\\n            808         raise util.DatalogError(\"Error: right hand side of comparison must be bound: %s\"\\n            809                             % literal.pred.id, None, None)\\n            810     return self.next_step()\\n        --> 812 raise AttributeError(\"Predicate without definition (or error in resolver): %s\" % literal.pred.id)\\n\\n        AttributeError: Predicate without definition (or error in resolver): film_genre/3\"\\n\\n    \"---------------------------------------------------------------------------\\n        NameError                                 Traceback (most recent call last)\\n        Cell In[3], line 5\\n              2 def has_any(lst, S):\\n              3     return any(x in S for x in (lst or []))\\n        ----> 5 recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\\n              6 recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\\n              7 recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/series.py:4924, in Series.apply(self, func, convert_dtype, args, by_row, **kwargs)\\n           4789 def apply(\\n           4790     self,\\n           4791     func: AggFuncType,\\n           (...)   4796     **kwargs,\\n           4797 ) -> DataFrame | Series:\\n           4798     \"\"\"\\n           4799     Invoke function on values of Series.\\n           4800\\n           (...)   4915     dtype: float64\\n           4916     \"\"\"\\n           4917     return SeriesApply(\\n           4918         self,\\n           4919         func,\\n           4920         convert_dtype=convert_dtype,\\n           4921         by_row=by_row,\\n           4922         args=args,\\n           4923         kwargs=kwargs,\\n        -> 4924     ).apply()\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1427, in SeriesApply.apply(self)\\n           1424     return self.apply_compat()\\n           1426 # self.func is Callable\\n        -> 1427 return self.apply_standard()\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1507, in SeriesApply.apply_standard(self)\\n           1501 # row-wise access\\n           1502 # apply doesn\\'t have a na_action keyword and for backward compat reasons\\n           1503 # we need to give na_action=\"ignore\" for categorical data.\\n           1504 # TODO: remove the na_action=\"ignore\" when that default has been changed in\\n           1505 #  Categorical (GH51645).\"\\n\\n    \"---------------------------------------------------------------------------\\n        TypeError                                 Traceback (most recent call last)\\n        Cell In[5], line 5\\n              2 def has_any(lst, S):\\n              3     return any(x in S for x in (lst or []))\\n        ----> 5 recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\\n              6 recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\\n              7 recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/series.py:4924, in Series.apply(self, func, convert_dtype, args, by_row, **kwargs)\\n           4789 def apply(\\n           4790     self,\\n           4791     func: AggFuncType,\\n           (...)   4796     **kwargs,\\n           4797 ) -> DataFrame | Series:\\n           4798     \"\"\"\\n           4799     Invoke function on values of Series.\\n           4800\\n           (...)   4915     dtype: float64\\n           4916     \"\"\"\\n           4917     return SeriesApply(\\n           4918         self,\\n           4919         func,\\n           4920         convert_dtype=convert_dtype,\\n           4921         by_row=by_row,\\n           4922         args=args,\\n           4923         kwargs=kwargs,\\n        -> 4924     ).apply()\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1427, in SeriesApply.apply(self)\\n           1424     return self.apply_compat()\\n           1426 # self.func is Callable\\n        -> 1427 return self.apply_standard()\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1507, in SeriesApply.apply_standard(self)\\n           1501 # row-wise access\\n           1502 # apply doesn\\'t have a na_action keyword and for backward compat reasons\\n           1503 # we need to give na_action=\"ignore\" for categorical data.\\n           1504 # TODO: remove the na_action=\"ignore\" when that default has been changed in\\n           1505 #  Categorical (GH51645).\\n           1506 action = \"ignore\" if isinstance(obj.dtype, CategoricalDtype) else None\\n        -> 1507 mapped = obj._map_values(\\n           1508     mapper=curried, na_action=action, convert=self.convert_dtype\\n           1509 )\\n           1511 if len(mapped) and isinstance(mapped[0], ABCSeries):\\n           1512     # GH#43986 Need to do list(mapped) in order to get treated as nested\\n           1513     #  See also GH#25959 regarding EA support\\n           1514     return obj._constructor_expanddim(list(mapped), index=obj.index)\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/base.py:921, in IndexOpsMixin._map_values(self, mapper, na_action, convert)\\n            918 if isinstance(arr, ExtensionArray):\\n            919     return arr.map(mapper, na_action=na_action)\\n        --> 921 return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/algorithms.py:1743, in map_array(arr, mapper, na_action, convert)\\n           1741 values = arr.astype(object, copy=False)\\n           1742 if na_action is None:\\n        -> 1743     return lib.map_infer(values, mapper, convert=convert)\\n           1744 else:\\n           1745     return lib.map_infer_mask(\\n           1746         values, mapper, mask=isna(values).view(np.uint8), convert=convert\\n           1747     )\\n\\n        File lib.pyx:2972, in pandas._libs.lib.map_infer()\\n\\n        Cell In[5], line 5, in <lambda>(lst)\\n              2 def has_any(lst, S):\\n              3     return any(x in S for x in (lst or []))\\n        ----> 5 recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\\n              6 recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\\n              7 recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\\n\\n        Cell In[5], line 3, in has_any(lst, S)\\n              2 def has_any(lst, S):\\n        ----> 3     return any(x in S for x in (lst or []))\\n\\n        TypeError: \\'float\\' object is not iterable\"\\n\\n    \"---------------------------------------------------------------------------\\n        AttributeError                            Traceback (most recent call last)\\n        Cell In[5], line 41\\n             39 all_pairs   = qset(f\\'recommended(\"{USER}\", N, Y)\\')\\n             40 watch_pairs = qset(f\\'watchBoost(\"{USER}\", N, Y)\\')\\n        ---> 41 g_like      = qset(f\\'genreBoost(\"{USER}\", N, Y)\\')\\n             42 d_like      = qset(f\\'dirBoost(\"{USER}\", N, Y)\\')\\n             43 g_bad       = qset(f\\'genrePenalty(\"{USER}\", N, Y)\\')\\n\\n        Cell In[5], line 36, in qset(s)\\n             35 def qset(s):\\n        ---> 36     ans = pyDatalog.ask(s)\\n             37     return set(tuple(x) for x in (ans.answers if ans else []))\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyDatalog.py:111, in ask(code)\\n            109 def ask(code):\\n            110     \"\"\"returns the result of the query contained in the code string\"\"\"\\n        --> 111     return pyParser.ask(code)\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:841, in ask(code)\\n            839 add_symbols(code.co_names, newglobals)\\n            840 parsed_code = eval(code, newglobals)\\n        --> 841 a = parsed_code.ask()\\n            842 return Answer.make(a)\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:577, in Query.ask(self)\\n            576 def ask(self):\\n        --> 577     self._data = Body(self.pre_calculations, self).ask()\\n            578     self.todo = None\\n            579     return self._data\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:693, in Body.ask(self)\\n            691 \"\"\" resolve the query and determine the values of its variables\"\"\"\\n            692 literal = self.literal()\\n        --> 693 self._data = literal.lua.ask()\\n            694 literal.todo, self.todo = None, None\\n            695 - (literal <= self) # delete the temporary clause\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:513, in Literal.ask(self)\\n            511 todo, arg = (SEARCH, (Ts.Goal, ))\"\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
