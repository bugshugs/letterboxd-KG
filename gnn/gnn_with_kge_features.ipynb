{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Induktiver Hetero-GNN **mit KGE-Embeddings als Features** (Movies/Persons/Users) + Kanten-Embeddings (optional)\n",
    "\n",
    "**Ziel:** Für neue Filme ohne `schema:review` / `ex:liked` Kanten Vorhersagen erzeugen und als Triples exportieren.\n",
    "\n",
    "**Was dieses Notebook macht**\n",
    "1. Lädt `movie_kg_triples.tsv` (head, rel, tail).\n",
    "2. Lädt **entity_embeddings.csv** (Pfad: `../data/kg/embeddings/`; Fallback: Upload).\n",
    "3. (Optional) Lädt **relation_embeddings.csv** und fügt diese als `edge_attr` pro Kanten-Typ hinzu.\n",
    "4. Baut einen **heterogenen Graphen** (User/Movie/Person) in **PyTorch Geometric**.\n",
    "5. Erzeugt Node-Features: **KGE-Embedding** (wenn vorhanden) **⊕** **Metadaten-Fallback** (Jahr/Runtime/Popularität/Sprache).\n",
    "6. Trainiert **GraphSAGE** + Edge-Head (**Regression**: Rating in [0,5] *oder* **Klassifikation**: liked).\n",
    "7. Inferenz: Scoring für **neue** Filme (ohne persönliche Review-Kante).\n",
    "8. Export: `ex:predictedReview` (Regression) oder `ex:liked` (Klassifikation) als Triples (auskommentiert; Backup empfohlen).\n"
   ],
   "id": "76f744bf84532f97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:14:39.312545Z",
     "start_time": "2025-09-16T21:14:35.701881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Optional: Installation (falls lokal ausgeführt, in Colab/virtualenv)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.2.0+cpu.html\n",
    "!pip install pandas numpy scikit-learn tqdm python-dotenv"
   ],
   "id": "934618d6d0d4e3fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\r\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (2.8.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.13/site-packages (0.23.0)\r\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.13/site-packages (2.8.0)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (4.14.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.3.2)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (2.1.3)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (11.1.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cpu.html\r\n",
      "Requirement already satisfied: torch-geometric in /opt/anaconda3/lib/python3.13/site-packages (2.6.1)\r\n",
      "Requirement already satisfied: torch-scatter in /opt/anaconda3/lib/python3.13/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: torch-sparse in /opt/anaconda3/lib/python3.13/site-packages (0.6.18)\r\n",
      "Requirement already satisfied: torch-cluster in /opt/anaconda3/lib/python3.13/site-packages (1.6.3)\r\n",
      "Requirement already satisfied: torch-spline-conv in /opt/anaconda3/lib/python3.13/site-packages (1.2.2)\r\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (3.11.10)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (2025.3.2)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (3.1.6)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (2.1.3)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (5.9.0)\r\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (3.2.0)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (4.67.1)\r\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from torch-sparse) (1.15.3)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (2.4.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (1.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (24.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (1.18.0)\r\n",
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch-geometric) (3.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch-geometric) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->torch-geometric) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->torch-geometric) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->torch-geometric) (2025.7.14)\r\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (2.1.3)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (1.6.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (4.67.1)\r\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.13/site-packages (1.1.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1) Imports, Pfade & Konfiguration",
   "id": "20fb059a3b1d4467"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:14:43.025972Z",
     "start_time": "2025-09-16T21:14:39.320703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, re, math\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    from torch_geometric.data import HeteroData\n",
    "    from torch_geometric.nn import HeteroConv, SAGEConv, Linear\n",
    "    pyg_available = True\n",
    "    print(\"PyTorch Geometric available.\")\n",
    "except Exception as e:\n",
    "    pyg_available = False\n",
    "    print(\"PyG not available in this env. You can still inspect/export this notebook; run it locally with PyG installed.\")\n",
    "\n",
    "# ---- Konfiguration ----\n",
    "# Pfade (passe an, falls nötig)\n",
    "KG_PATH = Path(\"../data/kg/triples/movie_kg_triples.tsv\")\n",
    "EMB_DIR = Path(\"../data/kg/embeddings\")\n",
    "ENTITY_EMB_PATHS = [EMB_DIR / \"entity_embeddings.csv\", Path(\"/mnt/data/entity_embeddings.csv\")]\n",
    "REL_EMB_PATHS    = [EMB_DIR / \"relation_embeddings.csv\", Path(\"/mnt/data/relation_embeddings.csv\")]\n",
    "\n",
    "# Trainingsmodus für den Edge-Head: 'regression' (Rating 0..5) oder 'classification' (Liked)\n",
    "HEAD_MODE = 'regression'   # 'regression' | 'classification'\n",
    "LIKED_THRESHOLD = 4.0      # nur relevant für Klassifikation -> Label = 1, wenn personal5 >= TH\n",
    "\n",
    "# Inferenz/Export\n",
    "TOPK_EXPORT = 100          # wie viele Vorhersagen exportieren\n",
    "EXPORT_MODE = 'predictedReview'  # 'predictedReview' | 'liked'"
   ],
   "id": "7ce99daf24137d2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Geometric available.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2) Daten laden: Triples & Embeddings",
   "id": "dec26469c65c6c51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:14:43.452936Z",
     "start_time": "2025-09-16T21:14:43.127588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KG laden\n",
    "if not KG_PATH.exists() and Path(\"../data/kg/triples/movie_kg_triples.tsv\").exists():\n",
    "    KG_PATH = Path(\"../data/kg/triples/movie_kg_triples.tsv\")\n",
    "\n",
    "triples = pd.read_csv(KG_PATH, sep=\"\\t\", header=None, names=[\"head\",\"rel\",\"tail\"])\n",
    "print(\"Triples loaded:\", len(triples))\n",
    "display(triples.head(5))\n",
    "\n",
    "def first_existing(paths):\n",
    "    for p in paths:\n",
    "        if Path(p).exists():\n",
    "            return Path(p)\n",
    "    return None\n",
    "\n",
    "ent_path = first_existing(ENTITY_EMB_PATHS)\n",
    "rel_path = first_existing(REL_EMB_PATHS)\n",
    "\n",
    "print(\"Entity embeddings:\", ent_path if ent_path else \"NOT FOUND\")\n",
    "print(\"Relation embeddings:\", rel_path if rel_path else \"NOT FOUND\")\n",
    "\n",
    "# Entity-Embeddings lesen (flexibles Schema: 'entity' oder 'id' + numerische Spalten)\n",
    "entity_emb = None\n",
    "ent_id_col = None\n",
    "if ent_path:\n",
    "    tmp = pd.read_csv(ent_path)\n",
    "    if \"entity\" in tmp.columns:\n",
    "        ent_id_col = \"entity\"\n",
    "    elif \"id\" in tmp.columns:\n",
    "        ent_id_col = \"id\"\n",
    "    else:\n",
    "        ent_id_col = tmp.columns[0]\n",
    "    # nur numerische Spalten als Vektor\n",
    "    vec_cols = [c for c in tmp.columns if c != ent_id_col]\n",
    "    for c in vec_cols: tmp[c] = pd.to_numeric(tmp[c], errors=\"coerce\")\n",
    "    vec_cols = [c for c in vec_cols if tmp[c].notna().any()]\n",
    "    entity_emb = tmp[[ent_id_col] + vec_cols].dropna()\n",
    "    print(f\"Loaded entity embeddings: {entity_emb.shape[0]} entities, dim={len(vec_cols)}\")\n",
    "else:\n",
    "    print(\"No entity embeddings available; will use metadata-only features for all nodes.\")\n",
    "\n",
    "# Relation-Embeddings (optional)\n",
    "relation_emb = None\n",
    "rel_key_col = None\n",
    "if rel_path:\n",
    "    tmp = pd.read_csv(rel_path)\n",
    "    if \"relation\" in tmp.columns:\n",
    "        rel_key_col = \"relation\"\n",
    "    elif \"rel\" in tmp.columns:\n",
    "        rel_key_col = \"rel\"\n",
    "    else:\n",
    "        rel_key_col = tmp.columns[0]\n",
    "    rvec_cols = [c for c in tmp.columns if c != rel_key_col]\n",
    "    for c in rvec_cols: tmp[c] = pd.to_numeric(tmp[c], errors=\"coerce\")\n",
    "    rvec_cols = [c for c in rvec_cols if tmp[c].notna().any()]\n",
    "    relation_emb = tmp[[rel_key_col] + rvec_cols].dropna()\n",
    "    print(f\"Loaded relation embeddings: {relation_emb.shape[0]} relations, dim={len(rvec_cols)}\")\n",
    "else:\n",
    "    print(\"No relation embeddings; edge_attr will be empty (the model still works).\")\n"
   ],
   "id": "1179e5533d0bfaa5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triples loaded: 87266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          head                     rel              tail\n",
       "0  movie452522                rdf:type      schema:Movie\n",
       "1  movie452522             schema:name        Twin Peaks\n",
       "2  movie452522    schema:datePublished    published_1989\n",
       "3  movie452522  schema:aggregateRating       avgVote_8.4\n",
       "4  movie452522           schema:review  personalVote_5.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>rel</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie452522</td>\n",
       "      <td>rdf:type</td>\n",
       "      <td>schema:Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie452522</td>\n",
       "      <td>schema:name</td>\n",
       "      <td>Twin Peaks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie452522</td>\n",
       "      <td>schema:datePublished</td>\n",
       "      <td>published_1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie452522</td>\n",
       "      <td>schema:aggregateRating</td>\n",
       "      <td>avgVote_8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie452522</td>\n",
       "      <td>schema:review</td>\n",
       "      <td>personalVote_5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity embeddings: ../data/kg/embeddings/entity_embeddings.csv\n",
      "Relation embeddings: ../data/kg/embeddings/relation_embeddings.csv\n",
      "Loaded entity embeddings: 19834 entities, dim=50\n",
      "Loaded relation embeddings: 21 relations, dim=50\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3) Knoten/Attribute ableiten & Feature-Fallbacks",
   "id": "c291b9bc0fa2ac62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:14:43.601840Z",
     "start_time": "2025-09-16T21:14:43.462362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parser\n",
    "def extract_year(s):\n",
    "    if pd.isna(s): return None\n",
    "    m = re.search(r\"(19|20)\\d{2}\", str(s))\n",
    "    return int(m.group(0)) if m else None\n",
    "\n",
    "def extract_float_token(s, key_prefix):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return None\n",
    "    m = re.search(rf\"{re.escape(key_prefix)}[_:\\s]*([0-9]+(?:[.,][0-9]+)?)\", str(s), flags=re.I)\n",
    "    if m: return float(m.group(1).replace(\",\", \".\"))\n",
    "    return None\n",
    "\n",
    "def extract_personal_review(s):  # 0..5\n",
    "    return extract_float_token(s, \"personalVote\")\n",
    "\n",
    "def extract_avg_vote(s):         # 0..10\n",
    "    return extract_float_token(s, \"avgVote\")\n",
    "\n",
    "# Movies\n",
    "#movie_ids = set(triples.loc[(triples.rel==\"rdf:type\") & (triples.tail==\"schema:Movie\"), \"head\"].astype(str))\n",
    "\n",
    "# 1) Normalisierung\n",
    "triples[\"rel_norm\"]  = triples[\"rel\"].str.strip().str.lower()\n",
    "triples[\"tail_norm\"] = triples[\"tail\"].str.strip().str.lower()\n",
    "\n",
    "# 2) Erkenne Typ-Tripel in mehreren Varianten\n",
    "type_aliases = {\"rdf:type\", \"a\", \"type\", \"schema:type\", \"@type\"}\n",
    "movie_aliases = {\n",
    "    \"schema:movie\", \"movie\",\n",
    "    \"http://schema.org/movie\", \"https://schema.org/movie\", \"schema.org/movie\"\n",
    "}\n",
    "\n",
    "type_mask  = triples[\"rel_norm\"].isin(type_aliases)\n",
    "movie_mask = triples[\"tail_norm\"].isin(movie_aliases)\n",
    "movie_ids_1 = set(triples.loc[type_mask & movie_mask, \"head\"])\n",
    "\n",
    "# 3) Fallback: Knoten, die typische Movie-Attribute tragen\n",
    "movie_like_rels = {\n",
    "    \"schema:director\",\"schema:actor\",\"schema:aggregaterating\",\"schema:datepublished\",\n",
    "    \"schema:duration\",\"schema:genre\",\"ex:originallanguage\",\"ex:popularity\", # \"schema:name\"\n",
    "}\n",
    "movie_ids_2 = set(triples.loc[triples[\"rel_norm\"].isin(movie_like_rels), \"head\"])\n",
    "\n",
    "# 4) Optional: Präfix-Heuristik (falls du tmdb-IDs nutzt)\n",
    "movie_ids_3 = set(triples.loc[triples[\"head\"].str.startswith(\"tmdbmovie\", na=False), \"head\"])\n",
    "\n",
    "movie_ids = movie_ids_1 | movie_ids_2 | movie_ids_3\n",
    "print(\"Movies erkannt:\", len(movie_ids))\n",
    "\n",
    "name_map = triples[triples.rel==\"schema:name\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "year_map = triples[triples.rel==\"schema:datePublished\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "avg_map  = triples[triples.rel==\"schema:aggregateRating\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "rev_map  = triples[triples.rel==\"schema:review\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "dur_map  = triples[triples.rel==\"schema:duration\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "lang_map = triples[triples.rel==\"ex:originalLanguage\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "pop_map  = triples[triples.rel==\"ex:popularity\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "\n",
    "rows = []\n",
    "for mid in movie_ids:\n",
    "    title = name_map.get(mid)\n",
    "    year = extract_year(year_map.get(mid))\n",
    "    personal5 = extract_personal_review(rev_map.get(mid))\n",
    "    avg10 = extract_avg_vote(avg_map.get(mid))\n",
    "    runtime = None\n",
    "    if mid in dur_map:\n",
    "        m = re.search(r\"(\\d+)\", str(dur_map[mid]))\n",
    "        runtime = int(m.group(1)) if m else None\n",
    "    lang = lang_map.get(mid)\n",
    "    pop = None\n",
    "    if mid in pop_map:\n",
    "        m = re.search(r\"([0-9]+(?:[.,][0-9]+)?)\", str(pop_map[mid]))\n",
    "        if m: pop = float(m.group(1).replace(\",\",\".\"))\n",
    "    rows.append({\"movie_id\": mid, \"title\": title, \"year\": year, \"personal5\": personal5, \"avg10\": avg10,\n",
    "                 \"runtime\": runtime, \"language\": lang, \"pop\": pop})\n",
    "movie_tbl = pd.DataFrame(rows)\n",
    "\n",
    "# Directors / Actors\n",
    "dir_edges = triples[triples.rel==\"schema:director\"][[\"head\",\"tail\"]].astype(str).values.tolist()\n",
    "act_edges = triples[triples.rel==\"schema:actor\"][[\"head\",\"tail\"]].astype(str).values.tolist()\n",
    "person_ids = set([t for _,t in dir_edges+act_edges])\n",
    "\n",
    "# Users\n",
    "has_user_nodes = (triples[\"head\"].str.startswith(\"user\").any()) or (triples[\"tail\"].str.startswith(\"user\").any())\n",
    "user_ids = set(triples.loc[triples[\"head\"].str.startswith(\"user\"), \"head\"].astype(str)) if has_user_nodes else {\"user0\"}\n",
    "\n",
    "# Ratings als (User -> Movie) mit Label 0..5\n",
    "rated_src, rated_dst, rated_y = [], [], []\n",
    "for _, row in movie_tbl.dropna(subset=[\"personal5\"]).iterrows():\n",
    "    rated_src.append(next(iter(user_ids)))   # erster/only user\n",
    "    rated_dst.append(row[\"movie_id\"])\n",
    "    rated_y.append(float(row[\"personal5\"]))\n",
    "\n",
    "print(\"Movies:\", len(movie_tbl), \"| Persons:\", len(person_ids), \"| Users:\", len(user_ids), \"| Rated edges:\", len(rated_y))\n",
    "display(movie_tbl.head(5))"
   ],
   "id": "4574cf3e4c341de3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies erkannt: 1328\n",
      "Movies: 1328 | Persons: 8677 | Users: 1 | Rated edges: 297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      movie_id                                        title  year  personal5  \\\n",
       "0   movie57158          The Hobbit: The Desolation of Smaug  2013        NaN   \n",
       "1  movie338952  Fantastic Beasts: The Crimes of Grindelwald  2018        NaN   \n",
       "2  movie252512                            While We're Young  2015        NaN   \n",
       "3  movie400160       The SpongeBob Movie: Sponge on the Run  2020        NaN   \n",
       "4  movie321697                                   Steve Jobs  2015        4.5   \n",
       "\n",
       "   avg10  runtime language      pop  \n",
       "0  7.572    161.0       en  15.2920  \n",
       "1  6.842    134.0       en   5.3420  \n",
       "2  6.000     97.0       en   1.2091  \n",
       "3  7.400     95.0       en   5.2927  \n",
       "4  6.800    122.0       en   2.0536  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>personal5</th>\n",
       "      <th>avg10</th>\n",
       "      <th>runtime</th>\n",
       "      <th>language</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie57158</td>\n",
       "      <td>The Hobbit: The Desolation of Smaug</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.572</td>\n",
       "      <td>161.0</td>\n",
       "      <td>en</td>\n",
       "      <td>15.2920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie338952</td>\n",
       "      <td>Fantastic Beasts: The Crimes of Grindelwald</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.842</td>\n",
       "      <td>134.0</td>\n",
       "      <td>en</td>\n",
       "      <td>5.3420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie252512</td>\n",
       "      <td>While We're Young</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000</td>\n",
       "      <td>97.0</td>\n",
       "      <td>en</td>\n",
       "      <td>1.2091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie400160</td>\n",
       "      <td>The SpongeBob Movie: Sponge on the Run</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.400</td>\n",
       "      <td>95.0</td>\n",
       "      <td>en</td>\n",
       "      <td>5.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie321697</td>\n",
       "      <td>Steve Jobs</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.800</td>\n",
       "      <td>122.0</td>\n",
       "      <td>en</td>\n",
       "      <td>2.0536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4) ID-Mappings & relationale Kanten (edge_attr via relation_embeddings)",
   "id": "7ab9f2f0458d834c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:14:43.638223Z",
     "start_time": "2025-09-16T21:14:43.609853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_idmap(ids):\n",
    "    ids = sorted(list(ids))\n",
    "    return {k:i for i,k in enumerate(ids)}, ids\n",
    "\n",
    "movie_id2idx, movie_idx2id = build_idmap(movie_ids)\n",
    "person_id2idx, person_idx2id = build_idmap(person_ids)\n",
    "user_id2idx, user_idx2id = build_idmap(user_ids)\n",
    "\n",
    "import numpy as np\n",
    "def edge_index_from_pairs(pairs, src_map, dst_map):\n",
    "    idx = [[src_map[h], dst_map[t]] for h,t in pairs if h in src_map and t in dst_map]\n",
    "    if len(idx)==0:\n",
    "        return np.zeros((2,0), dtype=int)\n",
    "    return np.array(idx, dtype=int).T\n",
    "\n",
    "dir_edge_index = edge_index_from_pairs(dir_edges, movie_id2idx, person_id2idx)\n",
    "act_edge_index = edge_index_from_pairs(act_edges, movie_id2idx, person_id2idx)\n",
    "rated_edge_index = edge_index_from_pairs(list(zip(rated_src, rated_dst)), user_id2idx, movie_id2idx)\n",
    "rated_y = np.array(rated_y, dtype=float)\n",
    "\n",
    "print(\"edge_index shapes -> dir:\", dir_edge_index.shape, \"| act:\", act_edge_index.shape, \"| rated:\", rated_edge_index.shape)\n",
    "\n",
    "# Edge-Attr pro Rel-Typ (gleicher Vektor für alle Kanten dieser Relation)\n",
    "edge_attr = {}\n",
    "if relation_emb is not None:\n",
    "    rkey = relation_emb.columns[0]\n",
    "    rvec_cols = relation_emb.columns[1:]\n",
    "    rel2vec = {row[rkey]: row[rvec_cols].values.astype(np.float32) for _,row in relation_emb.iterrows()}\n",
    "    def make_edge_attr(num_edges, rel_name):\n",
    "        if rel_name in rel2vec and num_edges>0:\n",
    "            vec = rel2vec[rel_name]\n",
    "            return np.tile(vec, (num_edges,1))\n",
    "        return None\n",
    "    edge_attr[('Movie','hasDirector','Person')] = make_edge_attr(dir_edge_index.shape[1], 'schema:director')\n",
    "    edge_attr[('Movie','hasActor','Person')]    = make_edge_attr(act_edge_index.shape[1], 'schema:actor')\n",
    "    edge_attr[('User','rated','Movie')]         = make_edge_attr(rated_edge_index.shape[1], 'schema:review')\n",
    "else:\n",
    "    edge_attr = { }"
   ],
   "id": "8bd5ff859812ec54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index shapes -> dir: (2, 1624) | act: (2, 13334) | rated: (2, 297)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5) Node-Features = **KGE-Entity-Embedding** ⊕ **Metadaten-Fallback**",
   "id": "4a0bf32b71d9471f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:14:45.417770Z",
     "start_time": "2025-09-16T21:14:43.702736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5.1 Metadaten-Vektoren (Fallback)\n",
    "def norm_col(x):\n",
    "    x = x.astype(float)\n",
    "    mn, mx = np.nanmin(x), np.nanmax(x)\n",
    "    if not np.isfinite(mn) or not np.isfinite(mx) or mx==mn:\n",
    "        return np.zeros_like(x, dtype=float)\n",
    "    y = (x - mn) / (mx - mn)\n",
    "    y[np.isnan(y)] = 0.0\n",
    "    return y\n",
    "\n",
    "mt = movie_tbl.set_index(\"movie_id\").reindex(movie_idx2id)\n",
    "year_feat    = norm_col(mt[\"year\"].fillna(mt[\"year\"].median()).values)\n",
    "runtime_feat = norm_col(mt[\"runtime\"].fillna(mt[\"runtime\"].median()).values)\n",
    "pop_feat     = norm_col(mt[\"pop\"].fillna(mt[\"pop\"].median()).values)\n",
    "\n",
    "lang_series = mt[\"language\"].fillna(\"unknown\").astype(str)\n",
    "top_langs = [l for l,_ in Counter(lang_series).most_common(8)]\n",
    "lang_feat = np.stack([ (lang_series==L).astype(float).values for L in top_langs ], axis=1) if len(top_langs)>0 else np.zeros((len(mt),0))\n",
    "\n",
    "meta_movie = np.stack([year_feat, runtime_feat, pop_feat], axis=1)\n",
    "if lang_feat.shape[1] > 0:\n",
    "    meta_movie = np.concatenate([meta_movie, lang_feat], axis=1)\n",
    "\n",
    "meta_person = np.zeros((len(person_idx2id), max(4, meta_movie.shape[1]//2)), dtype=float)\n",
    "meta_user   = np.zeros((len(user_idx2id),   max(4, meta_movie.shape[1]//2)), dtype=float)\n",
    "\n",
    "# 5.2 KGE-Entity-Embeddings mappen (falls vorhanden)\n",
    "def build_entity_lookup(df, id_col):\n",
    "    return {str(row[id_col]): row.drop(labels=[id_col]).to_numpy(dtype=np.float32) for _,row in df.iterrows()}\n",
    "\n",
    "entity_lookup = build_entity_lookup(entity_emb, entity_emb.columns[0]) if entity_emb is not None else {}\n",
    "\n",
    "def stack_features(ids_list, meta_fallback):\n",
    "    X = []\n",
    "    for i, node_id in enumerate(ids_list):\n",
    "        vec = entity_lookup.get(str(node_id))\n",
    "        if vec is not None:\n",
    "            # concat: [entity_emb ⊕ meta_fallback[i]]\n",
    "            v = np.concatenate([vec, meta_fallback[i]], axis=0)\n",
    "        else:\n",
    "            v = meta_fallback[i]\n",
    "        X.append(v.astype(np.float32))\n",
    "    # pad to common dim\n",
    "    maxd = max(x.shape[0] for x in X) if X else 0\n",
    "    Xp = np.zeros((len(X), maxd), dtype=np.float32)\n",
    "    for i,x in enumerate(X):\n",
    "        Xp[i,:x.shape[0]] = x\n",
    "    return Xp\n",
    "\n",
    "movie_x  = stack_features(movie_idx2id,  meta_movie)\n",
    "person_x = stack_features(person_idx2id, meta_person)\n",
    "user_x   = stack_features(user_idx2id,   meta_user)\n",
    "\n",
    "print(\"movie_x:\", movie_x.shape, \"| person_x:\", person_x.shape, \"| user_x:\", user_x.shape)\n"
   ],
   "id": "81ba8d0f1da052ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_x: (1328, 61) | person_x: (8677, 55) | user_x: (1, 5)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6) HeteroData in PyG",
   "id": "8ea13426e64197f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:14:45.511874Z",
     "start_time": "2025-09-16T21:14:45.491574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not pyg_available:\n",
    "    raise RuntimeError(\"PyG nicht verfügbar. Bitte lokal mit installiertem torch_geometric ausführen.\")\n",
    "\n",
    "data = HeteroData()\n",
    "data['Movie'].x  = torch.tensor(movie_x, dtype=torch.float)\n",
    "data['Person'].x = torch.tensor(person_x, dtype=torch.float)\n",
    "data['User'].x   = torch.tensor(user_x, dtype=torch.float)\n",
    "\n",
    "# Edge indices\n",
    "data[('Movie','hasDirector','Person')].edge_index = torch.tensor(dir_edge_index, dtype=torch.long)\n",
    "data[('Movie','hasActor','Person')].edge_index    = torch.tensor(act_edge_index, dtype=torch.long)\n",
    "data[('User','rated','Movie')].edge_index         = torch.tensor(rated_edge_index, dtype=torch.long)\n",
    "if rated_edge_index.shape[1] > 0:\n",
    "    data[('User','rated','Movie')].edge_label = torch.tensor(rated_y, dtype=torch.float)\n",
    "\n",
    "# Edge attributes (relation embeddings), wenn vorhanden\n",
    "for key, ea in edge_attr.items():\n",
    "    if ea is not None:\n",
    "        data[key].edge_attr = torch.tensor(ea, dtype=torch.float)\n",
    "\n",
    "print(data)"
   ],
   "id": "c83edc78bba427bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  Movie={ x=[1328, 61] },\n",
      "  Person={ x=[8677, 55] },\n",
      "  User={ x=[1, 5] },\n",
      "  (Movie, hasDirector, Person)={\n",
      "    edge_index=[2, 1624],\n",
      "    edge_attr=[1624, 50],\n",
      "  },\n",
      "  (Movie, hasActor, Person)={\n",
      "    edge_index=[2, 13334],\n",
      "    edge_attr=[13334, 50],\n",
      "  },\n",
      "  (User, rated, Movie)={\n",
      "    edge_index=[2, 297],\n",
      "    edge_label=[297],\n",
      "    edge_attr=[297, 50],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7) Train/Val/Test Split über vorhandene `rated`-Kanten",
   "id": "4fe61c51098a3929"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:14:45.588928Z",
     "start_time": "2025-09-16T21:14:45.547394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if data[('User','rated','Movie')].edge_index.numel() > 0:\n",
    "    E = data[('User','rated','Movie')].edge_index.shape[1]\n",
    "    idx = np.arange(E)\n",
    "    train_idx, test_idx = train_test_split(idx, test_size=0.2, random_state=42)\n",
    "    train_idx, val_idx  = train_test_split(train_idx, test_size=0.2, random_state=42)\n",
    "\n",
    "    for split, ids in [('train',train_idx),('val',val_idx),('test',test_idx)]:\n",
    "        mask = torch.zeros(E, dtype=torch.bool)\n",
    "        mask[torch.tensor(ids, dtype=torch.long)] = True\n",
    "        data[('User','rated','Movie')][f'{split}_mask'] = mask\n",
    "    print({k:int(v.sum()) for k,v in {\n",
    "        'train': data[('User','rated','Movie')]['train_mask'],\n",
    "        'val':   data[('User','rated','Movie')]['val_mask'],\n",
    "        'test':  data[('User','rated','Movie')]['test_mask']\n",
    "    }.items()})\n",
    "else:\n",
    "    print(\"Keine rated-Kanten gefunden — Regression/Klassifikation kann nicht trainiert werden.\")\n"
   ],
   "id": "ec4f6aaf47a08e87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 189, 'val': 48, 'test': 60}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8) Modell: Hetero GraphSAGE + Edge-Head",
   "id": "5496945dd885657b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:14:45.645968Z",
     "start_time": "2025-09-16T21:14:45.633034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import HeteroConv, SAGEConv, Linear\n",
    "\n",
    "class HeteroSAGE(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels=64, out_channels=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                ('Movie','hasDirector','Person'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('Movie','hasActor','Person'):    SAGEConv((-1, -1), hidden_channels),\n",
    "                ('User','rated','Movie'):         SAGEConv((-1, -1), hidden_channels),\n",
    "                # Rückkanten (on-the-fly erzeugt)\n",
    "                ('Person','rev_hasDirector','Movie'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('Person','rev_hasActor','Movie'):    SAGEConv((-1, -1), hidden_channels),\n",
    "                ('Movie','rev_rated','User'):         SAGEConv((-1, -1), hidden_channels),\n",
    "            }, aggr='sum')\n",
    "            self.convs.append(conv)\n",
    "        self.lin_dict = torch.nn.ModuleDict({nt: Linear(-1, out_channels) for nt in metadata[0]})\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        def add_rev(edge_index): return edge_index.flip(0)\n",
    "        if ('Movie','hasDirector','Person') in edge_index_dict:\n",
    "            edge_index_dict.setdefault(('Person','rev_hasDirector','Movie'), add_rev(edge_index_dict[('Movie','hasDirector','Person')]))\n",
    "        if ('Movie','hasActor','Person') in edge_index_dict:\n",
    "            edge_index_dict.setdefault(('Person','rev_hasActor','Movie'), add_rev(edge_index_dict[('Movie','hasActor','Person')]))\n",
    "        if ('User','rated','Movie') in edge_index_dict:\n",
    "            edge_index_dict.setdefault(('Movie','rev_rated','User'), add_rev(edge_index_dict[('User','rated','Movie')]))\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {k: torch.relu(v) for k,v in x_dict.items()}\n",
    "        out = {k: self.lin_dict[k](v) for k,v in x_dict.items()}\n",
    "        return out\n",
    "\n",
    "class EdgeHead(nn.Module):\n",
    "    def __init__(self, in_dim, mode='regression'):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim*3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "        self.out_act = nn.Identity() if mode=='regression' else nn.Sigmoid()\n",
    "\n",
    "    def forward(self, u, m):\n",
    "        x = torch.cat([u, m, u*m], dim=-1)\n",
    "        y = self.mlp(x)\n",
    "        return self.out_act(y).squeeze(-1)\n"
   ],
   "id": "5de8e1f7bbaab0c1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9) Training & Evaluation",
   "id": "fa8650c8113ab010"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:14:47.453995Z",
     "start_time": "2025-09-16T21:14:45.665953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "\n",
    "hidden = 64\n",
    "outdim = 64\n",
    "model = HeteroSAGE(data.metadata(), hidden_channels=hidden, out_channels=outdim, num_layers=2).to(device)\n",
    "head = EdgeHead(outdim, mode=HEAD_MODE).to(device)\n",
    "\n",
    "params = list(model.parameters()) + list(head.parameters())\n",
    "opt = torch.optim.Adam(params, lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn = nn.MSELoss() if HEAD_MODE=='regression' else nn.BCELoss()\n",
    "\n",
    "def get_edge_indices(split):\n",
    "    mask = data[('User','rated','Movie')][f'{split}_mask']\n",
    "    ei = data[('User','rated','Movie')].edge_index[:, mask]\n",
    "    ys = data[('User','rated','Movie')].edge_label[mask]\n",
    "    return ei, ys\n",
    "\n",
    "def train_epoch():\n",
    "    model.train(); head.train()\n",
    "    opt.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    ei, ys = get_edge_indices('train')\n",
    "    u_emb = out['User'][ei[0]]\n",
    "    m_emb = out['Movie'][ei[1]]\n",
    "    target = ys if HEAD_MODE=='regression' else (ys >= LIKED_THRESHOLD).float()\n",
    "    pred = head(u_emb, m_emb)\n",
    "    loss = loss_fn(pred, target)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return float(loss.item())\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_split(split):\n",
    "    model.eval(); head.eval()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    ei, ys = get_edge_indices(split)\n",
    "    u_emb = out['User'][ei[0]]\n",
    "    m_emb = out['Movie'][ei[1]]\n",
    "    target = ys if HEAD_MODE=='regression' else (ys >= LIKED_THRESHOLD).float()\n",
    "    pred = head(u_emb, m_emb)\n",
    "    if HEAD_MODE=='regression':\n",
    "        rmse = torch.sqrt(torch.mean((pred-ys)**2)).item()\n",
    "        return rmse\n",
    "    else:\n",
    "        prob = pred.detach().cpu().numpy()\n",
    "        ytrue = target.detach().cpu().numpy()\n",
    "        acc = ((prob>=0.5)==(ytrue>=0.5)).mean()\n",
    "        return acc\n",
    "\n",
    "if data[('User','rated','Movie')].edge_index.numel() > 0:\n",
    "    for epoch in range(1, 51):\n",
    "        tr_loss = train_epoch()\n",
    "        if epoch%5==0:\n",
    "            metric = eval_split('val')\n",
    "            print(f\"Epoch {epoch:03d} | train_loss={tr_loss:.4f} | val_{'RMSE' if HEAD_MODE=='regression' else 'ACC'}={metric:.4f}\")\n",
    "else:\n",
    "    print(\"Skip training: no rated edges.\")\n"
   ],
   "id": "be63bbc5f72ea999",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | train_loss=12.6317 | val_RMSE=3.8389\n",
      "Epoch 010 | train_loss=9.0394 | val_RMSE=3.1175\n",
      "Epoch 015 | train_loss=1.4134 | val_RMSE=1.0746\n",
      "Epoch 020 | train_loss=2.0583 | val_RMSE=1.0743\n",
      "Epoch 025 | train_loss=1.7230 | val_RMSE=1.6333\n",
      "Epoch 030 | train_loss=1.5170 | val_RMSE=1.3474\n",
      "Epoch 035 | train_loss=1.1784 | val_RMSE=1.0673\n",
      "Epoch 040 | train_loss=1.0824 | val_RMSE=1.0716\n",
      "Epoch 045 | train_loss=1.0859 | val_RMSE=1.2343\n",
      "Epoch 050 | train_loss=0.9466 | val_RMSE=1.0785\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10) Inferenz für **neue Filme** (ohne persönliche Review)",
   "id": "39b95297d520870"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:14:47.597408Z",
     "start_time": "2025-09-16T21:14:47.550829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def predict_for_user_on_movies(user_id):\n",
    "    model.eval(); head.eval()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    u_idx = torch.tensor([user_id2idx[user_id]], device=out['User'].device)\n",
    "    u_emb = out['User'][u_idx].repeat(len(movie_idx2id), 1)\n",
    "    m_emb = out['Movie']\n",
    "    pred = head(u_emb, m_emb).detach().cpu().numpy()\n",
    "    return pred  # [num_movies]\n",
    "\n",
    "# Filme ohne persönliche Bewertung identifizieren\n",
    "rated_movies_set = set([m for m in rated_dst])\n",
    "unrated_movie_mask = [mid not in rated_movies_set for mid in movie_idx2id]\n",
    "unrated_indices = np.where(unrated_movie_mask)[0]\n",
    "\n",
    "if len(unrated_indices) == 0:\n",
    "    print(\"Alle Filme haben bereits personal reviews im KG (nichts zu empfehlen).\")\n",
    "else:\n",
    "    uid0 = next(iter(user_id2idx.keys()))\n",
    "    scores_all = predict_for_user_on_movies(uid0)\n",
    "    unrated_scores = scores_all[unrated_indices]\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"movie_id\": [movie_idx2id[i] for i in unrated_indices],\n",
    "        \"pred_score\": unrated_scores\n",
    "    }).sort_values(\"pred_score\", ascending=False)\n",
    "    display(pred_df.head(10))"
   ],
   "id": "8aa645fcea3ba3b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        movie_id  pred_score\n",
       "767     movie615    3.961489\n",
       "745     movie597    3.942960\n",
       "258  movie206647    3.909224\n",
       "213   movie18162    3.903321\n",
       "365  movie284053    3.885588\n",
       "345  movie273248    3.877185\n",
       "318  movie257344    3.859955\n",
       "169     movie153    3.845813\n",
       "491   movie38365    3.842213\n",
       "267     movie218    3.840386"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>movie615</td>\n",
       "      <td>3.961489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>movie597</td>\n",
       "      <td>3.942960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>movie206647</td>\n",
       "      <td>3.909224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>movie18162</td>\n",
       "      <td>3.903321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>movie284053</td>\n",
       "      <td>3.885588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>movie273248</td>\n",
       "      <td>3.877185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>movie257344</td>\n",
       "      <td>3.859955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>movie153</td>\n",
       "      <td>3.845813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>movie38365</td>\n",
       "      <td>3.842213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>movie218</td>\n",
       "      <td>3.840386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 11) Export als neue Triples (auskommentiert – erst Backup anlegen!)",
   "id": "1e432ae5c8c40b80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T21:14:47.996346Z",
     "start_time": "2025-09-16T21:14:47.612219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === EXPORT: ein Tripel pro Prediction im Format:\n",
    "# movieID    ex:predictedReview    personalVote_4.00\n",
    "# mit Rundung auf 0.5er Schritte + automatisches Backup ===\n",
    "\n",
    "import os, csv, math, shutil\n",
    "from datetime import datetime\n",
    "\n",
    "def round_to_half(x: float) -> float:\n",
    "    # Rundung auf nächste 0.5 (3.66 -> 3.5, 3.99 -> 4.0)\n",
    "    return math.floor(x*2 + 0.5) / 2.0\n",
    "\n",
    "def sanitize_cell(x: str) -> str:\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    s = str(x)\n",
    "    return s.replace(\"\\t\", \" \").replace(\"\\r\", \" \").replace(\"\\n\", \" \").strip()\n",
    "\n",
    "def append_triples_safely(new_triples_df: pd.DataFrame, path: str):\n",
    "    df = new_triples_df.rename(columns={0:\"head\",1:\"rel\",2:\"tail\"})[[\"head\",\"rel\",\"tail\"]].copy()\n",
    "    for c in [\"head\",\"rel\",\"tail\"]:\n",
    "        df[c] = df[c].map(sanitize_cell)\n",
    "\n",
    "    # sorge für eine abschließende Zeile vorm Anhängen\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            try:\n",
    "                f.seek(-1, os.SEEK_END)\n",
    "                if f.read(1) != b\"\\n\":\n",
    "                    with open(path, \"ab\") as g:\n",
    "                        g.write(b\"\\n\")\n",
    "            except OSError:\n",
    "                # leere Datei\n",
    "                pass\n",
    "\n",
    "    df.to_csv(\n",
    "        path,\n",
    "        mode=\"a\",\n",
    "        header=False,\n",
    "        index=False,\n",
    "        sep=\"\\t\",\n",
    "        lineterminator=\"\\n\",\n",
    "        encoding=\"utf-8\",\n",
    "        quoting=csv.QUOTE_MINIMAL,\n",
    "        escapechar=\"\\\\\",\n",
    "    )\n",
    "\n",
    "# --- baue Triples aus pred_df ---\n",
    "if 'pred_df' in locals() and len(pred_df) > 0:\n",
    "    top = pred_df.head(TOPK_EXPORT).copy()\n",
    "\n",
    "    rows = []\n",
    "    for _, r in top.iterrows():\n",
    "        mid = r['movie_id']\n",
    "        score = float(r['pred_score'])\n",
    "\n",
    "        if HEAD_MODE == 'classification':\n",
    "            # falls Klassifikation aktiv ist, interpretiere score als Prob. und mappe auf 0..5\n",
    "            score = 5.0 * score\n",
    "\n",
    "        rounded = round_to_half(score)\n",
    "        # clamp auf 0..5 (nur zur Sicherheit)\n",
    "        rounded = max(0.0, min(5.0, rounded))\n",
    "\n",
    "        tail_value = f\"personalVote_{rounded:.2f}\"\n",
    "        rows.append([mid, \"ex:predictedReview\", tail_value])\n",
    "\n",
    "    export_df = pd.DataFrame(rows, columns=[\"head\",\"rel\",\"tail\"])\n",
    "\n",
    "    # Optional: Duplikate gegen bestehende Triples vermeiden\n",
    "    existing = pd.read_csv(KG_PATH, sep=\"\\t\", header=None, names=[\"head\",\"rel\",\"tail\"], dtype=str, keep_default_na=False, engine=\"python\")\n",
    "    merged = export_df.merge(existing.drop_duplicates(), on=[\"head\",\"rel\",\"tail\"], how=\"left\", indicator=True)\n",
    "    unique_new = merged[merged[\"_merge\"] == \"left_only\"][[\"head\",\"rel\",\"tail\"]]\n",
    "\n",
    "    print(f\"Neue Triples (nach Deduplikation): {len(unique_new)}\")\n",
    "    display(unique_new.head(10))\n",
    "\n",
    "    # --- Backup vor dem Anhängen ---\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # Backup-Verzeichnis erstellen, falls es nicht existiert\n",
    "    BACKUP_DIR = KG_PATH.parent / \"backups\"\n",
    "    BACKUP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Backup-Dateiname mit Zeitstempel\n",
    "    timestamp   = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    backup_path = BACKUP_DIR / f\"movie_kg_triples_backup_{timestamp}.tsv\"\n",
    "\n",
    "    shutil.copy2(KG_PATH, backup_path)\n",
    "    print(\"📂 Backup gespeichert unter:\", backup_path)\n",
    "\n",
    "    # --- an KG anhängen ---\n",
    "    append_triples_safely(unique_new, str(KG_PATH))\n",
    "    print(\"✅ Triples angehängt an:\", KG_PATH)\n",
    "\n",
    "else:\n",
    "    print(\"No predictions to export.\")"
   ],
   "id": "e17418565ab6c74a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neue Triples (nach Deduplikation): 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          head                 rel               tail\n",
       "0     movie615  ex:predictedReview  personalVote_4.00\n",
       "1     movie597  ex:predictedReview  personalVote_4.00\n",
       "2  movie206647  ex:predictedReview  personalVote_4.00\n",
       "3   movie18162  ex:predictedReview  personalVote_4.00\n",
       "4  movie284053  ex:predictedReview  personalVote_4.00\n",
       "5  movie273248  ex:predictedReview  personalVote_4.00\n",
       "6  movie257344  ex:predictedReview  personalVote_4.00\n",
       "7     movie153  ex:predictedReview  personalVote_4.00\n",
       "8   movie38365  ex:predictedReview  personalVote_4.00\n",
       "9     movie218  ex:predictedReview  personalVote_4.00"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>rel</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie615</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie597</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie206647</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie18162</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie284053</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>movie273248</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>movie257344</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>movie153</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>movie38365</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>movie218</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Backup gespeichert unter: ../data/kg/triples/backups/movie_kg_triples_backup_20250916_231447.tsv\n",
      "✅ Triples angehängt an: ../data/kg/triples/movie_kg_triples.tsv\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
