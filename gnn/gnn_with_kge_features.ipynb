{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Induktiver Hetero-GNN **mit KGE-Embeddings als Features** (Movies/Persons/Users) + Kanten-Embeddings (optional)\n",
    "\n",
    "**Ziel:** Für neue Filme ohne `schema:review` / `ex:liked` Kanten Vorhersagen erzeugen und als Triples exportieren.\n",
    "\n",
    "**Was dieses Notebook macht**\n",
    "1. Lädt `movie_kg_triples.tsv` (head, rel, tail).\n",
    "2. Lädt **entity_embeddings.csv** (Pfad: `../data/kg/embeddings/`; Fallback: Upload).\n",
    "3. (Optional) Lädt **relation_embeddings.csv** und fügt diese als `edge_attr` pro Kanten-Typ hinzu.\n",
    "4. Baut einen **heterogenen Graphen** (User/Movie/Person) in **PyTorch Geometric**.\n",
    "5. Erzeugt Node-Features: **KGE-Embedding** (wenn vorhanden) **⊕** **Metadaten-Fallback** (Jahr/Runtime/Popularität/Sprache).\n",
    "6. Trainiert **GraphSAGE** + Edge-Head (**Regression**: Rating in [0,5] *oder* **Klassifikation**: liked).\n",
    "7. Inferenz: Scoring für **neue** Filme (ohne persönliche Review-Kante).\n",
    "8. Export: `ex:predictedReview` (Regression) oder `ex:liked` (Klassifikation) als Triples (auskommentiert; Backup empfohlen).\n"
   ],
   "id": "76f744bf84532f97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:57:46.928778Z",
     "start_time": "2025-09-14T22:57:44.568788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Optional: Installation (falls lokal ausgeführt, in Colab/virtualenv)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.2.0+cpu.html\n",
    "!pip install pandas numpy scikit-learn tqdm python-dotenv"
   ],
   "id": "934618d6d0d4e3fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\r\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (2.8.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.13/site-packages (0.23.0)\r\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.13/site-packages (2.8.0)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (4.14.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.3.2)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (2.1.3)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (11.1.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cpu.html\r\n",
      "Requirement already satisfied: torch-geometric in /opt/anaconda3/lib/python3.13/site-packages (2.6.1)\r\n",
      "Requirement already satisfied: torch-scatter in /opt/anaconda3/lib/python3.13/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: torch-sparse in /opt/anaconda3/lib/python3.13/site-packages (0.6.18)\r\n",
      "Requirement already satisfied: torch-cluster in /opt/anaconda3/lib/python3.13/site-packages (1.6.3)\r\n",
      "Requirement already satisfied: torch-spline-conv in /opt/anaconda3/lib/python3.13/site-packages (1.2.2)\r\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (3.11.10)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (2025.3.2)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (3.1.6)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (2.1.3)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (5.9.0)\r\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (3.2.0)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (from torch-geometric) (4.67.1)\r\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from torch-sparse) (1.15.3)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (2.4.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (1.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (24.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp->torch-geometric) (1.18.0)\r\n",
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch-geometric) (3.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch-geometric) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->torch-geometric) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->torch-geometric) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->torch-geometric) (2025.7.14)\r\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (2.1.3)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (1.6.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (4.67.1)\r\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.13/site-packages (1.1.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1) Imports, Pfade & Konfiguration",
   "id": "20fb059a3b1d4467"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:57:46.954016Z",
     "start_time": "2025-09-14T22:57:46.947824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, re, math\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    from torch_geometric.data import HeteroData\n",
    "    from torch_geometric.nn import HeteroConv, SAGEConv, Linear\n",
    "    pyg_available = True\n",
    "    print(\"PyTorch Geometric available.\")\n",
    "except Exception as e:\n",
    "    pyg_available = False\n",
    "    print(\"PyG not available in this env. You can still inspect/export this notebook; run it locally with PyG installed.\")\n",
    "\n",
    "# ---- Konfiguration ----\n",
    "# Pfade (passe an, falls nötig)\n",
    "KG_PATH = Path(\"../data/kg/triples/movie_kg_triples.tsv\")\n",
    "EMB_DIR = Path(\"../data/kg/embeddings\")\n",
    "ENTITY_EMB_PATHS = [EMB_DIR / \"entity_embeddings.csv\", Path(\"/mnt/data/entity_embeddings.csv\")]\n",
    "REL_EMB_PATHS    = [EMB_DIR / \"relation_embeddings.csv\", Path(\"/mnt/data/relation_embeddings.csv\")]\n",
    "\n",
    "# Trainingsmodus für den Edge-Head: 'regression' (Rating 0..5) oder 'classification' (Liked)\n",
    "HEAD_MODE = 'regression'   # 'regression' | 'classification'\n",
    "LIKED_THRESHOLD = 4.0      # nur relevant für Klassifikation -> Label = 1, wenn personal5 >= TH\n",
    "\n",
    "# Inferenz/Export\n",
    "TOPK_EXPORT = 100          # wie viele Vorhersagen exportieren\n",
    "EXPORT_MODE = 'predictedReview'  # 'predictedReview' | 'liked'"
   ],
   "id": "7ce99daf24137d2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Geometric available.\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2) Daten laden: Triples & Embeddings",
   "id": "dec26469c65c6c51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:57:47.258306Z",
     "start_time": "2025-09-14T22:57:46.985262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KG laden\n",
    "if not KG_PATH.exists() and Path(\"../data/kg/triples/movie_kg_triples.tsv\").exists():\n",
    "    KG_PATH = Path(\"../data/kg/triples/movie_kg_triples.tsv\")\n",
    "\n",
    "triples = pd.read_csv(KG_PATH, sep=\"\\t\", header=None, names=[\"head\",\"rel\",\"tail\"])\n",
    "print(\"Triples loaded:\", len(triples))\n",
    "display(triples.head(5))\n",
    "\n",
    "def first_existing(paths):\n",
    "    for p in paths:\n",
    "        if Path(p).exists():\n",
    "            return Path(p)\n",
    "    return None\n",
    "\n",
    "ent_path = first_existing(ENTITY_EMB_PATHS)\n",
    "rel_path = first_existing(REL_EMB_PATHS)\n",
    "\n",
    "print(\"Entity embeddings:\", ent_path if ent_path else \"NOT FOUND\")\n",
    "print(\"Relation embeddings:\", rel_path if rel_path else \"NOT FOUND\")\n",
    "\n",
    "# Entity-Embeddings lesen (flexibles Schema: 'entity' oder 'id' + numerische Spalten)\n",
    "entity_emb = None\n",
    "ent_id_col = None\n",
    "if ent_path:\n",
    "    tmp = pd.read_csv(ent_path)\n",
    "    if \"entity\" in tmp.columns:\n",
    "        ent_id_col = \"entity\"\n",
    "    elif \"id\" in tmp.columns:\n",
    "        ent_id_col = \"id\"\n",
    "    else:\n",
    "        ent_id_col = tmp.columns[0]\n",
    "    # nur numerische Spalten als Vektor\n",
    "    vec_cols = [c for c in tmp.columns if c != ent_id_col]\n",
    "    for c in vec_cols: tmp[c] = pd.to_numeric(tmp[c], errors=\"coerce\")\n",
    "    vec_cols = [c for c in vec_cols if tmp[c].notna().any()]\n",
    "    entity_emb = tmp[[ent_id_col] + vec_cols].dropna()\n",
    "    print(f\"Loaded entity embeddings: {entity_emb.shape[0]} entities, dim={len(vec_cols)}\")\n",
    "else:\n",
    "    print(\"No entity embeddings available; will use metadata-only features for all nodes.\")\n",
    "\n",
    "# Relation-Embeddings (optional)\n",
    "relation_emb = None\n",
    "rel_key_col = None\n",
    "if rel_path:\n",
    "    tmp = pd.read_csv(rel_path)\n",
    "    if \"relation\" in tmp.columns:\n",
    "        rel_key_col = \"relation\"\n",
    "    elif \"rel\" in tmp.columns:\n",
    "        rel_key_col = \"rel\"\n",
    "    else:\n",
    "        rel_key_col = tmp.columns[0]\n",
    "    rvec_cols = [c for c in tmp.columns if c != rel_key_col]\n",
    "    for c in rvec_cols: tmp[c] = pd.to_numeric(tmp[c], errors=\"coerce\")\n",
    "    rvec_cols = [c for c in rvec_cols if tmp[c].notna().any()]\n",
    "    relation_emb = tmp[[rel_key_col] + rvec_cols].dropna()\n",
    "    print(f\"Loaded relation embeddings: {relation_emb.shape[0]} relations, dim={len(rvec_cols)}\")\n",
    "else:\n",
    "    print(\"No relation embeddings; edge_attr will be empty (the model still works).\")\n"
   ],
   "id": "1179e5533d0bfaa5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triples loaded: 58616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          head                     rel              tail\n",
       "0  movie452522                rdf:type      schema:Movie\n",
       "1  movie452522             schema:name        Twin Peaks\n",
       "2  movie452522    schema:datePublished    published_1989\n",
       "3  movie452522  schema:aggregateRating       avgVote_8.4\n",
       "4  movie452522           schema:review  personalVote_5.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>rel</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie452522</td>\n",
       "      <td>rdf:type</td>\n",
       "      <td>schema:Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie452522</td>\n",
       "      <td>schema:name</td>\n",
       "      <td>Twin Peaks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie452522</td>\n",
       "      <td>schema:datePublished</td>\n",
       "      <td>published_1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie452522</td>\n",
       "      <td>schema:aggregateRating</td>\n",
       "      <td>avgVote_8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie452522</td>\n",
       "      <td>schema:review</td>\n",
       "      <td>personalVote_5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity embeddings: ../data/kg/embeddings/entity_embeddings.csv\n",
      "Relation embeddings: ../data/kg/embeddings/relation_embeddings.csv\n",
      "Loaded entity embeddings: 19834 entities, dim=50\n",
      "Loaded relation embeddings: 21 relations, dim=50\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3) Knoten/Attribute ableiten & Feature-Fallbacks",
   "id": "c291b9bc0fa2ac62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:57:47.392553Z",
     "start_time": "2025-09-14T22:57:47.270095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parser\n",
    "def extract_year(s):\n",
    "    if pd.isna(s): return None\n",
    "    m = re.search(r\"(19|20)\\d{2}\", str(s))\n",
    "    return int(m.group(0)) if m else None\n",
    "\n",
    "def extract_float_token(s, key_prefix):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return None\n",
    "    m = re.search(rf\"{re.escape(key_prefix)}[_:\\s]*([0-9]+(?:[.,][0-9]+)?)\", str(s), flags=re.I)\n",
    "    if m: return float(m.group(1).replace(\",\", \".\"))\n",
    "    return None\n",
    "\n",
    "def extract_personal_review(s):  # 0..5\n",
    "    return extract_float_token(s, \"personalVote\")\n",
    "\n",
    "def extract_avg_vote(s):         # 0..10\n",
    "    return extract_float_token(s, \"avgVote\")\n",
    "\n",
    "# Movies\n",
    "#movie_ids = set(triples.loc[(triples.rel==\"rdf:type\") & (triples.tail==\"schema:Movie\"), \"head\"].astype(str))\n",
    "\n",
    "# 1) Normalisierung\n",
    "triples[\"rel_norm\"]  = triples[\"rel\"].str.strip().str.lower()\n",
    "triples[\"tail_norm\"] = triples[\"tail\"].str.strip().str.lower()\n",
    "\n",
    "# 2) Erkenne Typ-Tripel in mehreren Varianten\n",
    "type_aliases = {\"rdf:type\", \"a\", \"type\", \"schema:type\", \"@type\"}\n",
    "movie_aliases = {\n",
    "    \"schema:movie\", \"movie\",\n",
    "    \"http://schema.org/movie\", \"https://schema.org/movie\", \"schema.org/movie\"\n",
    "}\n",
    "\n",
    "type_mask  = triples[\"rel_norm\"].isin(type_aliases)\n",
    "movie_mask = triples[\"tail_norm\"].isin(movie_aliases)\n",
    "movie_ids_1 = set(triples.loc[type_mask & movie_mask, \"head\"])\n",
    "\n",
    "# 3) Fallback: Knoten, die typische Movie-Attribute tragen\n",
    "movie_like_rels = {\n",
    "    \"schema:director\",\"schema:actor\",\"schema:aggregaterating\",\"schema:datepublished\",\n",
    "    \"schema:duration\",\"schema:genre\",\"ex:originallanguage\",\"ex:popularity\", # \"schema:name\"\n",
    "}\n",
    "movie_ids_2 = set(triples.loc[triples[\"rel_norm\"].isin(movie_like_rels), \"head\"])\n",
    "\n",
    "# 4) Optional: Präfix-Heuristik (falls du tmdb-IDs nutzt)\n",
    "movie_ids_3 = set(triples.loc[triples[\"head\"].str.startswith(\"tmdbmovie\", na=False), \"head\"])\n",
    "\n",
    "movie_ids = movie_ids_1 | movie_ids_2 | movie_ids_3\n",
    "print(\"Movies erkannt:\", len(movie_ids))\n",
    "\n",
    "name_map = triples[triples.rel==\"schema:name\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "year_map = triples[triples.rel==\"schema:datePublished\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "avg_map  = triples[triples.rel==\"schema:aggregateRating\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "rev_map  = triples[triples.rel==\"schema:review\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "dur_map  = triples[triples.rel==\"schema:duration\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "lang_map = triples[triples.rel==\"ex:originalLanguage\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "pop_map  = triples[triples.rel==\"ex:popularity\"].set_index(\"head\")[\"tail\"].to_dict()\n",
    "\n",
    "rows = []\n",
    "for mid in movie_ids:\n",
    "    title = name_map.get(mid)\n",
    "    year = extract_year(year_map.get(mid))\n",
    "    personal5 = extract_personal_review(rev_map.get(mid))\n",
    "    avg10 = extract_avg_vote(avg_map.get(mid))\n",
    "    runtime = None\n",
    "    if mid in dur_map:\n",
    "        m = re.search(r\"(\\d+)\", str(dur_map[mid]))\n",
    "        runtime = int(m.group(1)) if m else None\n",
    "    lang = lang_map.get(mid)\n",
    "    pop = None\n",
    "    if mid in pop_map:\n",
    "        m = re.search(r\"([0-9]+(?:[.,][0-9]+)?)\", str(pop_map[mid]))\n",
    "        if m: pop = float(m.group(1).replace(\",\",\".\"))\n",
    "    rows.append({\"movie_id\": mid, \"title\": title, \"year\": year, \"personal5\": personal5, \"avg10\": avg10,\n",
    "                 \"runtime\": runtime, \"language\": lang, \"pop\": pop})\n",
    "movie_tbl = pd.DataFrame(rows)\n",
    "\n",
    "# Directors / Actors\n",
    "dir_edges = triples[triples.rel==\"schema:director\"][[\"head\",\"tail\"]].astype(str).values.tolist()\n",
    "act_edges = triples[triples.rel==\"schema:actor\"][[\"head\",\"tail\"]].astype(str).values.tolist()\n",
    "person_ids = set([t for _,t in dir_edges+act_edges])\n",
    "\n",
    "# Users\n",
    "has_user_nodes = (triples[\"head\"].str.startswith(\"user\").any()) or (triples[\"tail\"].str.startswith(\"user\").any())\n",
    "user_ids = set(triples.loc[triples[\"head\"].str.startswith(\"user\"), \"head\"].astype(str)) if has_user_nodes else {\"user0\"}\n",
    "\n",
    "# Ratings als (User -> Movie) mit Label 0..5\n",
    "rated_src, rated_dst, rated_y = [], [], []\n",
    "for _, row in movie_tbl.dropna(subset=[\"personal5\"]).iterrows():\n",
    "    rated_src.append(next(iter(user_ids)))   # erster/only user\n",
    "    rated_dst.append(row[\"movie_id\"])\n",
    "    rated_y.append(float(row[\"personal5\"]))\n",
    "\n",
    "print(\"Movies:\", len(movie_tbl), \"| Persons:\", len(person_ids), \"| Users:\", len(user_ids), \"| Rated edges:\", len(rated_y))\n",
    "display(movie_tbl.head(5))"
   ],
   "id": "4574cf3e4c341de3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies erkannt: 703\n",
      "Movies: 703 | Persons: 4611 | Users: 1 | Rated edges: 297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      movie_id                                              title  year  \\\n",
       "0     movie496  Borat: Cultural Learnings of America for Make ...  2006   \n",
       "1   movie22970                             The Cabin in the Woods  2011   \n",
       "2  movie391713                                          Lady Bird  2017   \n",
       "3  movie537116                                tick, tick... BOOM!  2021   \n",
       "4  movie354912                                               Coco  2017   \n",
       "\n",
       "   personal5  avg10  runtime language      pop  \n",
       "0        NaN  6.782     84.0       en   7.0690  \n",
       "1        NaN  6.639     95.0       en   8.1935  \n",
       "2        4.5  7.300     94.0       en   8.4172  \n",
       "3        3.5  7.615    115.0       en   4.9097  \n",
       "4        3.5  8.200    105.0       en  23.6656  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>personal5</th>\n",
       "      <th>avg10</th>\n",
       "      <th>runtime</th>\n",
       "      <th>language</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie496</td>\n",
       "      <td>Borat: Cultural Learnings of America for Make ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.782</td>\n",
       "      <td>84.0</td>\n",
       "      <td>en</td>\n",
       "      <td>7.0690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie22970</td>\n",
       "      <td>The Cabin in the Woods</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.639</td>\n",
       "      <td>95.0</td>\n",
       "      <td>en</td>\n",
       "      <td>8.1935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie391713</td>\n",
       "      <td>Lady Bird</td>\n",
       "      <td>2017</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.300</td>\n",
       "      <td>94.0</td>\n",
       "      <td>en</td>\n",
       "      <td>8.4172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie537116</td>\n",
       "      <td>tick, tick... BOOM!</td>\n",
       "      <td>2021</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.615</td>\n",
       "      <td>115.0</td>\n",
       "      <td>en</td>\n",
       "      <td>4.9097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie354912</td>\n",
       "      <td>Coco</td>\n",
       "      <td>2017</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.200</td>\n",
       "      <td>105.0</td>\n",
       "      <td>en</td>\n",
       "      <td>23.6656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4) ID-Mappings & relationale Kanten (edge_attr via relation_embeddings)",
   "id": "7ab9f2f0458d834c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:57:47.436618Z",
     "start_time": "2025-09-14T22:57:47.419207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_idmap(ids):\n",
    "    ids = sorted(list(ids))\n",
    "    return {k:i for i,k in enumerate(ids)}, ids\n",
    "\n",
    "movie_id2idx, movie_idx2id = build_idmap(movie_ids)\n",
    "person_id2idx, person_idx2id = build_idmap(person_ids)\n",
    "user_id2idx, user_idx2id = build_idmap(user_ids)\n",
    "\n",
    "import numpy as np\n",
    "def edge_index_from_pairs(pairs, src_map, dst_map):\n",
    "    idx = [[src_map[h], dst_map[t]] for h,t in pairs if h in src_map and t in dst_map]\n",
    "    if len(idx)==0:\n",
    "        return np.zeros((2,0), dtype=int)\n",
    "    return np.array(idx, dtype=int).T\n",
    "\n",
    "dir_edge_index = edge_index_from_pairs(dir_edges, movie_id2idx, person_id2idx)\n",
    "act_edge_index = edge_index_from_pairs(act_edges, movie_id2idx, person_id2idx)\n",
    "rated_edge_index = edge_index_from_pairs(list(zip(rated_src, rated_dst)), user_id2idx, movie_id2idx)\n",
    "rated_y = np.array(rated_y, dtype=float)\n",
    "\n",
    "print(\"edge_index shapes -> dir:\", dir_edge_index.shape, \"| act:\", act_edge_index.shape, \"| rated:\", rated_edge_index.shape)\n",
    "\n",
    "# Edge-Attr pro Rel-Typ (gleicher Vektor für alle Kanten dieser Relation)\n",
    "edge_attr = {}\n",
    "if relation_emb is not None:\n",
    "    rkey = relation_emb.columns[0]\n",
    "    rvec_cols = relation_emb.columns[1:]\n",
    "    rel2vec = {row[rkey]: row[rvec_cols].values.astype(np.float32) for _,row in relation_emb.iterrows()}\n",
    "    def make_edge_attr(num_edges, rel_name):\n",
    "        if rel_name in rel2vec and num_edges>0:\n",
    "            vec = rel2vec[rel_name]\n",
    "            return np.tile(vec, (num_edges,1))\n",
    "        return None\n",
    "    edge_attr[('Movie','hasDirector','Person')] = make_edge_attr(dir_edge_index.shape[1], 'schema:director')\n",
    "    edge_attr[('Movie','hasActor','Person')]    = make_edge_attr(act_edge_index.shape[1], 'schema:actor')\n",
    "    edge_attr[('User','rated','Movie')]         = make_edge_attr(rated_edge_index.shape[1], 'schema:review')\n",
    "else:\n",
    "    edge_attr = { }"
   ],
   "id": "8bd5ff859812ec54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index shapes -> dir: (2, 803) | act: (2, 6745) | rated: (2, 297)\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5) Node-Features = **KGE-Entity-Embedding** ⊕ **Metadaten-Fallback**",
   "id": "4a0bf32b71d9471f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:57:48.855479Z",
     "start_time": "2025-09-14T22:57:47.496718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5.1 Metadaten-Vektoren (Fallback)\n",
    "def norm_col(x):\n",
    "    x = x.astype(float)\n",
    "    mn, mx = np.nanmin(x), np.nanmax(x)\n",
    "    if not np.isfinite(mn) or not np.isfinite(mx) or mx==mn:\n",
    "        return np.zeros_like(x, dtype=float)\n",
    "    y = (x - mn) / (mx - mn)\n",
    "    y[np.isnan(y)] = 0.0\n",
    "    return y\n",
    "\n",
    "mt = movie_tbl.set_index(\"movie_id\").reindex(movie_idx2id)\n",
    "year_feat    = norm_col(mt[\"year\"].fillna(mt[\"year\"].median()).values)\n",
    "runtime_feat = norm_col(mt[\"runtime\"].fillna(mt[\"runtime\"].median()).values)\n",
    "pop_feat     = norm_col(mt[\"pop\"].fillna(mt[\"pop\"].median()).values)\n",
    "\n",
    "lang_series = mt[\"language\"].fillna(\"unknown\").astype(str)\n",
    "top_langs = [l for l,_ in Counter(lang_series).most_common(8)]\n",
    "lang_feat = np.stack([ (lang_series==L).astype(float).values for L in top_langs ], axis=1) if len(top_langs)>0 else np.zeros((len(mt),0))\n",
    "\n",
    "meta_movie = np.stack([year_feat, runtime_feat, pop_feat], axis=1)\n",
    "if lang_feat.shape[1] > 0:\n",
    "    meta_movie = np.concatenate([meta_movie, lang_feat], axis=1)\n",
    "\n",
    "meta_person = np.zeros((len(person_idx2id), max(4, meta_movie.shape[1]//2)), dtype=float)\n",
    "meta_user   = np.zeros((len(user_idx2id),   max(4, meta_movie.shape[1]//2)), dtype=float)\n",
    "\n",
    "# 5.2 KGE-Entity-Embeddings mappen (falls vorhanden)\n",
    "def build_entity_lookup(df, id_col):\n",
    "    return {str(row[id_col]): row.drop(labels=[id_col]).to_numpy(dtype=np.float32) for _,row in df.iterrows()}\n",
    "\n",
    "entity_lookup = build_entity_lookup(entity_emb, entity_emb.columns[0]) if entity_emb is not None else {}\n",
    "\n",
    "def stack_features(ids_list, meta_fallback):\n",
    "    X = []\n",
    "    for i, node_id in enumerate(ids_list):\n",
    "        vec = entity_lookup.get(str(node_id))\n",
    "        if vec is not None:\n",
    "            # concat: [entity_emb ⊕ meta_fallback[i]]\n",
    "            v = np.concatenate([vec, meta_fallback[i]], axis=0)\n",
    "        else:\n",
    "            v = meta_fallback[i]\n",
    "        X.append(v.astype(np.float32))\n",
    "    # pad to common dim\n",
    "    maxd = max(x.shape[0] for x in X) if X else 0\n",
    "    Xp = np.zeros((len(X), maxd), dtype=np.float32)\n",
    "    for i,x in enumerate(X):\n",
    "        Xp[i,:x.shape[0]] = x\n",
    "    return Xp\n",
    "\n",
    "movie_x  = stack_features(movie_idx2id,  meta_movie)\n",
    "person_x = stack_features(person_idx2id, meta_person)\n",
    "user_x   = stack_features(user_idx2id,   meta_user)\n",
    "\n",
    "print(\"movie_x:\", movie_x.shape, \"| person_x:\", person_x.shape, \"| user_x:\", user_x.shape)\n"
   ],
   "id": "81ba8d0f1da052ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_x: (703, 61) | person_x: (4611, 55) | user_x: (1, 5)\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6) HeteroData in PyG",
   "id": "8ea13426e64197f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:57:48.917966Z",
     "start_time": "2025-09-14T22:57:48.913481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not pyg_available:\n",
    "    raise RuntimeError(\"PyG nicht verfügbar. Bitte lokal mit installiertem torch_geometric ausführen.\")\n",
    "\n",
    "data = HeteroData()\n",
    "data['Movie'].x  = torch.tensor(movie_x, dtype=torch.float)\n",
    "data['Person'].x = torch.tensor(person_x, dtype=torch.float)\n",
    "data['User'].x   = torch.tensor(user_x, dtype=torch.float)\n",
    "\n",
    "# Edge indices\n",
    "data[('Movie','hasDirector','Person')].edge_index = torch.tensor(dir_edge_index, dtype=torch.long)\n",
    "data[('Movie','hasActor','Person')].edge_index    = torch.tensor(act_edge_index, dtype=torch.long)\n",
    "data[('User','rated','Movie')].edge_index         = torch.tensor(rated_edge_index, dtype=torch.long)\n",
    "if rated_edge_index.shape[1] > 0:\n",
    "    data[('User','rated','Movie')].edge_label = torch.tensor(rated_y, dtype=torch.float)\n",
    "\n",
    "# Edge attributes (relation embeddings), wenn vorhanden\n",
    "for key, ea in edge_attr.items():\n",
    "    if ea is not None:\n",
    "        data[key].edge_attr = torch.tensor(ea, dtype=torch.float)\n",
    "\n",
    "print(data)"
   ],
   "id": "c83edc78bba427bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  Movie={ x=[703, 61] },\n",
      "  Person={ x=[4611, 55] },\n",
      "  User={ x=[1, 5] },\n",
      "  (Movie, hasDirector, Person)={\n",
      "    edge_index=[2, 803],\n",
      "    edge_attr=[803, 50],\n",
      "  },\n",
      "  (Movie, hasActor, Person)={\n",
      "    edge_index=[2, 6745],\n",
      "    edge_attr=[6745, 50],\n",
      "  },\n",
      "  (User, rated, Movie)={\n",
      "    edge_index=[2, 297],\n",
      "    edge_label=[297],\n",
      "    edge_attr=[297, 50],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7) Train/Val/Test Split über vorhandene `rated`-Kanten",
   "id": "4fe61c51098a3929"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:57:48.945941Z",
     "start_time": "2025-09-14T22:57:48.939168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if data[('User','rated','Movie')].edge_index.numel() > 0:\n",
    "    E = data[('User','rated','Movie')].edge_index.shape[1]\n",
    "    idx = np.arange(E)\n",
    "    train_idx, test_idx = train_test_split(idx, test_size=0.2, random_state=42)\n",
    "    train_idx, val_idx  = train_test_split(train_idx, test_size=0.2, random_state=42)\n",
    "\n",
    "    for split, ids in [('train',train_idx),('val',val_idx),('test',test_idx)]:\n",
    "        mask = torch.zeros(E, dtype=torch.bool)\n",
    "        mask[torch.tensor(ids, dtype=torch.long)] = True\n",
    "        data[('User','rated','Movie')][f'{split}_mask'] = mask\n",
    "    print({k:int(v.sum()) for k,v in {\n",
    "        'train': data[('User','rated','Movie')]['train_mask'],\n",
    "        'val':   data[('User','rated','Movie')]['val_mask'],\n",
    "        'test':  data[('User','rated','Movie')]['test_mask']\n",
    "    }.items()})\n",
    "else:\n",
    "    print(\"Keine rated-Kanten gefunden — Regression/Klassifikation kann nicht trainiert werden.\")\n"
   ],
   "id": "ec4f6aaf47a08e87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 189, 'val': 48, 'test': 60}\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8) Modell: Hetero GraphSAGE + Edge-Head",
   "id": "5496945dd885657b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:57:48.977502Z",
     "start_time": "2025-09-14T22:57:48.971453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import HeteroConv, SAGEConv, Linear\n",
    "\n",
    "class HeteroSAGE(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels=64, out_channels=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                ('Movie','hasDirector','Person'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('Movie','hasActor','Person'):    SAGEConv((-1, -1), hidden_channels),\n",
    "                ('User','rated','Movie'):         SAGEConv((-1, -1), hidden_channels),\n",
    "                # Rückkanten (on-the-fly erzeugt)\n",
    "                ('Person','rev_hasDirector','Movie'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('Person','rev_hasActor','Movie'):    SAGEConv((-1, -1), hidden_channels),\n",
    "                ('Movie','rev_rated','User'):         SAGEConv((-1, -1), hidden_channels),\n",
    "            }, aggr='sum')\n",
    "            self.convs.append(conv)\n",
    "        self.lin_dict = torch.nn.ModuleDict({nt: Linear(-1, out_channels) for nt in metadata[0]})\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        def add_rev(edge_index): return edge_index.flip(0)\n",
    "        if ('Movie','hasDirector','Person') in edge_index_dict:\n",
    "            edge_index_dict.setdefault(('Person','rev_hasDirector','Movie'), add_rev(edge_index_dict[('Movie','hasDirector','Person')]))\n",
    "        if ('Movie','hasActor','Person') in edge_index_dict:\n",
    "            edge_index_dict.setdefault(('Person','rev_hasActor','Movie'), add_rev(edge_index_dict[('Movie','hasActor','Person')]))\n",
    "        if ('User','rated','Movie') in edge_index_dict:\n",
    "            edge_index_dict.setdefault(('Movie','rev_rated','User'), add_rev(edge_index_dict[('User','rated','Movie')]))\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {k: torch.relu(v) for k,v in x_dict.items()}\n",
    "        out = {k: self.lin_dict[k](v) for k,v in x_dict.items()}\n",
    "        return out\n",
    "\n",
    "class EdgeHead(nn.Module):\n",
    "    def __init__(self, in_dim, mode='regression'):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim*3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "        self.out_act = nn.Identity() if mode=='regression' else nn.Sigmoid()\n",
    "\n",
    "    def forward(self, u, m):\n",
    "        x = torch.cat([u, m, u*m], dim=-1)\n",
    "        y = self.mlp(x)\n",
    "        return self.out_act(y).squeeze(-1)\n"
   ],
   "id": "5de8e1f7bbaab0c1",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9) Training & Evaluation",
   "id": "fa8650c8113ab010"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:57:49.867181Z",
     "start_time": "2025-09-14T22:57:48.986690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "\n",
    "hidden = 64\n",
    "outdim = 64\n",
    "model = HeteroSAGE(data.metadata(), hidden_channels=hidden, out_channels=outdim, num_layers=2).to(device)\n",
    "head = EdgeHead(outdim, mode=HEAD_MODE).to(device)\n",
    "\n",
    "params = list(model.parameters()) + list(head.parameters())\n",
    "opt = torch.optim.Adam(params, lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn = nn.MSELoss() if HEAD_MODE=='regression' else nn.BCELoss()\n",
    "\n",
    "def get_edge_indices(split):\n",
    "    mask = data[('User','rated','Movie')][f'{split}_mask']\n",
    "    ei = data[('User','rated','Movie')].edge_index[:, mask]\n",
    "    ys = data[('User','rated','Movie')].edge_label[mask]\n",
    "    return ei, ys\n",
    "\n",
    "def train_epoch():\n",
    "    model.train(); head.train()\n",
    "    opt.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    ei, ys = get_edge_indices('train')\n",
    "    u_emb = out['User'][ei[0]]\n",
    "    m_emb = out['Movie'][ei[1]]\n",
    "    target = ys if HEAD_MODE=='regression' else (ys >= LIKED_THRESHOLD).float()\n",
    "    pred = head(u_emb, m_emb)\n",
    "    loss = loss_fn(pred, target)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return float(loss.item())\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_split(split):\n",
    "    model.eval(); head.eval()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    ei, ys = get_edge_indices(split)\n",
    "    u_emb = out['User'][ei[0]]\n",
    "    m_emb = out['Movie'][ei[1]]\n",
    "    target = ys if HEAD_MODE=='regression' else (ys >= LIKED_THRESHOLD).float()\n",
    "    pred = head(u_emb, m_emb)\n",
    "    if HEAD_MODE=='regression':\n",
    "        rmse = torch.sqrt(torch.mean((pred-ys)**2)).item()\n",
    "        return rmse\n",
    "    else:\n",
    "        prob = pred.detach().cpu().numpy()\n",
    "        ytrue = target.detach().cpu().numpy()\n",
    "        acc = ((prob>=0.5)==(ytrue>=0.5)).mean()\n",
    "        return acc\n",
    "\n",
    "if data[('User','rated','Movie')].edge_index.numel() > 0:\n",
    "    for epoch in range(1, 51):\n",
    "        tr_loss = train_epoch()\n",
    "        if epoch%5==0:\n",
    "            metric = eval_split('val')\n",
    "            print(f\"Epoch {epoch:03d} | train_loss={tr_loss:.4f} | val_{'RMSE' if HEAD_MODE=='regression' else 'ACC'}={metric:.4f}\")\n",
    "else:\n",
    "    print(\"Skip training: no rated edges.\")\n"
   ],
   "id": "be63bbc5f72ea999",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | train_loss=13.9891 | val_RMSE=3.7830\n",
      "Epoch 010 | train_loss=12.2530 | val_RMSE=3.4693\n",
      "Epoch 015 | train_loss=6.7613 | val_RMSE=2.3008\n",
      "Epoch 020 | train_loss=2.5395 | val_RMSE=1.8093\n",
      "Epoch 025 | train_loss=1.2347 | val_RMSE=1.0952\n",
      "Epoch 030 | train_loss=2.0615 | val_RMSE=1.4733\n",
      "Epoch 035 | train_loss=1.3304 | val_RMSE=1.0770\n",
      "Epoch 040 | train_loss=1.4147 | val_RMSE=1.1062\n",
      "Epoch 045 | train_loss=1.1055 | val_RMSE=1.0295\n",
      "Epoch 050 | train_loss=1.1898 | val_RMSE=1.1005\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10) Inferenz für **neue Filme** (ohne persönliche Review)",
   "id": "39b95297d520870"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:57:49.941156Z",
     "start_time": "2025-09-14T22:57:49.921614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def predict_for_user_on_movies(user_id):\n",
    "    model.eval(); head.eval()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    u_idx = torch.tensor([user_id2idx[user_id]], device=out['User'].device)\n",
    "    u_emb = out['User'][u_idx].repeat(len(movie_idx2id), 1)\n",
    "    m_emb = out['Movie']\n",
    "    pred = head(u_emb, m_emb).detach().cpu().numpy()\n",
    "    return pred  # [num_movies]\n",
    "\n",
    "# Filme ohne persönliche Bewertung identifizieren\n",
    "rated_movies_set = set([m for m in rated_dst])\n",
    "unrated_movie_mask = [mid not in rated_movies_set for mid in movie_idx2id]\n",
    "unrated_indices = np.where(unrated_movie_mask)[0]\n",
    "\n",
    "if len(unrated_indices) == 0:\n",
    "    print(\"Alle Filme haben bereits personal reviews im KG (nichts zu empfehlen).\")\n",
    "else:\n",
    "    uid0 = next(iter(user_id2idx.keys()))\n",
    "    scores_all = predict_for_user_on_movies(uid0)\n",
    "    unrated_scores = scores_all[unrated_indices]\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"movie_id\": [movie_idx2id[i] for i in unrated_indices],\n",
    "        \"pred_score\": unrated_scores\n",
    "    }).sort_values(\"pred_score\", ascending=False)\n",
    "    display(pred_df.head(10))"
   ],
   "id": "8aa645fcea3ba3b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        movie_id  pred_score\n",
       "285  movie539617    3.768758\n",
       "152  movie284053    3.711945\n",
       "36    movie12445    3.664667\n",
       "132  movie259316    3.630157\n",
       "234     movie425    3.616824\n",
       "69      movie162    3.610948\n",
       "195     movie364    3.600406\n",
       "232  movie424121    3.593978\n",
       "323     movie675    3.582785\n",
       "315   movie64688    3.578642"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>movie539617</td>\n",
       "      <td>3.768758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>movie284053</td>\n",
       "      <td>3.711945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>movie12445</td>\n",
       "      <td>3.664667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>movie259316</td>\n",
       "      <td>3.630157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>movie425</td>\n",
       "      <td>3.616824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>movie162</td>\n",
       "      <td>3.610948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>movie364</td>\n",
       "      <td>3.600406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>movie424121</td>\n",
       "      <td>3.593978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>movie675</td>\n",
       "      <td>3.582785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>movie64688</td>\n",
       "      <td>3.578642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 11) Export als neue Triples (auskommentiert – erst Backup anlegen!)",
   "id": "1e432ae5c8c40b80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:57:50.099843Z",
     "start_time": "2025-09-14T22:57:49.972329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === EXPORT: ein Tripel pro Prediction im Format:\n",
    "# movieID    ex:predictedReview    personalVote_4.00\n",
    "# mit Rundung auf 0.5er Schritte + automatisches Backup ===\n",
    "\n",
    "import os, csv, math, shutil\n",
    "from datetime import datetime\n",
    "\n",
    "def round_to_half(x: float) -> float:\n",
    "    # Rundung auf nächste 0.5 (3.66 -> 3.5, 3.99 -> 4.0)\n",
    "    return math.floor(x*2 + 0.5) / 2.0\n",
    "\n",
    "def sanitize_cell(x: str) -> str:\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    s = str(x)\n",
    "    return s.replace(\"\\t\", \" \").replace(\"\\r\", \" \").replace(\"\\n\", \" \").strip()\n",
    "\n",
    "def append_triples_safely(new_triples_df: pd.DataFrame, path: str):\n",
    "    df = new_triples_df.rename(columns={0:\"head\",1:\"rel\",2:\"tail\"})[[\"head\",\"rel\",\"tail\"]].copy()\n",
    "    for c in [\"head\",\"rel\",\"tail\"]:\n",
    "        df[c] = df[c].map(sanitize_cell)\n",
    "\n",
    "    # sorge für eine abschließende Zeile vorm Anhängen\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            try:\n",
    "                f.seek(-1, os.SEEK_END)\n",
    "                if f.read(1) != b\"\\n\":\n",
    "                    with open(path, \"ab\") as g:\n",
    "                        g.write(b\"\\n\")\n",
    "            except OSError:\n",
    "                # leere Datei\n",
    "                pass\n",
    "\n",
    "    df.to_csv(\n",
    "        path,\n",
    "        mode=\"a\",\n",
    "        header=False,\n",
    "        index=False,\n",
    "        sep=\"\\t\",\n",
    "        lineterminator=\"\\n\",\n",
    "        encoding=\"utf-8\",\n",
    "        quoting=csv.QUOTE_MINIMAL,\n",
    "        escapechar=\"\\\\\",\n",
    "    )\n",
    "\n",
    "# --- baue Triples aus pred_df ---\n",
    "if 'pred_df' in locals() and len(pred_df) > 0:\n",
    "    top = pred_df.head(TOPK_EXPORT).copy()\n",
    "\n",
    "    rows = []\n",
    "    for _, r in top.iterrows():\n",
    "        mid = r['movie_id']\n",
    "        score = float(r['pred_score'])\n",
    "\n",
    "        if HEAD_MODE == 'classification':\n",
    "            # falls Klassifikation aktiv ist, interpretiere score als Prob. und mappe auf 0..5\n",
    "            score = 5.0 * score\n",
    "\n",
    "        rounded = round_to_half(score)\n",
    "        # clamp auf 0..5 (nur zur Sicherheit)\n",
    "        rounded = max(0.0, min(5.0, rounded))\n",
    "\n",
    "        tail_value = f\"personalVote_{rounded:.2f}\"\n",
    "        rows.append([mid, \"ex:predictedReview\", tail_value])\n",
    "\n",
    "    export_df = pd.DataFrame(rows, columns=[\"head\",\"rel\",\"tail\"])\n",
    "\n",
    "    # Optional: Duplikate gegen bestehende Triples vermeiden\n",
    "    existing = pd.read_csv(KG_PATH, sep=\"\\t\", header=None, names=[\"head\",\"rel\",\"tail\"], dtype=str, keep_default_na=False, engine=\"python\")\n",
    "    merged = export_df.merge(existing.drop_duplicates(), on=[\"head\",\"rel\",\"tail\"], how=\"left\", indicator=True)\n",
    "    unique_new = merged[merged[\"_merge\"] == \"left_only\"][[\"head\",\"rel\",\"tail\"]]\n",
    "\n",
    "    print(f\"Neue Triples (nach Deduplikation): {len(unique_new)}\")\n",
    "    display(unique_new.head(10))\n",
    "\n",
    "    # --- Backup vor dem Anhängen ---\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # Backup-Verzeichnis erstellen, falls es nicht existiert\n",
    "    BACKUP_DIR = KG_PATH.parent / \"backups\"\n",
    "    BACKUP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Backup-Dateiname mit Zeitstempel\n",
    "    timestamp   = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    backup_path = BACKUP_DIR / f\"movie_kg_triples_backup_{timestamp}.tsv\"\n",
    "\n",
    "    shutil.copy2(KG_PATH, backup_path)\n",
    "    print(\"📂 Backup gespeichert unter:\", backup_path)\n",
    "\n",
    "    # --- an KG anhängen ---\n",
    "    append_triples_safely(unique_new, str(KG_PATH))\n",
    "    print(\"✅ Triples angehängt an:\", KG_PATH)\n",
    "\n",
    "else:\n",
    "    print(\"No predictions to export.\")"
   ],
   "id": "e17418565ab6c74a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neue Triples (nach Deduplikation): 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          head                 rel               tail\n",
       "0  movie539617  ex:predictedReview  personalVote_4.00\n",
       "1  movie284053  ex:predictedReview  personalVote_3.50\n",
       "2   movie12445  ex:predictedReview  personalVote_3.50\n",
       "3  movie259316  ex:predictedReview  personalVote_3.50\n",
       "4     movie425  ex:predictedReview  personalVote_3.50\n",
       "5     movie162  ex:predictedReview  personalVote_3.50\n",
       "6     movie364  ex:predictedReview  personalVote_3.50\n",
       "7  movie424121  ex:predictedReview  personalVote_3.50\n",
       "8     movie675  ex:predictedReview  personalVote_3.50\n",
       "9   movie64688  ex:predictedReview  personalVote_3.50"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>rel</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie539617</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie284053</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie12445</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie259316</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie425</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>movie162</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>movie364</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>movie424121</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>movie675</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>movie64688</td>\n",
       "      <td>ex:predictedReview</td>\n",
       "      <td>personalVote_3.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Backup gespeichert unter: ../data/kg/triples/movie_kg_triples_backup_20250915_005750.tsv\n",
      "✅ Triples angehängt an: ../data/kg/triples/movie_kg_triples.tsv\n"
     ]
    }
   ],
   "execution_count": 63
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
