{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cc7dd7d",
   "metadata": {},
   "source": [
    "# Film-KG — TSV-only Pipeline + Rekursive Traversierung\n",
    "\n",
    "Dieses Notebook:\n",
    "1) Lädt deine `movie_kg_triples.tsv`.\n",
    "2) **Backup** der TSV-Datei anlegen.\n",
    "3) Vorverarbeitung: kanonisierte Character-URIs `ex:char/<slug>` + `ex:featuresCharacter` **ins TSV anhängen** (und in den In-Memory-Graph einfügen).\n",
    "4) Ableitung:\n",
    "   - `ex:SAME_UNIVERSE` (Self-Join über Character) **nur TSV-Append**\n",
    "   - `ex:CREATIVE_PAIR` (Director×Actor ≥2) **nur TSV-Append**\n",
    "5) **Rekursive Traversierung** über `ex:SAME_UNIVERSE` (SPARQL Property Path **und** Python-BFS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb1095",
   "metadata": {},
   "source": [
    "## 0) Setup & Konfiguration"
   ]
  },
  {
   "cell_type": "code",
   "id": "0a262731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:52:03.364817Z",
     "start_time": "2025-09-15T00:52:03.035337Z"
    }
   },
   "source": [
    "!python -c \"import rdflib\" 2>/dev/null || pip -q install rdflib==7.0.0\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import shutil, re\n",
    "from datetime import datetime\n",
    "\n",
    "DATA_PATH = Path(\"../data/kg/triples/movie_kg_triples.tsv\")  # bestehende KG-Datei (TSV)\n",
    "OUT_DIR = Path(\"../data/kg/triples\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BATCH_SIZE = 50000  # Tripel je Ausgabedatei\n",
    "\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "EX     = Namespace(\"http://example.org/\")\n",
    "CHAR_NS = Namespace(str(EX) + \"char/\")\n",
    "\n",
    "print(\"Data:\", DATA_PATH.resolve())\n",
    "print(\"Output:\", OUT_DIR.resolve())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: /Users/tschaffel/PycharmProjects/letterboxd-KG/data/kg/triples/movie_kg_triples.tsv\n",
      "Output: /Users/tschaffel/PycharmProjects/letterboxd-KG/data/kg/triples\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "bf21de53",
   "metadata": {},
   "source": [
    "## 1) Daten laden (robuster TSV-Parser)"
   ]
  },
  {
   "cell_type": "code",
   "id": "106d7142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:52:03.956193Z",
     "start_time": "2025-09-15T00:52:03.378679Z"
    }
   },
   "source": [
    "g = Graph(); g.bind(\"schema\", SCHEMA); g.bind(\"ex\", EX); g.bind(\"rdf\", RDF)\n",
    "prefix_map = {\"schema\": str(SCHEMA), \"rdf\": str(RDF), \"rdfs\": str(RDFS), \"xsd\": str(XSD), \"ex\": str(EX)}\n",
    "\n",
    "def parse_term(term: str):\n",
    "    term = term.strip()\n",
    "    if len(term) >= 2 and term[0] == '\"' and term[-1] == '\"':\n",
    "        return Literal(term[1:-1])\n",
    "    if term.startswith(\"http://\") or term.startswith(\"https://\"):\n",
    "        return URIRef(term)\n",
    "    if \":\" in term:\n",
    "        pfx, local = term.split(\":\", 1)\n",
    "        if pfx in prefix_map:\n",
    "            return URIRef(prefix_map[pfx] + local)\n",
    "    return Literal(term)\n",
    "\n",
    "count = 0\n",
    "with DATA_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        parts = line.split(\"\\t\")\n",
    "        if len(parts) != 3:\n",
    "            continue\n",
    "        s, p, o = map(parse_term, parts)\n",
    "        g.add((s, p, o))\n",
    "        count += 1\n",
    "print(\"Geladene Tripel:\", count)\n",
    "print(\"Beispiel-Tripel:\")\n",
    "for i, (s,p,o) in enumerate(g):\n",
    "    print(\"-\", s, p, o)\n",
    "    if i >= 4: break\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geladene Tripel: 58601\n",
      "Beispiel-Tripel:\n",
      "- person57551 http://schema.org/name Mario Cantone\n",
      "- movie10567 http://schema.org/aggregateRating avgVote_6.548\n",
      "- movie9928 http://schema.org/genre genre35\n",
      "- movie809 http://schema.org/character Page / Elf / Nobleman / Nobleman's Son (voice)\n",
      "- person5649 http://www.w3.org/1999/02/22-rdf-syntax-ns#type http://schema.org/Person\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "ec92e839",
   "metadata": {},
   "source": [
    "## 2) Backup & TSV-Append-Helfer"
   ]
  },
  {
   "cell_type": "code",
   "id": "229bad2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:52:03.966512Z",
     "start_time": "2025-09-15T00:52:03.960832Z"
    }
   },
   "source": [
    "BACKUP_DIR = OUT_DIR / \"backups\"; BACKUP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BACKUP_PATH = BACKUP_DIR / f\"movie_kg_triples_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.tsv\"\n",
    "\n",
    "# Backup anlegen\n",
    "shutil.copy2(DATA_PATH, BACKUP_PATH)\n",
    "print(\"Backup gespeichert:\", BACKUP_PATH)\n",
    "\n",
    "def term_to_str(term):\n",
    "    if isinstance(term, URIRef):\n",
    "        # Versuche Prefix-Kurzform\n",
    "        for pfx, ns in prefix_map.items():\n",
    "            if str(term).startswith(ns):\n",
    "                return f\"{pfx}:{str(term)[len(ns):]}\"\n",
    "        return str(term)\n",
    "    elif isinstance(term, Literal):\n",
    "        s = str(term).replace('\"', '\\\"')\n",
    "        return f'\"{s}\"'\n",
    "    else:\n",
    "        return str(term)\n",
    "\n",
    "def append_triples_tsv(triples):\n",
    "    with DATA_PATH.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        for (s,p,o) in triples:\n",
    "            f.write(term_to_str(s) + \"\\t\" + term_to_str(p) + \"\\t\" + term_to_str(o) + \"\\n\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup gespeichert: ../data/kg/triples/backups/movie_kg_triples_backup_20250915_025203.tsv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "e4fd8ed2",
   "metadata": {},
   "source": [
    "## 3) Vorverarbeitung: Character-URIs + `ex:featuresCharacter` (TSV-only)"
   ]
  },
  {
   "cell_type": "code",
   "id": "4db2a6cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:52:04.204455Z",
     "start_time": "2025-09-15T00:52:03.978184Z"
    }
   },
   "source": [
    "canon_re = re.compile(r\"\\s*\\([^)]*\\)\")\n",
    "def canonize(text: str) -> str:\n",
    "    s = canon_re.sub(\"\", text)\n",
    "    return s.strip().lower()\n",
    "\n",
    "def slugify(text: str) -> str:\n",
    "    t = re.sub(r\"[^a-z0-9]+\", \"-\", text)\n",
    "    t = re.sub(r\"-+\", \"-\", t).strip(\"-\")\n",
    "    return t or \"x\"\n",
    "\n",
    "char_uri_by_canon = {}\n",
    "added_nodes = 0; added_edges = 0\n",
    "\n",
    "new_feature_triples = []  # für optionales Mitschreiben in TSV\n",
    "\n",
    "for f, _, ch in g.triples((None, SCHEMA.character, None)):\n",
    "    c = canonize(str(ch))\n",
    "    if not c:\n",
    "        continue\n",
    "    uri = char_uri_by_canon.get(c)\n",
    "    if uri is None:\n",
    "        uri = URIRef(CHAR_NS + slugify(c))\n",
    "        char_uri_by_canon[c] = uri\n",
    "        if (uri, RDF.type, EX.Character) not in g:\n",
    "            g.add((uri, RDF.type, EX.Character))\n",
    "            g.add((uri, EX.canonName, Literal(c)))\n",
    "            new_feature_triples.append((uri, RDF.type, EX.Character))\n",
    "            new_feature_triples.append((uri, EX.canonName, Literal(c)))\n",
    "            added_nodes += 1\n",
    "    if (f, EX.featuresCharacter, uri) not in g:\n",
    "        g.add((f, EX.featuresCharacter, uri))\n",
    "        new_feature_triples.append((f, EX.featuresCharacter, uri))\n",
    "        added_edges += 1\n",
    "\n",
    "print(\"Neue Character-Knoten:\", added_nodes)\n",
    "print(\"Neue featuresCharacter-Kanten:\", added_edges)\n",
    "\n",
    "# Optional: diese neuen Vorverarbeitungs-Tripel direkt ins TSV anhängen\n",
    "#if new_feature_triples:\n",
    "#    append_triples_tsv(new_feature_triples)\n",
    "#    print(\"Vorverarbeitungs-Tripel ins TSV angehängt:\", len(new_feature_triples))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neue Character-Knoten: 5392\n",
      "Neue featuresCharacter-Kanten: 6645\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "d490e560",
   "metadata": {},
   "source": [
    "## 4) SAME_UNIVERSE (Self-Join über Character) — **TSV-only**"
   ]
  },
  {
   "cell_type": "code",
   "id": "e077c560",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:52:04.237674Z",
     "start_time": "2025-09-15T00:52:04.208681Z"
    }
   },
   "source": [
    "from itertools import combinations\n",
    "films_by_char = defaultdict(list)\n",
    "for f, _, c in g.triples((None, EX.featuresCharacter, None)):\n",
    "    films_by_char[c].append(f)\n",
    "\n",
    "new_su_triples = []\n",
    "seen = set()\n",
    "for char_uri, films in films_by_char.items():\n",
    "    if len(films) < 2:\n",
    "        continue\n",
    "    films_sorted = sorted(set(films), key=str)\n",
    "    for f1, f2 in combinations(films_sorted, 2):\n",
    "        key = (str(f1), str(f2))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        triple = (f1, EX.sameUniverse, f2)\n",
    "        new_su_triples.append(triple)\n",
    "        g.add(triple)  # auch in-memory für Traversierung\n",
    "\n",
    "append_triples_tsv(new_su_triples)\n",
    "print(\"SAME_UNIVERSE Tripel angehängt:\", len(new_su_triples))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAME_UNIVERSE Tripel angehängt: 1576\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "a9c34eb4",
   "metadata": {},
   "source": [
    "## 5) CREATIVE_PAIR (Director×Actor ≥2) — **TSV-only**"
   ]
  },
  {
   "cell_type": "code",
   "id": "c1a5183a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:52:04.281758Z",
     "start_time": "2025-09-15T00:52:04.242826Z"
    }
   },
   "source": [
    "pair_counts = defaultdict(int)\n",
    "for f, _, d in g.triples((None, SCHEMA.director, None)):\n",
    "    for _, _, a in g.triples((f, SCHEMA.actor, None)):\n",
    "        pair_counts[(d, a)] += 1\n",
    "\n",
    "new_cp_triples = []\n",
    "for (d, a), n in pair_counts.items():\n",
    "    if n >= 2:\n",
    "        new_cp_triples.append((d, EX.creativePair, a))\n",
    "        new_cp_triples.append((d, EX.creativePairRoles, Literal(\"Director,Actor\")))\n",
    "        new_cp_triples.append((d, EX.creativePairCount, Literal(n)))\n",
    "        g.add((d, EX.creativePair, a))\n",
    "        g.add((d, EX.creativePairRoles, Literal(\"Director,Actor\")))\n",
    "        g.add((d, EX.creativePairCount, Literal(n)))\n",
    "\n",
    "append_triples_tsv(new_cp_triples)\n",
    "print(\"CREATIVE_PAIR Tripel angehängt:\", len(new_cp_triples))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATIVE_PAIR Tripel angehängt: 1644\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "fdf6e52b",
   "metadata": {},
   "source": [
    "## 6) Rekursive Traversierung über `ex:SAME_UNIVERSE`\n",
    "Wir bieten **zwei Wege**:\n",
    "\n",
    "**A) SPARQL Property Path** (`ex:SAME_UNIVERSE+`) — bequem, wenn du einen Seed kennst.\n",
    "\n",
    "**B) Python-BFS** — schnell und vielseitig (z. B. mit Tiefenlimit)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO",
   "id": "5fd11a2918bdf927"
  },
  {
   "cell_type": "markdown",
   "id": "51558ad0",
   "metadata": {},
   "source": [
    "### 6A) SPARQL Property Path"
   ]
  },
  {
   "cell_type": "code",
   "id": "5fc96e44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T01:04:34.230142Z",
     "start_time": "2025-09-15T01:04:34.215260Z"
    }
   },
   "source": [
    "def sparql_same_universe(seed_uri_str: str, limit=200):\n",
    "    seed = URIRef(seed_uri_str) if seed_uri_str.startswith(\"http\") else URIRef(str(EX) + seed_uri_str)\n",
    "    q = (\n",
    "        \"PREFIX ex: <http://example.org/>\\n\"\n",
    "        \"SELECT DISTINCT ?g WHERE {\\n\"\n",
    "        f\"  VALUES ?seed {{ <{seed}> }}\\n\"\n",
    "        \"  ?seed ex:sameUniverse+ ?g .\\n\"\n",
    "        \"} LIMIT \" + str(limit)\n",
    "    )\n",
    "    return [str(row[0]) for row in g.query(q)]\n",
    "\n",
    "# Beispiel (anpassen!):\n",
    "results = sparql_same_universe(\"movie181808\")\n",
    "print(len(results), \"Filme im selben Universe\")\n",
    "results[:10]\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Filme im selben Universe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "c37784ae",
   "metadata": {},
   "source": [
    "### 6B) Python-BFS (mit optionalem Tiefenlimit)"
   ]
  },
  {
   "cell_type": "code",
   "id": "aac0b0b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T01:04:42.554132Z",
     "start_time": "2025-09-15T01:04:42.538511Z"
    }
   },
   "source": [
    "from collections import deque\n",
    "\n",
    "def bfs_same_universe(seed_uri_str: str, max_hops=None):\n",
    "    seed = URIRef(seed_uri_str) if seed_uri_str.startswith(\"http\") else URIRef(str(EX) + seed_uri_str)\n",
    "    # Adjazenz (beide Richtungen behandeln, falls du die Kante nur einseitig erzeugst)\n",
    "    adj = defaultdict(set)\n",
    "    for s, _, o in g.triples((None, EX.sameUniverse, None)):\n",
    "        adj[s].add(o)\n",
    "        adj[o].add(s)\n",
    "\n",
    "    seen = {seed}\n",
    "    q = deque([(seed, 0)])\n",
    "    order = []\n",
    "    while q:\n",
    "        node, d = q.popleft()\n",
    "        order.append((node, d))\n",
    "        if max_hops is not None and d >= max_hops:\n",
    "            continue\n",
    "        for nei in adj.get(node, []):\n",
    "            if nei not in seen:\n",
    "                seen.add(nei)\n",
    "                q.append((nei, d+1))\n",
    "    return order\n",
    "\n",
    "# Beispiel (anpassen!):\n",
    "comp = bfs_same_universe(\"movie181808\", max_hops=6)\n",
    "print(\"Gefundene Filme:\", len(comp))\n",
    "[str(n) for n,_ in comp[:10]]\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gefundene Filme: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://example.org/movie181808']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "164b23a9",
   "metadata": {},
   "source": [
    "**Fertig!** Dieses Notebook hängt nur an die TSV-Datei an (nach Backup) und erzeugt **keine** zusätzlichen `.nt`/`.ttl` Files. Für die Traversierung kannst du entweder SPARQL (Property Path) oder den BFS-Helfer verwenden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
