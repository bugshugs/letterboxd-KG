{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2393886",
   "metadata": {},
   "source": [
    "\n",
    "# LO2 with **Datalog** — Robust (Patched)\n",
    "We keep Datalog for the **core logic** (exclude watched, mark watchlist),\n",
    "and compute **genre/director likes/dislikes** directly in Python (stable).\n",
    "\n",
    "**Datalog:** `recommendedBase(U,N,Y) :- candidateFor(U,N,Y) ∧ not watched_fact(U,N,Y)`\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "55b60b11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:24:24.113097Z",
     "start_time": "2025-09-12T11:24:24.077931Z"
    }
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "import ast, re\n",
    "from pathlib import Path\n",
    "\n",
    "# Auto-detect project root\n",
    "here = Path.cwd()\n",
    "candidate = here\n",
    "while candidate != candidate.parent and not (candidate / \"data\").exists():\n",
    "    candidate = candidate.parent\n",
    "project_root = candidate if (candidate / \"data\").exists() else Path(\".\")\n",
    "print(\"Detected project_root:\", project_root.resolve())\n",
    "\n",
    "# Paths\n",
    "watched_path   = project_root / \"data\" / \"letterboxd_export\" / \"watched.csv\"\n",
    "watchlist_path = project_root / \"data\" / \"letterboxd_export\" / \"watchlist.csv\"\n",
    "candidates_path= project_root / \"data\" / \"kg\" / \"rerank_with_embedding_results.csv\"\n",
    "\n",
    "# enriched-merged uploaded in this session or local fallback\n",
    "enriched_uploaded = Path(\"/mnt/data/0bf2f757-dc8c-43d8-9f82-d2705737b4fe.csv\")\n",
    "enriched_local = project_root / \"data\" / \"enriched_merged.csv\"\n",
    "enriched_path = enriched_uploaded if enriched_uploaded.exists() else enriched_local\n",
    "print(\"Using enriched file:\", enriched_path)\n",
    "\n",
    "out_csv = project_root / \"data\" / \"kg\" / \"rerank_by_logical_rules.csv\"\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected project_root: /Users/tschaffel/PycharmProjects/letterboxd-KG\n",
      "Using enriched file: /Users/tschaffel/PycharmProjects/letterboxd-KG/data/enriched_merged.csv\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "id": "98e12f65",
   "metadata": {},
   "source": [
    "## Load & Normalize"
   ]
  },
  {
   "cell_type": "code",
   "id": "644366e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:24:24.256154Z",
     "start_time": "2025-09-12T11:24:24.121686Z"
    }
   },
   "source": [
    "\n",
    "watched_df = pd.read_csv(watched_path)\n",
    "watchlist_df = pd.read_csv(watchlist_path)\n",
    "recs_df = pd.read_csv(candidates_path)\n",
    "enriched_df = pd.read_csv(enriched_path)\n",
    "\n",
    "# lowercase columns\n",
    "for df in (watched_df, watchlist_df, recs_df, enriched_df):\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "def pick(cols, opts):\n",
    "    for o in opts:\n",
    "        if o in cols: return o\n",
    "    return None\n",
    "\n",
    "# pick columns\n",
    "watched_name_col = pick(watched_df.columns, [\"name\",\"film name\",\"title\"])\n",
    "watched_year_col = pick(watched_df.columns, [\"year\",\"release year\",\"release_year\"])\n",
    "watch_name_col   = pick(watchlist_df.columns, [\"name\",\"film name\",\"title\",\"candidate_title\",\"movie\",\"movie_title\",\"original_title\"])\n",
    "watch_year_col   = pick(watchlist_df.columns, [\"year\",\"release year\",\"release_year\",\"releaseyear\"])\n",
    "recs_name_col    = pick(recs_df.columns, [\"candidate_title\",\"name\",\"title\",\"movie_title\",\"original_title\"])\n",
    "recs_year_col    = pick(recs_df.columns, [\"year\",\"release_year\",\"candidate_year\",\"releaseyear\",\"year_x\",\"year_y\"])\n",
    "en_title_col     = pick(enriched_df.columns, [\"title\",\"name\"])\n",
    "en_year_col      = pick(enriched_df.columns, [\"year\",\"release_year\"])\n",
    "en_rating_col    = pick(enriched_df.columns, [\"rating\",\"myrating\",\"rating10\",\"rating_10\"])\n",
    "en_genres_col    = pick(enriched_df.columns, [\"genres\",\"genre\",\"tmdb_genres\"])\n",
    "en_dir_col       = pick(enriched_df.columns, [\"director\",\"directors\",\"tmdb_directors\"])\n",
    "\n",
    "assert all([watched_name_col, watched_year_col, watch_name_col, watch_year_col, recs_name_col, recs_year_col, en_title_col, en_year_col, en_rating_col, en_genres_col, en_dir_col])\n",
    "\n",
    "def norm_name(s): return s.astype(str).str.strip().str.lower()\n",
    "def norm_year(s):  return s.astype(str).str.extract(r\"(\\d{4})\", expand=False).fillna(s.astype(str).str.strip())\n",
    "\n",
    "for df_, ncol, ycol in [(watched_df, watched_name_col, watched_year_col),\n",
    "                        (watchlist_df, watch_name_col, watch_year_col),\n",
    "                        (recs_df, recs_name_col, recs_year_col),\n",
    "                        (enriched_df, en_title_col, en_year_col)]:\n",
    "    df_[\"name_norm\"] = norm_name(df_[ncol])\n",
    "    df_[\"year_str\"]  = norm_year(df_[ycol])\n",
    "\n",
    "# parse list-like fields to pure lists of names (strip URLs)\n",
    "def parse_list(cell):\n",
    "    if pd.isna(cell): return []\n",
    "    txt = str(cell)\n",
    "    try:\n",
    "        lst = ast.literal_eval(txt)\n",
    "        out = []\n",
    "        if isinstance(lst, list):\n",
    "            for it in lst:\n",
    "                if isinstance(it, str):\n",
    "                    out.append(it.split(':',1)[0].strip())\n",
    "                else:\n",
    "                    out.append(str(it))\n",
    "        return out\n",
    "    except Exception:\n",
    "        hits = re.findall(r\"'([^':]+):\", txt)\n",
    "        return [h.strip() for h in hits]\n",
    "\n",
    "enriched_df[\"genre_list\"]    = enriched_df[en_genres_col].apply(parse_list)\n",
    "enriched_df[\"director_list\"] = enriched_df[en_dir_col].apply(parse_list)\n",
    "\n",
    "# aggregate metadata per (name_norm, year_str)\n",
    "def set_union(series_of_lists):\n",
    "    s = set()\n",
    "    for lst in series_of_lists:\n",
    "        if isinstance(lst, list):\n",
    "            s.update(lst)\n",
    "        elif pd.isna(lst):\n",
    "            continue\n",
    "        else:\n",
    "            s.add(str(lst))\n",
    "    return sorted(s)\n",
    "\n",
    "agg_meta = (enriched_df\n",
    "            .groupby([\"name_norm\",\"year_str\"], as_index=False)\n",
    "            .agg(genre_list=(\"genre_list\", set_union),\n",
    "                 director_list=(\"director_list\", set_union)))\n",
    "\n",
    "recs_df = recs_df.merge(agg_meta, on=[\"name_norm\",\"year_str\"], how=\"left\")\n",
    "\n",
    "# force to lists\n",
    "def ensure_list(x):\n",
    "    if isinstance(x, list): return x\n",
    "    if pd.isna(x): return []\n",
    "    return [str(x)]\n",
    "recs_df[\"genre_list\"] = recs_df[\"genre_list\"].apply(ensure_list)\n",
    "recs_df[\"director_list\"] = recs_df[\"director_list\"].apply(ensure_list)\n",
    "\n",
    "watched_pairs   = set(zip(watched_df[\"name_norm\"], watched_df[\"year_str\"]))\n",
    "watchlist_pairs = set(zip(watchlist_df[\"name_norm\"], watchlist_df[\"year_str\"]))\n"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "id": "b6ff1056",
   "metadata": {},
   "source": [
    "## Preferences (likes/dislikes) from ratings"
   ]
  },
  {
   "cell_type": "code",
   "id": "b76eb766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:24:24.285193Z",
     "start_time": "2025-09-12T11:24:24.262944Z"
    }
   },
   "source": [
    "\n",
    "rated = enriched_df.dropna(subset=[en_rating_col]).copy()\n",
    "rmax = rated[en_rating_col].max()\n",
    "scale = 10.0 if rmax > 5 else 5.0\n",
    "like_th = 7.0 if scale == 10.0 else 3.5\n",
    "dislike_th = 3.0 if scale == 10.0 else 1.5\n",
    "min_count = 2\n",
    "\n",
    "genres_long = rated.explode(\"genre_list\").dropna(subset=[\"genre_list\"])\n",
    "dirs_long   = rated.explode(\"director_list\").dropna(subset=[\"director_list\"])\n",
    "\n",
    "g_stats = genres_long.groupby(\"genre_list\")[en_rating_col].agg(['mean','count']).reset_index().rename(columns={'genre_list':'genre'})\n",
    "d_stats = dirs_long.groupby(\"director_list\")[en_rating_col].agg(['mean','count']).reset_index().rename(columns={'director_list':'director'})\n",
    "\n",
    "liked_genres    = set(g_stats[(g_stats['mean']>=like_th)    & (g_stats['count']>=min_count)]['genre'])\n",
    "disliked_genres = set(g_stats[(g_stats['mean']<=dislike_th) & (g_stats['count']>=min_count)]['genre'])\n",
    "liked_dirs      = set(d_stats[(d_stats['mean']>=like_th)    & (d_stats['count']>=min_count)]['director'])\n",
    "disliked_dirs   = set(d_stats[(d_stats['mean']<=dislike_th) & (d_stats['count']>=min_count)]['director'])\n",
    "\n",
    "print(\"Scale:\", scale, \"| like_th:\", like_th, \"| dislike_th:\", dislike_th)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale: 5.0 | like_th: 3.5 | dislike_th: 1.5\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "id": "8c4026da",
   "metadata": {},
   "source": [
    "## Datalog core (only recommended & watchBoost)"
   ]
  },
  {
   "cell_type": "code",
   "id": "d32586e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:24:24.430669Z",
     "start_time": "2025-09-12T11:24:24.291436Z"
    }
   },
   "source": [
    "\n",
    "use_pyDatalog = False\n",
    "try:\n",
    "    from pyDatalog import pyDatalog\n",
    "    use_pyDatalog = True\n",
    "    print(\"pyDatalog is available — using it.\")\n",
    "except Exception as e:\n",
    "    print(\"pyDatalog not available, fallback will be used:\", e)\n",
    "\n",
    "USER = \"tobias\"\n",
    "\n",
    "\n",
    "if use_pyDatalog:\n",
    "    pyDatalog.clear()\n",
    "    pyDatalog.create_terms('watched_fact, candidateFor, onWatchlist, '\n",
    "                           'recommendedBase, recommended, watchBoost, U,N,Y')\n",
    "    for n,y in watched_pairs:   +watched_fact(USER,n,y)\n",
    "    for n,y in watchlist_pairs: +onWatchlist(USER,n,y)\n",
    "    for _,row in recs_df.iterrows():\n",
    "        +candidateFor(USER,row[\"name_norm\"],row[\"year_str\"])\n",
    "    recommendedBase(U,N,Y) <= candidateFor(U,N,Y) & ~watched_fact(U,N,Y)\n",
    "    recommended(U,N,Y)     <= recommendedBase(U,N,Y)\n",
    "    watchBoost(U,N,Y)      <= recommendedBase(U,N,Y) & onWatchlist(U,N,Y)\n",
    "\n",
    "    def qset(s):\n",
    "        ans = pyDatalog.ask(s)\n",
    "        return set(tuple(x) for x in (ans.answers if ans else []))\n",
    "\n",
    "    all_pairs   = qset(f'recommended(\"{USER}\", N, Y)')\n",
    "    watch_pairs = qset(f'watchBoost(\"{USER}\", N, Y)')\n",
    "\n",
    "    if all_pairs:\n",
    "        rec_df = pd.DataFrame(list(all_pairs), columns=[\"name_norm\",\"year_str\"])\n",
    "        out = recs_df.merge(rec_df, on=[\"name_norm\",\"year_str\"], how=\"inner\")\n",
    "    else:\n",
    "        out = recs_df.iloc[0:0].copy()\n",
    "\n",
    "    out[\"watchlist_priority\"] = list(map(lambda p: p in watch_pairs, zip(out[\"name_norm\"], out[\"year_str\"])))\n",
    "\n",
    "else:\n",
    "    # Fallback: pure pandas for 'recommended' and 'watchlist'\n",
    "    cand_pairs = list(zip(recs_df[\"name_norm\"], recs_df[\"year_str\"]))\n",
    "    keep_mask = [pair not in watched_pairs for pair in cand_pairs]\n",
    "    out = recs_df.loc[keep_mask].copy()\n",
    "    out[\"watchlist_priority\"] = list(map(lambda p: p in watchlist_pairs, zip(out[\"name_norm\"], out[\"year_str\"])))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyDatalog is available — using it.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "id": "dc187a2a",
   "metadata": {},
   "source": [
    "## Compute boosts/penalties (Python) & Score"
   ]
  },
  {
   "cell_type": "code",
   "id": "e2150f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:24:24.444866Z",
     "start_time": "2025-09-12T11:24:24.439527Z"
    }
   },
   "source": [
    "\n",
    "def any_in(candidate_list, prefer_set):\n",
    "    try:\n",
    "        return any(x in prefer_set for x in (candidate_list or []))\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "out[\"genre_boost\"]      = out[\"genre_list\"].apply(lambda lst: any_in(lst, liked_genres))\n",
    "out[\"director_boost\"]   = out[\"director_list\"].apply(lambda lst: any_in(lst, liked_dirs))\n",
    "out[\"genre_penalty\"]    = out[\"genre_list\"].apply(lambda lst: any_in(lst, disliked_genres))\n",
    "out[\"director_penalty\"] = out[\"director_list\"].apply(lambda lst: any_in(lst, disliked_dirs))\n",
    "\n",
    "# Weights\n",
    "w_watch, w_glike, w_dlike, w_gbad, w_dbad = 2, 1, 2, 1, 2\n",
    "out[\"score\"] = (out[\"watchlist_priority\"].astype(int)*w_watch +\n",
    "                out[\"genre_boost\"].astype(int)*w_glike +\n",
    "                out[\"director_boost\"].astype(int)*w_dlike -\n",
    "                out[\"genre_penalty\"].astype(int)*w_gbad -\n",
    "                out[\"director_penalty\"].astype(int)*w_dbad)\n",
    "\n",
    "sort_cols, ascending = [\"score\"], [False]\n",
    "if \"rank\" in out.columns: sort_cols.append(\"rank\"); ascending.append(True)\n",
    "out_sorted = out.sort_values(by=sort_cols, ascending=ascending).reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "ad64c820",
   "metadata": {},
   "source": [
    "## Save & Summary"
   ]
  },
  {
   "cell_type": "code",
   "id": "d366c57f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:24:24.460650Z",
     "start_time": "2025-09-12T11:24:24.450748Z"
    }
   },
   "source": [
    "\n",
    "out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_sorted.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv.resolve())\n",
    "\n",
    "summary = {\n",
    "    \"candidates_total\": int(len(recs_df)),\n",
    "    \"recommended_total\": int(len(out_sorted)),\n",
    "    \"watchlist_priority_true\": int(out_sorted[\"watchlist_priority\"].sum()),\n",
    "    \"genre_boost_true\": int(out_sorted[\"genre_boost\"].sum()),\n",
    "    \"director_boost_true\": int(out_sorted[\"director_boost\"].sum()),\n",
    "    \"genre_penalty_true\": int(out_sorted[\"genre_penalty\"].sum()),\n",
    "    \"director_penalty_true\": int(out_sorted[\"director_penalty\"].sum()),\n",
    "    \"top5\": list(out_sorted.head(5).get(\"candidate_title\", out_sorted.head(5).get(\"name\")).astype(str))\n",
    "}\n",
    "summary\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/tschaffel/PycharmProjects/letterboxd-KG/data/kg/rerank_by_logical_rules.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'candidates_total': 200,\n",
       " 'recommended_total': 200,\n",
       " 'watchlist_priority_true': 17,\n",
       " 'genre_boost_true': 0,\n",
       " 'director_boost_true': 0,\n",
       " 'genre_penalty_true': 0,\n",
       " 'director_penalty_true': 0,\n",
       " 'top5': ['Breakfast on Pluto',\n",
       "  'The Matrix Resurrections',\n",
       "  'The Last King of Scotland',\n",
       "  'The Talented Mr. Ripley',\n",
       "  'Sunshine']}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T11:24:24.484019Z",
     "start_time": "2025-09-12T11:24:24.476261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "The code in the previous cells is in big parts AI generated by the free and paid version of ChatGPT and was afterwards heavily adapted by me. Since it is not possible to accurately say which parts were originaly AI generated by wich promt, I have included all prompts that were used on this file here.\n",
    "These following prompts were used:\n",
    "\n",
    "    \"\"Beispiel: Zeig, dass du mit Regeln ausschließen kannst, dass dir Filme empfohlen werden, die du schon gesehen hast – das ist eine logische Restriktion, kein Embedding-Thema.\" ich würde gern damit beginnen\"\n",
    "\n",
    "    \"ja bitte, mach das. bitte gib das notebook als .ipynb file\"\n",
    "\n",
    "    \"kannst du in dem jupyter notebook datalog für die anwendung der regeln verwenden?\"\n",
    "\n",
    "    \"Ja, Genre und Regisseur Regeln sollen auch noch rein. Dafür sollte ich zuerst erkennen, welche Regisseure und welche Genres in den Daten gut bewertet wurden, oder? Also dafür sollte ich wahrscheinlich mein Ebedding verwenden?\"\n",
    "\n",
    "    \"pyDatalog is available — using it.\n",
    "        ---------------------------------------------------------------------------\n",
    "        AttributeError                            Traceback (most recent call last)\n",
    "        Cell In[6], line 48\n",
    "             46 all_pairs   = qset(f'recommended(\"{USER}\", N, Y)')\n",
    "             47 watch_pairs = qset(f'watchBoost(\"{USER}\", N, Y)')\n",
    "        ---> 48 g_like      = qset(f'genreBoost(\"{USER}\", N, Y)')\n",
    "             49 d_like      = qset(f'dirBoost(\"{USER}\", N, Y)')\n",
    "             50 g_bad       = qset(f'genrePenalty(\"{USER}\", N, Y)')\n",
    "\n",
    "        Cell In[6], line 43, in qset(s)\n",
    "             42 def qset(s):\n",
    "        ---> 43     ans = pyDatalog.ask(s);\n",
    "             44     return set(tuple(x) for x in (ans.answers if ans else []))\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyDatalog.py:111, in ask(code)\n",
    "            109 def ask(code):\n",
    "            110     \"\"\"returns the result of the query contained in the code string\"\"\"\n",
    "        --> 111     return pyParser.ask(code)\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:841, in ask(code)\n",
    "            839 add_symbols(code.co_names, newglobals)\n",
    "            840 parsed_code = eval(code, newglobals)\n",
    "        --> 841 a = parsed_code.ask()\n",
    "            842 return Answer.make(a)\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:577, in Query.ask(self)\n",
    "            576 def ask(self):\n",
    "        --> 577     self._data = Body(self.pre_calculations, self).ask()\n",
    "            578     self.todo = None\n",
    "            579     return self._data\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:693, in Body.ask(self)\n",
    "            691 \"\"\" resolve the query and determine the values of its variables\"\"\"\n",
    "            692 literal = self.literal()\n",
    "        --> 693 self._data = literal.lua.ask()\n",
    "            694 literal.todo, self.todo = None, None\n",
    "            695 - (literal <= self) # delete the temporary clause\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:513, in Literal.ask(self)\n",
    "            511 todo, arg = (SEARCH, (Ts.Goal, ))\n",
    "            512 while todo:\n",
    "        --> 513     todo, arg = todo(*arg)\n",
    "            515 if Ts.Goal.facts is True:\n",
    "            516     return True\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:812, in Subgoal.search(self)\n",
    "            808         raise util.DatalogError(\"Error: right hand side of comparison must be bound: %s\"\n",
    "            809                             % literal.pred.id, None, None)\n",
    "            810     return self.next_step()\n",
    "        --> 812 raise AttributeError(\"Predicate without definition (or error in resolver): %s\" % literal.pred.id)\n",
    "\n",
    "        AttributeError: Predicate without definition (or error in resolver): film_genre/3\"\n",
    "\n",
    "    \"---------------------------------------------------------------------------\n",
    "        NameError                                 Traceback (most recent call last)\n",
    "        Cell In[3], line 5\n",
    "              2 def has_any(lst, S):\n",
    "              3     return any(x in S for x in (lst or []))\n",
    "        ----> 5 recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\n",
    "              6 recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\n",
    "              7 recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/series.py:4924, in Series.apply(self, func, convert_dtype, args, by_row, **kwargs)\n",
    "           4789 def apply(\n",
    "           4790     self,\n",
    "           4791     func: AggFuncType,\n",
    "           (...)   4796     **kwargs,\n",
    "           4797 ) -> DataFrame | Series:\n",
    "           4798     \"\"\"\n",
    "           4799     Invoke function on values of Series.\n",
    "           4800\n",
    "           (...)   4915     dtype: float64\n",
    "           4916     \"\"\"\n",
    "           4917     return SeriesApply(\n",
    "           4918         self,\n",
    "           4919         func,\n",
    "           4920         convert_dtype=convert_dtype,\n",
    "           4921         by_row=by_row,\n",
    "           4922         args=args,\n",
    "           4923         kwargs=kwargs,\n",
    "        -> 4924     ).apply()\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1427, in SeriesApply.apply(self)\n",
    "           1424     return self.apply_compat()\n",
    "           1426 # self.func is Callable\n",
    "        -> 1427 return self.apply_standard()\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1507, in SeriesApply.apply_standard(self)\n",
    "           1501 # row-wise access\n",
    "           1502 # apply doesn't have a na_action keyword and for backward compat reasons\n",
    "           1503 # we need to give na_action=\"ignore\" for categorical data.\n",
    "           1504 # TODO: remove the na_action=\"ignore\" when that default has been changed in\n",
    "           1505 #  Categorical (GH51645).\"\n",
    "\n",
    "    \"---------------------------------------------------------------------------\n",
    "        TypeError                                 Traceback (most recent call last)\n",
    "        Cell In[5], line 5\n",
    "              2 def has_any(lst, S):\n",
    "              3     return any(x in S for x in (lst or []))\n",
    "        ----> 5 recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\n",
    "              6 recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\n",
    "              7 recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/series.py:4924, in Series.apply(self, func, convert_dtype, args, by_row, **kwargs)\n",
    "           4789 def apply(\n",
    "           4790     self,\n",
    "           4791     func: AggFuncType,\n",
    "           (...)   4796     **kwargs,\n",
    "           4797 ) -> DataFrame | Series:\n",
    "           4798     \"\"\"\n",
    "           4799     Invoke function on values of Series.\n",
    "           4800\n",
    "           (...)   4915     dtype: float64\n",
    "           4916     \"\"\"\n",
    "           4917     return SeriesApply(\n",
    "           4918         self,\n",
    "           4919         func,\n",
    "           4920         convert_dtype=convert_dtype,\n",
    "           4921         by_row=by_row,\n",
    "           4922         args=args,\n",
    "           4923         kwargs=kwargs,\n",
    "        -> 4924     ).apply()\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1427, in SeriesApply.apply(self)\n",
    "           1424     return self.apply_compat()\n",
    "           1426 # self.func is Callable\n",
    "        -> 1427 return self.apply_standard()\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1507, in SeriesApply.apply_standard(self)\n",
    "           1501 # row-wise access\n",
    "           1502 # apply doesn't have a na_action keyword and for backward compat reasons\n",
    "           1503 # we need to give na_action=\"ignore\" for categorical data.\n",
    "           1504 # TODO: remove the na_action=\"ignore\" when that default has been changed in\n",
    "           1505 #  Categorical (GH51645).\n",
    "           1506 action = \"ignore\" if isinstance(obj.dtype, CategoricalDtype) else None\n",
    "        -> 1507 mapped = obj._map_values(\n",
    "           1508     mapper=curried, na_action=action, convert=self.convert_dtype\n",
    "           1509 )\n",
    "           1511 if len(mapped) and isinstance(mapped[0], ABCSeries):\n",
    "           1512     # GH#43986 Need to do list(mapped) in order to get treated as nested\n",
    "           1513     #  See also GH#25959 regarding EA support\n",
    "           1514     return obj._constructor_expanddim(list(mapped), index=obj.index)\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/base.py:921, in IndexOpsMixin._map_values(self, mapper, na_action, convert)\n",
    "            918 if isinstance(arr, ExtensionArray):\n",
    "            919     return arr.map(mapper, na_action=na_action)\n",
    "        --> 921 return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/algorithms.py:1743, in map_array(arr, mapper, na_action, convert)\n",
    "           1741 values = arr.astype(object, copy=False)\n",
    "           1742 if na_action is None:\n",
    "        -> 1743     return lib.map_infer(values, mapper, convert=convert)\n",
    "           1744 else:\n",
    "           1745     return lib.map_infer_mask(\n",
    "           1746         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n",
    "           1747     )\n",
    "\n",
    "        File lib.pyx:2972, in pandas._libs.lib.map_infer()\n",
    "\n",
    "        Cell In[5], line 5, in <lambda>(lst)\n",
    "              2 def has_any(lst, S):\n",
    "              3     return any(x in S for x in (lst or []))\n",
    "        ----> 5 recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\n",
    "              6 recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\n",
    "              7 recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\n",
    "\n",
    "        Cell In[5], line 3, in has_any(lst, S)\n",
    "              2 def has_any(lst, S):\n",
    "        ----> 3     return any(x in S for x in (lst or []))\n",
    "\n",
    "        TypeError: 'float' object is not iterable\"\n",
    "\n",
    "    \"---------------------------------------------------------------------------\n",
    "        AttributeError                            Traceback (most recent call last)\n",
    "        Cell In[5], line 41\n",
    "             39 all_pairs   = qset(f'recommended(\"{USER}\", N, Y)')\n",
    "             40 watch_pairs = qset(f'watchBoost(\"{USER}\", N, Y)')\n",
    "        ---> 41 g_like      = qset(f'genreBoost(\"{USER}\", N, Y)')\n",
    "             42 d_like      = qset(f'dirBoost(\"{USER}\", N, Y)')\n",
    "             43 g_bad       = qset(f'genrePenalty(\"{USER}\", N, Y)')\n",
    "\n",
    "        Cell In[5], line 36, in qset(s)\n",
    "             35 def qset(s):\n",
    "        ---> 36     ans = pyDatalog.ask(s)\n",
    "             37     return set(tuple(x) for x in (ans.answers if ans else []))\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyDatalog.py:111, in ask(code)\n",
    "            109 def ask(code):\n",
    "            110     \"\"\"returns the result of the query contained in the code string\"\"\"\n",
    "        --> 111     return pyParser.ask(code)\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:841, in ask(code)\n",
    "            839 add_symbols(code.co_names, newglobals)\n",
    "            840 parsed_code = eval(code, newglobals)\n",
    "        --> 841 a = parsed_code.ask()\n",
    "            842 return Answer.make(a)\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:577, in Query.ask(self)\n",
    "            576 def ask(self):\n",
    "        --> 577     self._data = Body(self.pre_calculations, self).ask()\n",
    "            578     self.todo = None\n",
    "            579     return self._data\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:693, in Body.ask(self)\n",
    "            691 \"\"\" resolve the query and determine the values of its variables\"\"\"\n",
    "            692 literal = self.literal()\n",
    "        --> 693 self._data = literal.lua.ask()\n",
    "            694 literal.todo, self.todo = None, None\n",
    "            695 - (literal <= self) # delete the temporary clause\n",
    "\n",
    "        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:513, in Literal.ask(self)\n",
    "            511 todo, arg = (SEARCH, (Ts.Goal, ))\"\n",
    "\n",
    "'''"
   ],
   "id": "93e70991153b3838",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe code in the previous cells is in big parts AI generated by the free and paid version of ChatGPT and was afterwards heavily adapted by me. Since it is not possible to accurately say which parts were originaly AI generated by wich promt, I have included all prompts that were used on this file here.\\nThese following prompts were used:\\n\\n    \"\"Beispiel: Zeig, dass du mit Regeln ausschließen kannst, dass dir Filme empfohlen werden, die du schon gesehen hast – das ist eine logische Restriktion, kein Embedding-Thema.\" ich würde gern damit beginnen\"\\n\\n    \"ja bitte, mach das. bitte gib das notebook als .ipynb file\"\\n\\n    \"kannst du in dem jupyter notebook datalog für die anwendung der regeln verwenden?\"\\n\\n    \"Ja, Genre und Regisseur Regeln sollen auch noch rein. Dafür sollte ich zuerst erkennen, welche Regisseure und welche Genres in den Daten gut bewertet wurden, oder? Also dafür sollte ich wahrscheinlich mein Ebedding verwenden?\"\\n\\n    \"pyDatalog is available — using it.\\n        ---------------------------------------------------------------------------\\n        AttributeError                            Traceback (most recent call last)\\n        Cell In[6], line 48\\n             46 all_pairs   = qset(f\\'recommended(\"{USER}\", N, Y)\\')\\n             47 watch_pairs = qset(f\\'watchBoost(\"{USER}\", N, Y)\\')\\n        ---> 48 g_like      = qset(f\\'genreBoost(\"{USER}\", N, Y)\\')\\n             49 d_like      = qset(f\\'dirBoost(\"{USER}\", N, Y)\\')\\n             50 g_bad       = qset(f\\'genrePenalty(\"{USER}\", N, Y)\\')\\n\\n        Cell In[6], line 43, in qset(s)\\n             42 def qset(s):\\n        ---> 43     ans = pyDatalog.ask(s);\\n             44     return set(tuple(x) for x in (ans.answers if ans else []))\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyDatalog.py:111, in ask(code)\\n            109 def ask(code):\\n            110     \"\"\"returns the result of the query contained in the code string\"\"\"\\n        --> 111     return pyParser.ask(code)\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:841, in ask(code)\\n            839 add_symbols(code.co_names, newglobals)\\n            840 parsed_code = eval(code, newglobals)\\n        --> 841 a = parsed_code.ask()\\n            842 return Answer.make(a)\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:577, in Query.ask(self)\\n            576 def ask(self):\\n        --> 577     self._data = Body(self.pre_calculations, self).ask()\\n            578     self.todo = None\\n            579     return self._data\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:693, in Body.ask(self)\\n            691 \"\"\" resolve the query and determine the values of its variables\"\"\"\\n            692 literal = self.literal()\\n        --> 693 self._data = literal.lua.ask()\\n            694 literal.todo, self.todo = None, None\\n            695 - (literal <= self) # delete the temporary clause\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:513, in Literal.ask(self)\\n            511 todo, arg = (SEARCH, (Ts.Goal, ))\\n            512 while todo:\\n        --> 513     todo, arg = todo(*arg)\\n            515 if Ts.Goal.facts is True:\\n            516     return True\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:812, in Subgoal.search(self)\\n            808         raise util.DatalogError(\"Error: right hand side of comparison must be bound: %s\"\\n            809                             % literal.pred.id, None, None)\\n            810     return self.next_step()\\n        --> 812 raise AttributeError(\"Predicate without definition (or error in resolver): %s\" % literal.pred.id)\\n\\n        AttributeError: Predicate without definition (or error in resolver): film_genre/3\"\\n\\n    \"---------------------------------------------------------------------------\\n        NameError                                 Traceback (most recent call last)\\n        Cell In[3], line 5\\n              2 def has_any(lst, S):\\n              3     return any(x in S for x in (lst or []))\\n        ----> 5 recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\\n              6 recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\\n              7 recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/series.py:4924, in Series.apply(self, func, convert_dtype, args, by_row, **kwargs)\\n           4789 def apply(\\n           4790     self,\\n           4791     func: AggFuncType,\\n           (...)   4796     **kwargs,\\n           4797 ) -> DataFrame | Series:\\n           4798     \"\"\"\\n           4799     Invoke function on values of Series.\\n           4800\\n           (...)   4915     dtype: float64\\n           4916     \"\"\"\\n           4917     return SeriesApply(\\n           4918         self,\\n           4919         func,\\n           4920         convert_dtype=convert_dtype,\\n           4921         by_row=by_row,\\n           4922         args=args,\\n           4923         kwargs=kwargs,\\n        -> 4924     ).apply()\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1427, in SeriesApply.apply(self)\\n           1424     return self.apply_compat()\\n           1426 # self.func is Callable\\n        -> 1427 return self.apply_standard()\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1507, in SeriesApply.apply_standard(self)\\n           1501 # row-wise access\\n           1502 # apply doesn\\'t have a na_action keyword and for backward compat reasons\\n           1503 # we need to give na_action=\"ignore\" for categorical data.\\n           1504 # TODO: remove the na_action=\"ignore\" when that default has been changed in\\n           1505 #  Categorical (GH51645).\"\\n\\n    \"---------------------------------------------------------------------------\\n        TypeError                                 Traceback (most recent call last)\\n        Cell In[5], line 5\\n              2 def has_any(lst, S):\\n              3     return any(x in S for x in (lst or []))\\n        ----> 5 recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\\n              6 recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\\n              7 recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/series.py:4924, in Series.apply(self, func, convert_dtype, args, by_row, **kwargs)\\n           4789 def apply(\\n           4790     self,\\n           4791     func: AggFuncType,\\n           (...)   4796     **kwargs,\\n           4797 ) -> DataFrame | Series:\\n           4798     \"\"\"\\n           4799     Invoke function on values of Series.\\n           4800\\n           (...)   4915     dtype: float64\\n           4916     \"\"\"\\n           4917     return SeriesApply(\\n           4918         self,\\n           4919         func,\\n           4920         convert_dtype=convert_dtype,\\n           4921         by_row=by_row,\\n           4922         args=args,\\n           4923         kwargs=kwargs,\\n        -> 4924     ).apply()\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1427, in SeriesApply.apply(self)\\n           1424     return self.apply_compat()\\n           1426 # self.func is Callable\\n        -> 1427 return self.apply_standard()\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/apply.py:1507, in SeriesApply.apply_standard(self)\\n           1501 # row-wise access\\n           1502 # apply doesn\\'t have a na_action keyword and for backward compat reasons\\n           1503 # we need to give na_action=\"ignore\" for categorical data.\\n           1504 # TODO: remove the na_action=\"ignore\" when that default has been changed in\\n           1505 #  Categorical (GH51645).\\n           1506 action = \"ignore\" if isinstance(obj.dtype, CategoricalDtype) else None\\n        -> 1507 mapped = obj._map_values(\\n           1508     mapper=curried, na_action=action, convert=self.convert_dtype\\n           1509 )\\n           1511 if len(mapped) and isinstance(mapped[0], ABCSeries):\\n           1512     # GH#43986 Need to do list(mapped) in order to get treated as nested\\n           1513     #  See also GH#25959 regarding EA support\\n           1514     return obj._constructor_expanddim(list(mapped), index=obj.index)\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/base.py:921, in IndexOpsMixin._map_values(self, mapper, na_action, convert)\\n            918 if isinstance(arr, ExtensionArray):\\n            919     return arr.map(mapper, na_action=na_action)\\n        --> 921 return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pandas/core/algorithms.py:1743, in map_array(arr, mapper, na_action, convert)\\n           1741 values = arr.astype(object, copy=False)\\n           1742 if na_action is None:\\n        -> 1743     return lib.map_infer(values, mapper, convert=convert)\\n           1744 else:\\n           1745     return lib.map_infer_mask(\\n           1746         values, mapper, mask=isna(values).view(np.uint8), convert=convert\\n           1747     )\\n\\n        File lib.pyx:2972, in pandas._libs.lib.map_infer()\\n\\n        Cell In[5], line 5, in <lambda>(lst)\\n              2 def has_any(lst, S):\\n              3     return any(x in S for x in (lst or []))\\n        ----> 5 recs_df[\"genre_boost\"]     = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, liked_genres))\\n              6 recs_df[\"director_boost\"]  = recs_df[\"director_list\"].apply(lambda lst: has_any(lst, liked_dirs))\\n              7 recs_df[\"genre_penalty\"]   = recs_df[\"genre_list\"].apply(lambda lst: has_any(lst, disliked_genres))\\n\\n        Cell In[5], line 3, in has_any(lst, S)\\n              2 def has_any(lst, S):\\n        ----> 3     return any(x in S for x in (lst or []))\\n\\n        TypeError: \\'float\\' object is not iterable\"\\n\\n    \"---------------------------------------------------------------------------\\n        AttributeError                            Traceback (most recent call last)\\n        Cell In[5], line 41\\n             39 all_pairs   = qset(f\\'recommended(\"{USER}\", N, Y)\\')\\n             40 watch_pairs = qset(f\\'watchBoost(\"{USER}\", N, Y)\\')\\n        ---> 41 g_like      = qset(f\\'genreBoost(\"{USER}\", N, Y)\\')\\n             42 d_like      = qset(f\\'dirBoost(\"{USER}\", N, Y)\\')\\n             43 g_bad       = qset(f\\'genrePenalty(\"{USER}\", N, Y)\\')\\n\\n        Cell In[5], line 36, in qset(s)\\n             35 def qset(s):\\n        ---> 36     ans = pyDatalog.ask(s)\\n             37     return set(tuple(x) for x in (ans.answers if ans else []))\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyDatalog.py:111, in ask(code)\\n            109 def ask(code):\\n            110     \"\"\"returns the result of the query contained in the code string\"\"\"\\n        --> 111     return pyParser.ask(code)\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:841, in ask(code)\\n            839 add_symbols(code.co_names, newglobals)\\n            840 parsed_code = eval(code, newglobals)\\n        --> 841 a = parsed_code.ask()\\n            842 return Answer.make(a)\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:577, in Query.ask(self)\\n            576 def ask(self):\\n        --> 577     self._data = Body(self.pre_calculations, self).ask()\\n            578     self.todo = None\\n            579     return self._data\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyParser.py:693, in Body.ask(self)\\n            691 \"\"\" resolve the query and determine the values of its variables\"\"\"\\n            692 literal = self.literal()\\n        --> 693 self._data = literal.lua.ask()\\n            694 literal.todo, self.todo = None, None\\n            695 - (literal <= self) # delete the temporary clause\\n\\n        File /opt/anaconda3/envs/letterboxd-KG/lib/python3.12/site-packages/pyDatalog/pyEngine.py:513, in Literal.ask(self)\\n            511 todo, arg = (SEARCH, (Ts.Goal, ))\"\\n\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
