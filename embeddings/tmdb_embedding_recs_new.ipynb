{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMDB Similar Movies (nur Filme) ➜ Re-Ranking mit KG-Embedding\n",
    "\n",
    "Dieses Notebook:\n",
    "1. liest **nur Movie-Seeds** (alle `/tv/…` werden ignoriert) aus `data/enriched_merged.csv`,\n",
    "2. holt **ähnliche Filme** über TMDB `/movie/{id}/similar`,\n",
    "3. berechnet **Metadaten-Ähnlichkeit** und **Cosine mit deinem KG-Embedding**,\n",
    "4. kombiniert beides zu einem finalen Score und zeigt **Top-K**.\n",
    "\n",
    "> Voraussetzungen:\n",
    "> - `TMDB_API_TOKEN` (v4 Bearer) als Umgebungsvariable (oder in `.env`),\n",
    "> - `data/kg/embeddings/entity_embeddings.csv` vorhanden,\n",
    "> - Python: `pandas`, `numpy`, `requests`."
   ],
   "id": "845adaa062b4a917"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ],
   "id": "bc6c828882c5fe52"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T22:30:18.370511Z",
     "start_time": "2025-09-12T22:30:18.339452Z"
    }
   },
   "source": [
    "# Optional: Falls nötig, lokal installieren\n",
    "# %pip install pandas numpy requests python-dotenv"
   ],
   "id": "a87aa352633e9c71",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T22:30:18.403303Z",
     "start_time": "2025-09-12T22:30:18.384090Z"
    }
   },
   "source": [
    "import os, re, time, math\n",
    "from typing import Dict, List, Set\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json, pathlib\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "assert os.getenv(\"TMDB_API_TOKEN\"), \"Bitte TMDB_API_TOKEN (v4 Bearer) als Umgebungsvariable oder in .env setzen!\""
   ],
   "id": "c300c997ed026ce0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pfade & Parameter"
   ],
   "id": "66d3a8be6c78f8de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T22:30:18.416161Z",
     "start_time": "2025-09-12T22:30:18.408291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_DIR = \"..\"\n",
    "CACHE_DIR = pathlib.Path(\"../.tmdb_cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Pfade\n",
    "ENRICHED_CSV = f\"{PROJECT_DIR}/data/enriched_merged.csv\"\n",
    "ENTITY_EMB   = f\"{PROJECT_DIR}/data/kg/embeddings/entity_embeddings.csv\"\n",
    "\n",
    "# Recommender-Parameter\n",
    "TOPK   = 200          # Anzahl Empfehlungen\n",
    "PAGES  = 2          # Anzahl Seiten von TMDB /similar je Seed (20 Einträge/Seite)\n",
    "ALPHA  = 0.6        # Mischung: alpha * Cosine + (1-alpha) * Metadaten\n",
    "WEIGHTS = {\n",
    "    \"genres\": 0.25, \"keywords\": 0.20,\n",
    "    \"cast\": 0.20, \"director\": 0.15,\n",
    "    \"runtime\": 0.05, \"language\": 0.05,\n",
    "    \"popularity\": 0.05, \"vote\": 0.05,\n",
    "}\n",
    "\n",
    "# Optional: explizite Seeds (nur Movies). Beispiel: [603, 238]\n",
    "EXPLICIT_SEED_MOVIE_IDS = None"
   ],
   "id": "b7317c001ca710e5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) TMDB-API, Parser & Helper (nur Movie!)"
   ],
   "id": "8adfc2638e467e9a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T22:30:18.452657Z",
     "start_time": "2025-09-12T22:30:18.422051Z"
    }
   },
   "source": [
    "TMDB_API = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "def _cache_get(key: str):\n",
    "    p = CACHE_DIR / (re.sub(r'[^a-zA-Z0-9_.-]+','_', key) + \".json\")\n",
    "    if p.exists():\n",
    "        try:\n",
    "            return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "        except:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def _cache_set(key: str, data: dict):\n",
    "    p = CACHE_DIR / (re.sub(r'[^a-zA-Z0-9_.-]+','_', key) + \".json\")\n",
    "    p.write_text(json.dumps(data), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def _api_get(path: str, params: Dict | None = None, retries: int = 3):\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    bearer = os.getenv(\"TMDB_API_TOKEN\")\n",
    "    headers = {\"Authorization\": f\"Bearer {bearer}\", \"Content-Type\": \"application/json;charset=utf-8\"}\n",
    "\n",
    "    # Cache-Key bauen\n",
    "    key = path + \"?\" + \"&\".join(f\"{k}={v}\" for k,v in sorted(params.items()))\n",
    "    hit = _cache_get(key)\n",
    "    if hit is not None:\n",
    "        return hit\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        r = requests.get(f\"{TMDB_API}{path}\", headers=headers, params=params, timeout=20)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            _cache_set(key, data)\n",
    "            return data\n",
    "        if r.status_code in (429, 500, 502, 503, 504):\n",
    "            time.sleep(1.5 * (attempt + 1))\n",
    "            continue\n",
    "        raise RuntimeError(f\"TMDB error {r.status_code}: {r.text}\")\n",
    "    raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "def parse_tmdb_ref_movies_only(s: str):\n",
    "    \"\"\"\n",
    "    Extrahiert NUR Movie-IDs: return (\"movie\", id) oder (None, None).\n",
    "    - URLs mit /tv/… werden bewusst ignoriert.\n",
    "    - Reine Zahlen werden als Movie interpretiert.\n",
    "    \"\"\"\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)):\n",
    "        return None, None\n",
    "    s = str(s)\n",
    "    m = re.search(r\"/(movie|tv)/(\\d+)\", s)\n",
    "    if m:\n",
    "        kind, sid = m.group(1), int(m.group(2))\n",
    "        if kind == \"movie\":\n",
    "            return \"movie\", sid\n",
    "        return None, None  # tv ignorieren\n",
    "    if s.isdigit():\n",
    "        return \"movie\", int(s)\n",
    "    m = re.search(r\"(\\d+)\", s)\n",
    "    return (\"movie\", int(m.group(1))) if m else (None, None)\n",
    "\n",
    "@dataclass\n",
    "class MovieMeta:\n",
    "    id: int\n",
    "    title: str\n",
    "    original_title: str | None\n",
    "    release_year: int | None\n",
    "    genres: Set[int]\n",
    "    keywords: Set[int]\n",
    "    cast_ids: Set[int]\n",
    "    director_ids: Set[int]\n",
    "    runtime: int | None\n",
    "    language: str | None\n",
    "    popularity: float | None\n",
    "    vote_average: float | None\n",
    "\n",
    "def _year_from(s: str | None) -> int | None:\n",
    "    if not s: return None\n",
    "    try: return int(s[:4])\n",
    "    except: return None\n",
    "\n",
    "def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "    base = _api_get(f\"/movie/{movie_id}\", params={\"append_to_response\": \"credits,keywords\"})\n",
    "    genres   = {g[\"id\"] for g in (base.get(\"genres\") or [])}\n",
    "    # bei append_to_response liegen die Felder direkt im base:\n",
    "    credits  = base.get(\"credits\") or {}\n",
    "    kw       = base.get(\"keywords\") or {}\n",
    "    keywords = {k[\"id\"] for k in (kw.get(\"keywords\") or [])}\n",
    "    cast_ids = {c[\"id\"] for c in (credits.get(\"cast\") or [])[:20]}\n",
    "    director_ids = {c[\"id\"] for c in (credits.get(\"crew\") or []) if c.get(\"job\") == \"Director\"}\n",
    "\n",
    "    def _year(s):\n",
    "        return int(s[:4]) if s and len(s) >= 4 else None\n",
    "\n",
    "    return MovieMeta(\n",
    "        id=movie_id,\n",
    "        title=base.get(\"title\") or str(movie_id),\n",
    "        original_title=base.get(\"original_title\"),\n",
    "        release_year=_year(base.get(\"release_date\")),\n",
    "        genres=genres,\n",
    "        keywords=keywords,\n",
    "        cast_ids=cast_ids,\n",
    "        director_ids=director_ids,\n",
    "        runtime=base.get(\"runtime\"),\n",
    "        language=base.get(\"original_language\"),\n",
    "        popularity=base.get(\"popularity\"),\n",
    "        vote_average=base.get(\"vote_average\"),\n",
    "    )\n",
    "\n",
    "def gather_candidates_movies_only(seed_movie_ids: List[int], pages_per_seed: int=1,\n",
    "                                  per_seed_limit: int=10, global_limit: int=1500) -> set[int]:\n",
    "    cands: list[int] = []\n",
    "    seen = set()\n",
    "    for sid in seed_movie_ids:\n",
    "        added_for_seed = 0\n",
    "        for p in range(1, pages_per_seed+1):\n",
    "            data = _api_get(f\"/movie/{sid}/similar\", params={\"page\": p})\n",
    "            for m in data.get(\"results\", []):\n",
    "                mid = m.get(\"id\")\n",
    "                if not mid or mid in seen:\n",
    "                    continue\n",
    "                cands.append(int(mid))\n",
    "                seen.add(int(mid))\n",
    "                added_for_seed += 1\n",
    "                if per_seed_limit and added_for_seed >= per_seed_limit:\n",
    "                    break\n",
    "            if per_seed_limit and added_for_seed >= per_seed_limit:\n",
    "                break\n",
    "        if global_limit and len(cands) >= global_limit:\n",
    "            break\n",
    "    # Seeds entfernen\n",
    "    return set(cands) - set(seed_movie_ids)"
   ],
   "id": "8c458f01bae39f2e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Similarity & Embeddings (unverändert nützlich)"
   ],
   "id": "6474056a628dca3b"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T22:30:18.468817Z",
     "start_time": "2025-09-12T22:30:18.457948Z"
    }
   },
   "source": [
    "def jaccard(a: Set, b: Set) -> float:\n",
    "    if not a and not b:\n",
    "        return 0.0\n",
    "    return len(a & b) / (len(a | b) or 1)\n",
    "\n",
    "def sim_runtime(a: int | None, b: int | None) -> float:\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    return math.exp(-(abs(a-b)**2) / (2 * 30**2))\n",
    "\n",
    "def sim_numeric(a: float | None, b: float | None, maxdiff: float) -> float:\n",
    "    if a is None or b is None:\n",
    "        return 0.0\n",
    "    return max(0.0, 1.0 - abs(a-b)/maxdiff)\n",
    "\n",
    "def sim_language(a: str | None, b: str | None) -> float:\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    return 1.0 if a == b else 0.0\n",
    "\n",
    "def metadata_similarity(seed: MovieMeta, cand: MovieMeta, weights: Dict[str,float]):\n",
    "    comps = {\n",
    "        \"genres\": jaccard(seed.genres, cand.genres),\n",
    "        \"keywords\": jaccard(seed.keywords, cand.keywords),\n",
    "        \"cast\": jaccard(seed.cast_ids, cand.cast_ids),\n",
    "        \"director\": jaccard(seed.director_ids, cand.director_ids),\n",
    "        \"runtime\": sim_runtime(seed.runtime, cand.runtime),\n",
    "        \"language\": sim_language(seed.language, cand.language),\n",
    "        \"popularity\": sim_numeric(seed.popularity, cand.popularity, 50.0),\n",
    "        \"vote\": sim_numeric(seed.vote_average, cand.vote_average, 4.0),\n",
    "    }\n",
    "    return sum(weights[k]*comps[k] for k in comps), comps\n",
    "\n",
    "def load_entity_embeddings(path: str):\n",
    "    df = pd.read_csv(path)\n",
    "    name_col = \"Unnamed: 0\" if \"Unnamed: 0\" in df.columns else df.columns[0]\n",
    "    names = df[name_col].astype(str).tolist()\n",
    "    vecs = df.drop(columns=[name_col]).to_numpy(float)\n",
    "    vecs /= (np.linalg.norm(vecs, axis=1, keepdims=True)+1e-9)\n",
    "    return {names[i].strip(): vecs[i] for i in range(len(names))}, vecs\n",
    "\n",
    "def cosine(a, b):\n",
    "    return float(np.dot(a, b)) if a is not None and b is not None else 0.0\n",
    "\n",
    "def normalize_title(t: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (t or \"\").strip()).lower()\n",
    "\n",
    "def find_embedding_for_title(table, title, year=None):\n",
    "    if not title:\n",
    "        return None\n",
    "    if title in table:\n",
    "        return table[title]\n",
    "    norm = normalize_title(title)\n",
    "    for k,v in table.items():\n",
    "        if normalize_title(k) == norm:\n",
    "            return v\n",
    "    if year is not None:\n",
    "        key = f\"{title} ({year})\"\n",
    "        if key in table:\n",
    "            return table[key]\n",
    "    return None"
   ],
   "id": "efe3813af59e5300",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Seeds laden (nur Movies), Kandidaten holen, Scoring, Top-K anzeigen & speichern"
   ],
   "id": "f2bce8a390be0181"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T22:30:57.116535Z",
     "start_time": "2025-09-12T22:30:18.482635Z"
    }
   },
   "source": [
    "# 5.1 Seeds (nur Movies)\n",
    "if EXPLICIT_SEED_MOVIE_IDS:\n",
    "    seed_movie_ids = list(dict.fromkeys([int(x) for x in EXPLICIT_SEED_MOVIE_IDS]))\n",
    "else:\n",
    "    df_enr = pd.read_csv(ENRICHED_CSV)\n",
    "    raw = df_enr.get(\"tmdb_url\", pd.Series(dtype=str)).dropna().tolist()\n",
    "    seed_movie_ids = []\n",
    "    for s in raw:\n",
    "        kind, sid = parse_tmdb_ref_movies_only(s)\n",
    "        if kind == \"movie\" and sid:\n",
    "            seed_movie_ids.append(sid)\n",
    "    seed_movie_ids = list(dict.fromkeys(seed_movie_ids))\n",
    "\n",
    "assert seed_movie_ids, \"Keine Movie-Seeds gefunden (alle /tv/ wurden ignoriert).\"\n",
    "print(f\"Movie-Seeds: {len(seed_movie_ids)}\")\n",
    "\n",
    "# 5.2 Seed-Metadaten\n",
    "seeds_meta = []\n",
    "for sid in seed_movie_ids:\n",
    "    try:\n",
    "        seeds_meta.append(get_movie_meta(sid))\n",
    "    except RuntimeError as e:\n",
    "        print(f\"WARN: Seed /movie/{sid} übersprungen: {e}\")\n",
    "assert seeds_meta, \"Alle Seeds fielen raus. Prüfe tmdb_url und TMDB_API_TOKEN.\"\n",
    "\n",
    "# 5.3 Embedding laden & User-Zentroid\n",
    "emb_table, _ = load_entity_embeddings(ENTITY_EMB)\n",
    "seed_vecs = []\n",
    "for sm in seeds_meta:\n",
    "    v = find_embedding_for_title(emb_table, sm.title, sm.release_year)\n",
    "    if v is None:\n",
    "        v = find_embedding_for_title(emb_table, sm.original_title, sm.release_year)\n",
    "    if v is not None:\n",
    "        seed_vecs.append(v)\n",
    "user_vec = None\n",
    "if seed_vecs:\n",
    "    user_vec = np.mean(np.vstack(seed_vecs), axis=0)\n",
    "    user_vec /= (np.linalg.norm(user_vec)+1e-9)\n",
    "else:\n",
    "    print(\"WARN: Keine Seed-Embeddings gefunden – Cosine fällt auf 0.\")\n",
    "\n",
    "# 5.4 Kandidaten (nur Movies)\n",
    "cand_ids = gather_candidates_movies_only(seed_movie_ids, pages_per_seed=PAGES,\n",
    "                                         per_seed_limit=10, global_limit=1500)\n",
    "print(f\"Kandidaten-Pool (Movies): {len(cand_ids)}\")\n",
    "\n",
    "# 5.5 Scoring\n",
    "rows = []\n",
    "for cid in cand_ids:\n",
    "    try:\n",
    "        cm = get_movie_meta(cid)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"WARN: skip /movie/{cid}: {e}\")\n",
    "        continue\n",
    "    best_meta = 0.0\n",
    "    best_seed_title = None\n",
    "    comps_keep = None\n",
    "    for sm in seeds_meta:\n",
    "        s, comps = metadata_similarity(sm, cm, WEIGHTS)\n",
    "        if s > best_meta:\n",
    "            best_meta = s\n",
    "            best_seed_title = sm.title\n",
    "            comps_keep = comps\n",
    "    cand_vec = find_embedding_for_title(emb_table, cm.title, cm.release_year)\n",
    "    if cand_vec is None:\n",
    "        cand_vec = find_embedding_for_title(emb_table, cm.original_title, cm.release_year)\n",
    "    cos = cosine(user_vec, cand_vec) if (user_vec is not None and cand_vec is not None) else 0.0\n",
    "    final = ALPHA * cos + (1 - ALPHA) * best_meta\n",
    "    rows.append({\n",
    "        \"candidate_id\": cid,\n",
    "        \"candidate_title\": cm.title,\n",
    "        \"year\": cm.release_year,\n",
    "        \"cos\": round(cos,4),\n",
    "        \"meta\": round(best_meta,4),\n",
    "        \"final\": round(final,4),\n",
    "        \"seed\": best_seed_title,\n",
    "        **{f\"comp_{k}\": round(comps_keep[k],4) for k in (comps_keep or {})}\n",
    "    })\n",
    "\n",
    "df_out = pd.DataFrame(rows).sort_values(\"final\", ascending=False).head(TOPK)\n",
    "df_out"
   ],
   "id": "11ddc94f6e837e5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie-Seeds: 694\n",
      "Kandidaten-Pool (Movies): 1444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      candidate_id                            candidate_title    year     cos  \\\n",
       "219            929                                   Godzilla  1998.0  0.3688   \n",
       "1134         11797                               Fright Night  1985.0  0.3051   \n",
       "1433        262097                                       Trio  1997.0  0.3612   \n",
       "1152         11868                                    Dracula  1958.0  0.2846   \n",
       "468           1498               Teenage Mutant Ninja Turtles  1990.0  0.2999   \n",
       "...            ...                                        ...     ...     ...   \n",
       "525           1662                             State of Grace  1990.0  0.0000   \n",
       "685           1979  Fantastic Four: Rise of the Silver Surfer  2007.0  0.0000   \n",
       "300           9366                              Donnie Brasco  1997.0  0.0000   \n",
       "583           1878             Fear and Loathing in Las Vegas  1998.0  0.0000   \n",
       "1171         28288                           The Gay Divorcee  1934.0  0.0000   \n",
       "\n",
       "        meta   final                                seed  comp_genres  \\\n",
       "219   0.5221  0.4301              The Day After Tomorrow         0.75   \n",
       "1134  0.4600  0.3671                        Fright Night         1.00   \n",
       "1433  0.3630  0.3619                   Seven Psychopaths         1.00   \n",
       "1152  0.4735  0.3601                             Dracula         1.00   \n",
       "468   0.4414  0.3565        Teenage Mutant Ninja Turtles         0.80   \n",
       "...      ...     ...                                 ...          ...   \n",
       "525   0.4478  0.1791                          Uncut Gems         1.00   \n",
       "685   0.4478  0.1791         Venom: Let There Be Carnage         1.00   \n",
       "300   0.4477  0.1791                          Inside Man         1.00   \n",
       "583   0.4476  0.1790  The Life Aquatic with Steve Zissou         1.00   \n",
       "1171  0.4475  0.1790                          Mamma Mia!         1.00   \n",
       "\n",
       "      comp_keywords  comp_cast  comp_director  comp_runtime  comp_language  \\\n",
       "219          0.0189     0.0000            1.0        0.8825            1.0   \n",
       "1134         0.0769     0.0278            0.0        0.9994            1.0   \n",
       "1433         0.0000     0.0000            0.0        0.9731            0.0   \n",
       "1152         0.1364     0.0000            0.0        0.9651            1.0   \n",
       "468          0.3182     0.0000            0.0        0.9651            1.0   \n",
       "...             ...        ...            ...           ...            ...   \n",
       "525          0.0303     0.0000            0.0        0.9994            1.0   \n",
       "685          0.0789     0.0000            0.0        0.9862            1.0   \n",
       "300          0.0278     0.0000            0.0        0.9978            1.0   \n",
       "583          0.0000     0.0000            0.0        0.9994            1.0   \n",
       "1171         0.0303     0.0000            0.0        0.9994            1.0   \n",
       "\n",
       "      comp_popularity  comp_vote  \n",
       "219            0.9615     0.7732  \n",
       "1134           0.9916     0.7908  \n",
       "1433           0.9183     0.3692  \n",
       "1152           0.9900     0.9695  \n",
       "468            0.7857     0.8055  \n",
       "...               ...        ...  \n",
       "525            0.8853     0.9500  \n",
       "685            0.9405     0.7135  \n",
       "300            0.8796     0.9650  \n",
       "583            0.9858     0.9663  \n",
       "1171           0.8475     0.9810  \n",
       "\n",
       "[200 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>candidate_title</th>\n",
       "      <th>year</th>\n",
       "      <th>cos</th>\n",
       "      <th>meta</th>\n",
       "      <th>final</th>\n",
       "      <th>seed</th>\n",
       "      <th>comp_genres</th>\n",
       "      <th>comp_keywords</th>\n",
       "      <th>comp_cast</th>\n",
       "      <th>comp_director</th>\n",
       "      <th>comp_runtime</th>\n",
       "      <th>comp_language</th>\n",
       "      <th>comp_popularity</th>\n",
       "      <th>comp_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>929</td>\n",
       "      <td>Godzilla</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.3688</td>\n",
       "      <td>0.5221</td>\n",
       "      <td>0.4301</td>\n",
       "      <td>The Day After Tomorrow</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.7732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>11797</td>\n",
       "      <td>Fright Night</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>0.3051</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.3671</td>\n",
       "      <td>Fright Night</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.7908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>262097</td>\n",
       "      <td>Trio</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.3619</td>\n",
       "      <td>Seven Psychopaths</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>0.3692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>11868</td>\n",
       "      <td>Dracula</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.4735</td>\n",
       "      <td>0.3601</td>\n",
       "      <td>Dracula</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>1498</td>\n",
       "      <td>Teenage Mutant Ninja Turtles</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>0.2999</td>\n",
       "      <td>0.4414</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>Teenage Mutant Ninja Turtles</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.8055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>1662</td>\n",
       "      <td>State of Grace</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4478</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>Uncut Gems</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1979</td>\n",
       "      <td>Fantastic Four: Rise of the Silver Surfer</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4478</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>Venom: Let There Be Carnage</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>9366</td>\n",
       "      <td>Donnie Brasco</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4477</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>Inside Man</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.9650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1878</td>\n",
       "      <td>Fear and Loathing in Las Vegas</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4476</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>The Life Aquatic with Steve Zissou</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>0.9663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>28288</td>\n",
       "      <td>The Gay Divorcee</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4475</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>Mamma Mia!</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8475</td>\n",
       "      <td>0.9810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Ergebnisse speichern"
   ],
   "id": "44742ff8924ef706"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T22:30:57.274112Z",
     "start_time": "2025-09-12T22:30:57.260194Z"
    }
   },
   "source": [
    "OUT_CSV = f\"{PROJECT_DIR}/data/kg/rerank_with_embedding_results.csv\"\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Gespeichert: {OUT_CSV}\")"
   ],
   "id": "8b7282c2ad879ada",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gespeichert: ../data/kg/rerank_with_embedding_results.csv\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T22:30:57.639008Z",
     "start_time": "2025-09-12T22:30:57.622887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "The code in the previous cells is in big parts AI generated by the free and paid version of ChatGPT and was afterwards heavily adapted by me. Since it is not possible to accurately say which parts were originaly AI generated by wich promt, I have included all prompts that were used on this file here.\n",
    "These following prompts were used:\n",
    "\n",
    "\n",
    "    \"im file kg_recommender_from_pykeen möchte ich anstelle von selbst eingegeben daten nun ähnliche filme zu den filmen in den triplen aus der tmdb datenbank laden, und für diese filme einen similarity score erstellen. danach möchte ich 5 filme mit dem besten similarity score empfehlen\"\n",
    "\n",
    "    \"import re, time, math\n",
    "        from typing import Dict, List, Set\n",
    "        from dataclasses import dataclass\n",
    "        from dotenv import load_dotenv\n",
    "\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import requests\n",
    "\n",
    "        load_dotenv()\n",
    "\n",
    "        TMDB_API_TOKEN = \"https://api.themoviedb.org/3\"\n",
    "        HEADERS = {\n",
    "            \"Authorization\": \"Bearer \" + TMDB_API_TOKEN,\n",
    "            \"Content-Type\": \"application/json;charset=utf-8\"\n",
    "        }\n",
    "\n",
    "        def _api_get(path: str, params: Dict=None, retries: int=3):\n",
    "            if params is None:\n",
    "                params = {}\n",
    "            key = os.getenv(\"TMDB_API_TOKEN\")\n",
    "            if not key:\n",
    "                raise RuntimeError(\"TMDB_API_TOKEN ist nicht gesetzt.\")\n",
    "            params = {**params, \"api_key\": key}\n",
    "            for attempt in range(retries):\n",
    "                r = requests.get(f\"{TMDB_API_TOKEN}{path}\",headers=HEADERS, params=params, timeout=20)\n",
    "                if r.status_code == 200:\n",
    "                    return r.json()\n",
    "                if r.status_code in (429, 500, 502, 503, 504):\n",
    "                    time.sleep(1.5 * (attempt + 1))\n",
    "                    continue\n",
    "                raise RuntimeError(f\"TMDB error {r.status_code}: {r.text[:200]}\")\n",
    "            raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "        def parse_tmdb_id(s: str) -> int | None:\n",
    "            if pd.isna(s):\n",
    "                return None\n",
    "            s = str(s)\n",
    "            m = re.search(r\"/movie/(\\d+)\", s)\n",
    "            if m:\n",
    "                return int(m.group(1))\n",
    "            if s.isdigit():\n",
    "                return int(s)\n",
    "            m = re.search(r\"(\\d+)\", s)\n",
    "            return int(m.group(1)) if m else None\n",
    "\n",
    "        @dataclass\n",
    "        class MovieMeta:\n",
    "            id: int\n",
    "            title: str\n",
    "            original_title: str | None\n",
    "            release_year: int | None\n",
    "            genres: Set[int]\n",
    "            keywords: Set[int]\n",
    "            cast_ids: Set[int]\n",
    "            director_ids: Set[int]\n",
    "            runtime: int | None\n",
    "            language: str | None\n",
    "            popularity: float | None\n",
    "            vote_average: float | None\n",
    "\n",
    "        def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "            base = _api_get(f\"/movie/{movie_id}\")\n",
    "            credits = _api_get(f\"/movie/{movie_id}/credits\")\n",
    "            kw = _api_get(f\"/movie/{movie_id}/keywords\")\n",
    "            genres = {g[\"id\"] for g in (base.get(\"genres\") or [])}\n",
    "            keywords = {k[\"id\"] for k in (kw.get(\"keywords\") or [])}\n",
    "            cast_ids = {c[\"id\"] for c in (credits.get(\"cast\") or [])[:20]}\n",
    "            director_ids = {c[\"id\"] for c in (credits.get(\"crew\") or []) if c.get(\"job\") == \"Director\"}\n",
    "            y = None\n",
    "            if base.get(\"release_date\"):\n",
    "                try: y = int(base[\"release_date\"][:4])\n",
    "                except: pass\n",
    "            return MovieMeta(\n",
    "                id=movie_id,\n",
    "                title=base.get(\"title\") or str(movie_id),\n",
    "                original_title=base.get(\"original_title\"),\n",
    "                release_year=y,\n",
    "                genres=genres,\n",
    "                keywords=keywords,\n",
    "                cast_ids=cast_ids,\n",
    "                director_ids=director_ids,\n",
    "                runtime=base.get(\"runtime\"),\n",
    "                language=base.get(\"original_language\"),\n",
    "                popularity=base.get(\"popularity\"),\n",
    "                vote_average=base.get(\"vote_average\"),\n",
    "            )\n",
    "\n",
    "        def gather_candidates(seed_ids: List[int], pages_per_seed: int=2) -> Set[int]:\n",
    "            cands: Set[int] = set()\n",
    "            for sid in seed_ids:\n",
    "                for p in range(1, pages_per_seed+1):\n",
    "                    data = _api_get(f\"/movie/{sid}/similar\", params={\"page\": p})\n",
    "                    for m in data.get(\"results\", []):\n",
    "                        if m.get(\"id\"):\n",
    "                            cands.add(m[\"id\"])\n",
    "            return cands - set(seed_ids)\n",
    "\n",
    "        def jaccard(a: Set, b: Set) -> float:\n",
    "            if not a and not b:\n",
    "                return 0.0\n",
    "            return len(a & b) / (len(a | b) or 1)\n",
    "\n",
    "        def sim_runtime(a: int | None, b: int | None) -> float:\n",
    "            if not a or not b:\n",
    "                return 0.0\n",
    "            return math.exp(-(abs(a-b)**2) / (2 * 30**2))\n",
    "\n",
    "        def sim_numeric(a: float | None, b: float | None, maxdiff: float) -> float:\n",
    "            if a is None or b is None:\n",
    "                return 0.0\n",
    "            return max(0.0, 1.0 - abs(a-b)/maxdiff)\n",
    "\n",
    "        def sim_language(a: str | None, b: str | None) -> float:\n",
    "            if not a or not b:\n",
    "                return 0.0\n",
    "            return 1.0 if a == b else 0.0\n",
    "\n",
    "        def metadata_similarity(seed: MovieMeta, cand: MovieMeta, weights: Dict[str,float]):\n",
    "            comps = {\n",
    "                \"genres\": jaccard(seed.genres, cand.genres),\n",
    "                \"keywords\": jaccard(seed.keywords, cand.keywords),\n",
    "                \"cast\": jaccard(seed.cast_ids, cand.cast_ids),\n",
    "                \"director\": jaccard(seed.director_ids, cand.director_ids),\n",
    "                \"runtime\": sim_runtime(seed.runtime, cand.runtime),\n",
    "                \"language\": sim_language(seed.language, cand.language),\n",
    "                \"popularity\": sim_numeric(seed.popularity, cand.popularity, 50.0),\n",
    "                \"vote\": sim_numeric(seed.vote_average, cand.vote_average, 4.0),\n",
    "            }\n",
    "            return sum(weights[k]*comps[k] for k in comps), comps\n",
    "\n",
    "        def load_entity_embeddings(path: str):\n",
    "            df = pd.read_csv(path)\n",
    "            name_col = \"Unnamed: 0\" if \"Unnamed: 0\" in df.columns else df.columns[0]\n",
    "            names = df[name_col].astype(str).tolist()\n",
    "            vecs = df.drop(columns=[name_col]).to_numpy(float)\n",
    "            vecs /= (np.linalg.norm(vecs, axis=1, keepdims=True)+1e-9)\n",
    "            return {names[i].strip(): vecs[i] for i in range(len(names))}, vecs\n",
    "\n",
    "        def cosine(a, b):\n",
    "            return float(np.dot(a, b)) if a is not None and b is not None else 0.0\n",
    "\n",
    "        def normalize_title(t: str) -> str:\n",
    "            return re.sub(r\"\\s+\", \" \", (t or \"\").strip()).lower()\n",
    "\n",
    "        def find_embedding_for_title(table, title, year=None):\n",
    "            if not title:\n",
    "                return None\n",
    "            if title in table:\n",
    "                return table[title]\n",
    "            norm = normalize_title(title)\n",
    "            for k,v in table.items():\n",
    "                if normalize_title(k) == norm:\n",
    "                    return v\n",
    "            if year is not None:\n",
    "                key = f\"{title} ({year})\"\n",
    "                if key in table:\n",
    "                    return table[key]\n",
    "            return None\n",
    "\n",
    "        i altered this file slightly to try to resolve this error:\n",
    "        ---------------------------------------------------------------------------\n",
    "        RuntimeError                              Traceback (most recent call last)\n",
    "        Cell In[14], line 9\n",
    "              6 seed_ids = list(dict.fromkeys(seed_ids))\n",
    "              7 assert seed_ids, \"Keine Seeds gefunden.\"\n",
    "        ----> 9 seeds_meta = [get_movie_meta(sid) for sid in seed_ids]\n",
    "             11 emb_table,_ = load_entity_embeddings(ENTITY_EMB)\n",
    "             12 seed_vecs=[find_embedding_for_title(emb_table, sm.title, sm.release_year) for sm in seeds_meta]\n",
    "\n",
    "        Cell In[13], line 63, in get_movie_meta(movie_id)\n",
    "             62 def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "        ---> 63     base = _api_get(f\"/movie/{movie_id}\")\n",
    "             64     credits = _api_get(f\"/movie/{movie_id}/credits\")\n",
    "             65     kw = _api_get(f\"/movie/{movie_id}/keywords\")\n",
    "\n",
    "        Cell In[13], line 32, in _api_get(path, params, retries)\n",
    "             30         time.sleep(1.5 * (attempt + 1))\n",
    "             31         continue\n",
    "        ---> 32     raise RuntimeError(f\"TMDB error {r.status_code}: {r.text[:200]}\")\n",
    "             33 raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "        RuntimeError: TMDB error 401: {\"status_code\":7,\"status_message\":\"Invalid API key: You must be granted a valid key.\",\"success\":false}\n",
    "\n",
    "        unfortunately, it didnt work\"\n",
    "\n",
    "    \"---------------------------------------------------------------------------\n",
    "        RuntimeError                              Traceback (most recent call last)\n",
    "        Cell In[21], line 9\n",
    "              6 seed_ids = list(dict.fromkeys(seed_ids))\n",
    "              7 assert seed_ids, \"Keine Seeds gefunden.\"\n",
    "        ----> 9 seeds_meta = [get_movie_meta(sid) for sid in seed_ids]\n",
    "             11 emb_table,_ = load_entity_embeddings(ENTITY_EMB)\n",
    "             12 seed_vecs=[find_embedding_for_title(emb_table, sm.title, sm.release_year) for sm in seeds_meta]\n",
    "\n",
    "        Cell In[19], line 68, in get_movie_meta(movie_id)\n",
    "             67 def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "        ---> 68     base = _api_get(f\"/movie/{movie_id}\")\n",
    "             69     credits = _api_get(f\"/movie/{movie_id}/credits\")\n",
    "             70     kw = _api_get(f\"/movie/{movie_id}/keywords\")\n",
    "\n",
    "        Cell In[19], line 36, in _api_get(path, params, retries)\n",
    "             34         time.sleep(1.5 * (attempt + 1))\n",
    "             35         continue\n",
    "        ---> 36     raise RuntimeError(f\"TMDB error {r.status_code}: {r.text}\")\n",
    "             38 raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "        RuntimeError: TMDB error 404: {\"success\":false,\"status_code\":34,\"status_message\":\"The resource you requested could not be found.\"}\n",
    "\n",
    "        was tu ich mit dieser fehlermeldung?\n",
    "\n",
    "        das ist der aktuelle stand meines codes:\n",
    "        import re, time, math\n",
    "        from typing import Dict, List, Set\n",
    "        from dataclasses import dataclass\n",
    "        from dotenv import load_dotenv\n",
    "\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import requests\n",
    "        import os\n",
    "\n",
    "        load_dotenv()\n",
    "\n",
    "        TMDB_API = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "        def _api_get(path: str, params: Dict | None = None, retries: int = 3):\n",
    "            if params is None:\n",
    "                params = {}\n",
    "\n",
    "            bearer = os.getenv(\"TMDB_API_TOKEN\")  # <-- genau dein Name aus .env\n",
    "            if not bearer:\n",
    "                raise RuntimeError(\"TMDB_API_TOKEN ist nicht gesetzt (v4 Bearer-Token erwartet).\")\n",
    "\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {bearer}\",\n",
    "                \"Content-Type\": \"application/json;charset=utf-8\",\n",
    "            }\n",
    "            # WICHTIG: KEIN api_key Query-Parameter bei Bearer-Auth!\n",
    "\n",
    "            for attempt in range(retries):\n",
    "                r = requests.get(f\"{TMDB_API}{path}\", headers=headers, params=params, timeout=20)\n",
    "                if r.status_code == 200:\n",
    "                    return r.json()\n",
    "                if r.status_code in (429, 500, 502, 503, 504):\n",
    "                    time.sleep(1.5 * (attempt + 1))\n",
    "                    continue\n",
    "                raise RuntimeError(f\"TMDB error {r.status_code}: {r.text}\")\n",
    "\n",
    "            raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "        def parse_tmdb_id(s: str) -> int | None:\n",
    "            if pd.isna(s):\n",
    "                return None\n",
    "            s = str(s)\n",
    "            m = re.search(r\"/movie/(\\d+)\", s)\n",
    "            if m:\n",
    "                return int(m.group(1))\n",
    "            if s.isdigit():\n",
    "                return int(s)\n",
    "            m = re.search(r\"(\\d+)\", s)\n",
    "            return int(m.group(1)) if m else None\n",
    "\n",
    "        @dataclass\n",
    "        class MovieMeta:\n",
    "            id: int\n",
    "            title: str\n",
    "            original_title: str | None\n",
    "            release_year: int | None\n",
    "            genres: Set[int]\n",
    "            keywords: Set[int]\n",
    "            cast_ids: Set[int]\n",
    "            director_ids: Set[int]\n",
    "            runtime: int | None\n",
    "            language: str | None\n",
    "            popularity: float | None\n",
    "            vote_average: float | None\n",
    "\n",
    "        def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "            base = _api_get(f\"/movie/{movie_id}\")\n",
    "            credits = _api_get(f\"/movie/{movie_id}/credits\")\n",
    "            kw = _api_get(f\"/movie/{movie_id}/keywords\")\n",
    "            genres = {g[\"id\"] for g in (base.get(\"genres\") or [])}\n",
    "            keywords = {k[\"id\"] for k in (kw.get(\"keywords\") or [])}\n",
    "            cast_ids = {c[\"id\"] for c in (credits.get(\"cast\") or [])[:20]}\n",
    "            director_ids = {c[\"id\"] for c in (credits.get(\"crew\") or []) if c.get(\"job\") == \"Director\"}\n",
    "            y = None\n",
    "            if base.get(\"release_date\"):\n",
    "                try: y = int(base[\"release_date\"][:4])\n",
    "                except: pass\n",
    "            return MovieMeta(\n",
    "                id=movie_id,\n",
    "                title=base.get(\"title\") or str(movie_id),\n",
    "                original_title=base.get(\"original_title\"),\n",
    "                release_year=y,\n",
    "                genres=genres,\n",
    "                keywords=keywords,\n",
    "                cast_ids=cast_ids,\n",
    "                director_ids=director_ids,\n",
    "                runtime=base.get(\"runtime\"),\n",
    "                language=base.get(\"original_language\"),\n",
    "                popularity=base.get(\"popularity\"),\n",
    "                vote_average=base.get(\"vote_average\"),\n",
    "            )\n",
    "\n",
    "        def gather_candidates(seed_ids: List[int], pages_per_seed: int=2) -> Set[int]:\n",
    "            cands: Set[int] = set()\n",
    "            for sid in seed_ids:\n",
    "                for p in range(1, pages_per_seed+1):\n",
    "                    data = _api_get(f\"/movie/{sid}/similar\", params={\"page\": p})\n",
    "                    for m in data.get(\"results\", []):\n",
    "                        if m.get(\"id\"):\n",
    "                            cands.add(m[\"id\"])\n",
    "            return cands - set(seed_ids)\n",
    "\n",
    "        def jaccard(a: Set, b: Set) -> float:\n",
    "            if not a and not b:\n",
    "                return 0.0\n",
    "            return len(a & b) / (len(a | b) or 1)\n",
    "\n",
    "        def sim_runtime(a: int | None, b: int | None) -> float:\n",
    "            if not a or not b:\n",
    "                return 0.0\n",
    "            return math.exp(-(abs(a-b)**2) / (2 * 30**2))\n",
    "\n",
    "        def sim_numeric(a: float | None, b: float | None, maxdiff: float) -> float:\n",
    "            if a is None or b is None:\n",
    "                return 0.0\n",
    "            return max(0.0, 1.0 - abs(a-b)/maxdiff)\n",
    "\n",
    "        def sim_language(a: str | None, b: str | None) -> float:\n",
    "            if not a or not b:\n",
    "                return 0.0\n",
    "            return 1.0 if a == b else 0.0\n",
    "\n",
    "        def metadata_similarity(seed: MovieMeta, cand: MovieMeta, weights: Dict[str,float]):\n",
    "            comps = {\n",
    "                \"genres\": jaccard(seed.genres, cand.genres),\n",
    "                \"keywords\": jaccard(seed.keywords, cand.keywords),\n",
    "                \"cast\": jaccard(seed.cast_ids, cand.cast_ids),\n",
    "                \"director\": jaccard(seed.director_ids, cand.director_ids),\n",
    "                \"runtime\": sim_runtime(seed.runtime, cand.runtime),\n",
    "                \"language\": sim_language(seed.language, cand.language),\n",
    "                \"popularity\": sim_numeric(seed.popularity, cand.popularity, 50.0),\n",
    "                \"vote\": sim_numeric(seed.vote_average, cand.vote_average, 4.0),\n",
    "            }\n",
    "            return sum(weights[k]*comps[k] for k in comps), comps\n",
    "\n",
    "        def load_entity_embeddings(path: str):\n",
    "            df = pd.read_csv(path)\n",
    "            name_col = \"Unnamed: 0\" if \"Unnamed: 0\" in df.columns else df.columns[0]\n",
    "            names = df[name_col].astype(str).tolist()\n",
    "            vecs = df.drop(columns=[name_col]).to_numpy(float)\n",
    "            vecs /= (np.linalg.norm(vecs, axis=1, keepdims=True)+1e-9)\n",
    "            return {names[i].strip(): vecs[i] for i in range(len(names))}, vecs\n",
    "\n",
    "        def cosine(a, b):\n",
    "            return float(np.dot(a, b)) if a is not None and b is not None else 0.0\n",
    "\n",
    "        def normalize_title(t: str) -> str:\n",
    "            return re.sub(r\"\\s+\", \" \", (t or \"\").strip()).lower()\n",
    "\n",
    "        def find_embedding_for_title(table, title, year=None):\n",
    "            if not title:\n",
    "                return None\n",
    "            if title in table:\n",
    "                return table[title]\n",
    "            norm = normalize_title(title)\n",
    "            for k,v in table.items():\n",
    "                if normalize_title(k) == norm:\n",
    "                    return v\n",
    "            if year is not None:\n",
    "                key = f\"{title} ({year})\"\n",
    "                if key in table:\n",
    "                    return table[key]\n",
    "            return None\"\n",
    "\n",
    "    \"ich möchte folgende änderungen: für alle serien in tmdb_url soll einfach gar kein tmdb endpoint abgefragt werden\"\n",
    "\n",
    "    \"---------------------------------------------------------------------------\n",
    "        ValueError                                Traceback (most recent call last)\n",
    "        Cell In[7], line 30\n",
    "             28 seed_vecs = []\n",
    "             29 for sm in seeds_meta:\n",
    "        ---> 30     v = (find_embedding_for_title(emb_table, sm.title, sm.release_year) or\n",
    "             31          find_embedding_for_title(emb_table, sm.original_title, sm.release_year))\n",
    "             32     if v is not None:\n",
    "             33         seed_vecs.append(v)\n",
    "\n",
    "        ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\"\n",
    "\n",
    "    \"Movie-Seeds: 693\n",
    "        Kandidaten-Pool (Movies): 6200\n",
    "\n",
    "        wie kommt diese hohe anzahl an Kandiaten zustande? der code lief fast 2h lang\"\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ],
   "id": "9c4039ebe96bb33e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe code in the previous cells is in big parts AI generated by the free and paid version of ChatGPT and was afterwards heavily adapted by me. Since it is not possible to accurately say which parts were originaly AI generated by wich promt, I have included all prompts that were used on this file here.\\nThese following prompts were used:\\n\\n\\n    \"im file kg_recommender_from_pykeen möchte ich anstelle von selbst eingegeben daten nun ähnliche filme zu den filmen in den triplen aus der tmdb datenbank laden, und für diese filme einen similarity score erstellen. danach möchte ich 5 filme mit dem besten similarity score empfehlen\"\\n\\n    \"import re, time, math\\n        from typing import Dict, List, Set\\n        from dataclasses import dataclass\\n        from dotenv import load_dotenv\\n\\n        import pandas as pd\\n        import numpy as np\\n        import requests\\n\\n        load_dotenv()\\n\\n        TMDB_API_TOKEN = \"https://api.themoviedb.org/3\"\\n        HEADERS = {\\n            \"Authorization\": \"Bearer \" + TMDB_API_TOKEN,\\n            \"Content-Type\": \"application/json;charset=utf-8\"\\n        }\\n\\n        def _api_get(path: str, params: Dict=None, retries: int=3):\\n            if params is None:\\n                params = {}\\n            key = os.getenv(\"TMDB_API_TOKEN\")\\n            if not key:\\n                raise RuntimeError(\"TMDB_API_TOKEN ist nicht gesetzt.\")\\n            params = {**params, \"api_key\": key}\\n            for attempt in range(retries):\\n                r = requests.get(f\"{TMDB_API_TOKEN}{path}\",headers=HEADERS, params=params, timeout=20)\\n                if r.status_code == 200:\\n                    return r.json()\\n                if r.status_code in (429, 500, 502, 503, 504):\\n                    time.sleep(1.5 * (attempt + 1))\\n                    continue\\n                raise RuntimeError(f\"TMDB error {r.status_code}: {r.text[:200]}\")\\n            raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\\n\\n        def parse_tmdb_id(s: str) -> int | None:\\n            if pd.isna(s):\\n                return None\\n            s = str(s)\\n            m = re.search(r\"/movie/(\\\\d+)\", s)\\n            if m:\\n                return int(m.group(1))\\n            if s.isdigit():\\n                return int(s)\\n            m = re.search(r\"(\\\\d+)\", s)\\n            return int(m.group(1)) if m else None\\n\\n        @dataclass\\n        class MovieMeta:\\n            id: int\\n            title: str\\n            original_title: str | None\\n            release_year: int | None\\n            genres: Set[int]\\n            keywords: Set[int]\\n            cast_ids: Set[int]\\n            director_ids: Set[int]\\n            runtime: int | None\\n            language: str | None\\n            popularity: float | None\\n            vote_average: float | None\\n\\n        def get_movie_meta(movie_id: int) -> MovieMeta:\\n            base = _api_get(f\"/movie/{movie_id}\")\\n            credits = _api_get(f\"/movie/{movie_id}/credits\")\\n            kw = _api_get(f\"/movie/{movie_id}/keywords\")\\n            genres = {g[\"id\"] for g in (base.get(\"genres\") or [])}\\n            keywords = {k[\"id\"] for k in (kw.get(\"keywords\") or [])}\\n            cast_ids = {c[\"id\"] for c in (credits.get(\"cast\") or [])[:20]}\\n            director_ids = {c[\"id\"] for c in (credits.get(\"crew\") or []) if c.get(\"job\") == \"Director\"}\\n            y = None\\n            if base.get(\"release_date\"):\\n                try: y = int(base[\"release_date\"][:4])\\n                except: pass\\n            return MovieMeta(\\n                id=movie_id,\\n                title=base.get(\"title\") or str(movie_id),\\n                original_title=base.get(\"original_title\"),\\n                release_year=y,\\n                genres=genres,\\n                keywords=keywords,\\n                cast_ids=cast_ids,\\n                director_ids=director_ids,\\n                runtime=base.get(\"runtime\"),\\n                language=base.get(\"original_language\"),\\n                popularity=base.get(\"popularity\"),\\n                vote_average=base.get(\"vote_average\"),\\n            )\\n\\n        def gather_candidates(seed_ids: List[int], pages_per_seed: int=2) -> Set[int]:\\n            cands: Set[int] = set()\\n            for sid in seed_ids:\\n                for p in range(1, pages_per_seed+1):\\n                    data = _api_get(f\"/movie/{sid}/similar\", params={\"page\": p})\\n                    for m in data.get(\"results\", []):\\n                        if m.get(\"id\"):\\n                            cands.add(m[\"id\"])\\n            return cands - set(seed_ids)\\n\\n        def jaccard(a: Set, b: Set) -> float:\\n            if not a and not b:\\n                return 0.0\\n            return len(a & b) / (len(a | b) or 1)\\n\\n        def sim_runtime(a: int | None, b: int | None) -> float:\\n            if not a or not b:\\n                return 0.0\\n            return math.exp(-(abs(a-b)**2) / (2 * 30**2))\\n\\n        def sim_numeric(a: float | None, b: float | None, maxdiff: float) -> float:\\n            if a is None or b is None:\\n                return 0.0\\n            return max(0.0, 1.0 - abs(a-b)/maxdiff)\\n\\n        def sim_language(a: str | None, b: str | None) -> float:\\n            if not a or not b:\\n                return 0.0\\n            return 1.0 if a == b else 0.0\\n\\n        def metadata_similarity(seed: MovieMeta, cand: MovieMeta, weights: Dict[str,float]):\\n            comps = {\\n                \"genres\": jaccard(seed.genres, cand.genres),\\n                \"keywords\": jaccard(seed.keywords, cand.keywords),\\n                \"cast\": jaccard(seed.cast_ids, cand.cast_ids),\\n                \"director\": jaccard(seed.director_ids, cand.director_ids),\\n                \"runtime\": sim_runtime(seed.runtime, cand.runtime),\\n                \"language\": sim_language(seed.language, cand.language),\\n                \"popularity\": sim_numeric(seed.popularity, cand.popularity, 50.0),\\n                \"vote\": sim_numeric(seed.vote_average, cand.vote_average, 4.0),\\n            }\\n            return sum(weights[k]*comps[k] for k in comps), comps\\n\\n        def load_entity_embeddings(path: str):\\n            df = pd.read_csv(path)\\n            name_col = \"Unnamed: 0\" if \"Unnamed: 0\" in df.columns else df.columns[0]\\n            names = df[name_col].astype(str).tolist()\\n            vecs = df.drop(columns=[name_col]).to_numpy(float)\\n            vecs /= (np.linalg.norm(vecs, axis=1, keepdims=True)+1e-9)\\n            return {names[i].strip(): vecs[i] for i in range(len(names))}, vecs\\n\\n        def cosine(a, b):\\n            return float(np.dot(a, b)) if a is not None and b is not None else 0.0\\n\\n        def normalize_title(t: str) -> str:\\n            return re.sub(r\"\\\\s+\", \" \", (t or \"\").strip()).lower()\\n\\n        def find_embedding_for_title(table, title, year=None):\\n            if not title:\\n                return None\\n            if title in table:\\n                return table[title]\\n            norm = normalize_title(title)\\n            for k,v in table.items():\\n                if normalize_title(k) == norm:\\n                    return v\\n            if year is not None:\\n                key = f\"{title} ({year})\"\\n                if key in table:\\n                    return table[key]\\n            return None\\n\\n        i altered this file slightly to try to resolve this error:\\n        ---------------------------------------------------------------------------\\n        RuntimeError                              Traceback (most recent call last)\\n        Cell In[14], line 9\\n              6 seed_ids = list(dict.fromkeys(seed_ids))\\n              7 assert seed_ids, \"Keine Seeds gefunden.\"\\n        ----> 9 seeds_meta = [get_movie_meta(sid) for sid in seed_ids]\\n             11 emb_table,_ = load_entity_embeddings(ENTITY_EMB)\\n             12 seed_vecs=[find_embedding_for_title(emb_table, sm.title, sm.release_year) for sm in seeds_meta]\\n\\n        Cell In[13], line 63, in get_movie_meta(movie_id)\\n             62 def get_movie_meta(movie_id: int) -> MovieMeta:\\n        ---> 63     base = _api_get(f\"/movie/{movie_id}\")\\n             64     credits = _api_get(f\"/movie/{movie_id}/credits\")\\n             65     kw = _api_get(f\"/movie/{movie_id}/keywords\")\\n\\n        Cell In[13], line 32, in _api_get(path, params, retries)\\n             30         time.sleep(1.5 * (attempt + 1))\\n             31         continue\\n        ---> 32     raise RuntimeError(f\"TMDB error {r.status_code}: {r.text[:200]}\")\\n             33 raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\\n\\n        RuntimeError: TMDB error 401: {\"status_code\":7,\"status_message\":\"Invalid API key: You must be granted a valid key.\",\"success\":false}\\n\\n        unfortunately, it didnt work\"\\n\\n    \"---------------------------------------------------------------------------\\n        RuntimeError                              Traceback (most recent call last)\\n        Cell In[21], line 9\\n              6 seed_ids = list(dict.fromkeys(seed_ids))\\n              7 assert seed_ids, \"Keine Seeds gefunden.\"\\n        ----> 9 seeds_meta = [get_movie_meta(sid) for sid in seed_ids]\\n             11 emb_table,_ = load_entity_embeddings(ENTITY_EMB)\\n             12 seed_vecs=[find_embedding_for_title(emb_table, sm.title, sm.release_year) for sm in seeds_meta]\\n\\n        Cell In[19], line 68, in get_movie_meta(movie_id)\\n             67 def get_movie_meta(movie_id: int) -> MovieMeta:\\n        ---> 68     base = _api_get(f\"/movie/{movie_id}\")\\n             69     credits = _api_get(f\"/movie/{movie_id}/credits\")\\n             70     kw = _api_get(f\"/movie/{movie_id}/keywords\")\\n\\n        Cell In[19], line 36, in _api_get(path, params, retries)\\n             34         time.sleep(1.5 * (attempt + 1))\\n             35         continue\\n        ---> 36     raise RuntimeError(f\"TMDB error {r.status_code}: {r.text}\")\\n             38 raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\\n\\n        RuntimeError: TMDB error 404: {\"success\":false,\"status_code\":34,\"status_message\":\"The resource you requested could not be found.\"}\\n\\n        was tu ich mit dieser fehlermeldung?\\n\\n        das ist der aktuelle stand meines codes:\\n        import re, time, math\\n        from typing import Dict, List, Set\\n        from dataclasses import dataclass\\n        from dotenv import load_dotenv\\n\\n        import pandas as pd\\n        import numpy as np\\n        import requests\\n        import os\\n\\n        load_dotenv()\\n\\n        TMDB_API = \"https://api.themoviedb.org/3\"\\n\\n        def _api_get(path: str, params: Dict | None = None, retries: int = 3):\\n            if params is None:\\n                params = {}\\n\\n            bearer = os.getenv(\"TMDB_API_TOKEN\")  # <-- genau dein Name aus .env\\n            if not bearer:\\n                raise RuntimeError(\"TMDB_API_TOKEN ist nicht gesetzt (v4 Bearer-Token erwartet).\")\\n\\n            headers = {\\n                \"Authorization\": f\"Bearer {bearer}\",\\n                \"Content-Type\": \"application/json;charset=utf-8\",\\n            }\\n            # WICHTIG: KEIN api_key Query-Parameter bei Bearer-Auth!\\n\\n            for attempt in range(retries):\\n                r = requests.get(f\"{TMDB_API}{path}\", headers=headers, params=params, timeout=20)\\n                if r.status_code == 200:\\n                    return r.json()\\n                if r.status_code in (429, 500, 502, 503, 504):\\n                    time.sleep(1.5 * (attempt + 1))\\n                    continue\\n                raise RuntimeError(f\"TMDB error {r.status_code}: {r.text}\")\\n\\n            raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\\n\\n        def parse_tmdb_id(s: str) -> int | None:\\n            if pd.isna(s):\\n                return None\\n            s = str(s)\\n            m = re.search(r\"/movie/(\\\\d+)\", s)\\n            if m:\\n                return int(m.group(1))\\n            if s.isdigit():\\n                return int(s)\\n            m = re.search(r\"(\\\\d+)\", s)\\n            return int(m.group(1)) if m else None\\n\\n        @dataclass\\n        class MovieMeta:\\n            id: int\\n            title: str\\n            original_title: str | None\\n            release_year: int | None\\n            genres: Set[int]\\n            keywords: Set[int]\\n            cast_ids: Set[int]\\n            director_ids: Set[int]\\n            runtime: int | None\\n            language: str | None\\n            popularity: float | None\\n            vote_average: float | None\\n\\n        def get_movie_meta(movie_id: int) -> MovieMeta:\\n            base = _api_get(f\"/movie/{movie_id}\")\\n            credits = _api_get(f\"/movie/{movie_id}/credits\")\\n            kw = _api_get(f\"/movie/{movie_id}/keywords\")\\n            genres = {g[\"id\"] for g in (base.get(\"genres\") or [])}\\n            keywords = {k[\"id\"] for k in (kw.get(\"keywords\") or [])}\\n            cast_ids = {c[\"id\"] for c in (credits.get(\"cast\") or [])[:20]}\\n            director_ids = {c[\"id\"] for c in (credits.get(\"crew\") or []) if c.get(\"job\") == \"Director\"}\\n            y = None\\n            if base.get(\"release_date\"):\\n                try: y = int(base[\"release_date\"][:4])\\n                except: pass\\n            return MovieMeta(\\n                id=movie_id,\\n                title=base.get(\"title\") or str(movie_id),\\n                original_title=base.get(\"original_title\"),\\n                release_year=y,\\n                genres=genres,\\n                keywords=keywords,\\n                cast_ids=cast_ids,\\n                director_ids=director_ids,\\n                runtime=base.get(\"runtime\"),\\n                language=base.get(\"original_language\"),\\n                popularity=base.get(\"popularity\"),\\n                vote_average=base.get(\"vote_average\"),\\n            )\\n\\n        def gather_candidates(seed_ids: List[int], pages_per_seed: int=2) -> Set[int]:\\n            cands: Set[int] = set()\\n            for sid in seed_ids:\\n                for p in range(1, pages_per_seed+1):\\n                    data = _api_get(f\"/movie/{sid}/similar\", params={\"page\": p})\\n                    for m in data.get(\"results\", []):\\n                        if m.get(\"id\"):\\n                            cands.add(m[\"id\"])\\n            return cands - set(seed_ids)\\n\\n        def jaccard(a: Set, b: Set) -> float:\\n            if not a and not b:\\n                return 0.0\\n            return len(a & b) / (len(a | b) or 1)\\n\\n        def sim_runtime(a: int | None, b: int | None) -> float:\\n            if not a or not b:\\n                return 0.0\\n            return math.exp(-(abs(a-b)**2) / (2 * 30**2))\\n\\n        def sim_numeric(a: float | None, b: float | None, maxdiff: float) -> float:\\n            if a is None or b is None:\\n                return 0.0\\n            return max(0.0, 1.0 - abs(a-b)/maxdiff)\\n\\n        def sim_language(a: str | None, b: str | None) -> float:\\n            if not a or not b:\\n                return 0.0\\n            return 1.0 if a == b else 0.0\\n\\n        def metadata_similarity(seed: MovieMeta, cand: MovieMeta, weights: Dict[str,float]):\\n            comps = {\\n                \"genres\": jaccard(seed.genres, cand.genres),\\n                \"keywords\": jaccard(seed.keywords, cand.keywords),\\n                \"cast\": jaccard(seed.cast_ids, cand.cast_ids),\\n                \"director\": jaccard(seed.director_ids, cand.director_ids),\\n                \"runtime\": sim_runtime(seed.runtime, cand.runtime),\\n                \"language\": sim_language(seed.language, cand.language),\\n                \"popularity\": sim_numeric(seed.popularity, cand.popularity, 50.0),\\n                \"vote\": sim_numeric(seed.vote_average, cand.vote_average, 4.0),\\n            }\\n            return sum(weights[k]*comps[k] for k in comps), comps\\n\\n        def load_entity_embeddings(path: str):\\n            df = pd.read_csv(path)\\n            name_col = \"Unnamed: 0\" if \"Unnamed: 0\" in df.columns else df.columns[0]\\n            names = df[name_col].astype(str).tolist()\\n            vecs = df.drop(columns=[name_col]).to_numpy(float)\\n            vecs /= (np.linalg.norm(vecs, axis=1, keepdims=True)+1e-9)\\n            return {names[i].strip(): vecs[i] for i in range(len(names))}, vecs\\n\\n        def cosine(a, b):\\n            return float(np.dot(a, b)) if a is not None and b is not None else 0.0\\n\\n        def normalize_title(t: str) -> str:\\n            return re.sub(r\"\\\\s+\", \" \", (t or \"\").strip()).lower()\\n\\n        def find_embedding_for_title(table, title, year=None):\\n            if not title:\\n                return None\\n            if title in table:\\n                return table[title]\\n            norm = normalize_title(title)\\n            for k,v in table.items():\\n                if normalize_title(k) == norm:\\n                    return v\\n            if year is not None:\\n                key = f\"{title} ({year})\"\\n                if key in table:\\n                    return table[key]\\n            return None\"\\n\\n    \"ich möchte folgende änderungen: für alle serien in tmdb_url soll einfach gar kein tmdb endpoint abgefragt werden\"\\n\\n    \"---------------------------------------------------------------------------\\n        ValueError                                Traceback (most recent call last)\\n        Cell In[7], line 30\\n             28 seed_vecs = []\\n             29 for sm in seeds_meta:\\n        ---> 30     v = (find_embedding_for_title(emb_table, sm.title, sm.release_year) or\\n             31          find_embedding_for_title(emb_table, sm.original_title, sm.release_year))\\n             32     if v is not None:\\n             33         seed_vecs.append(v)\\n\\n        ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\"\\n\\n    \"Movie-Seeds: 693\\n        Kandidaten-Pool (Movies): 6200\\n\\n        wie kommt diese hohe anzahl an Kandiaten zustande? der code lief fast 2h lang\"\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
