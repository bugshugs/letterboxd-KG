{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMDB Similar Movies (nur Filme) ➜ Re-Ranking mit KG-Embedding\n",
    "\n",
    "Dieses Notebook:\n",
    "1. liest **nur Movie-Seeds** (alle `/tv/…` werden ignoriert) aus `data/enriched_merged.csv`,\n",
    "2. holt **ähnliche Filme** über TMDB `/movie/{id}/similar`,\n",
    "3. berechnet **Metadaten-Ähnlichkeit** und **Cosine mit deinem KG-Embedding**,\n",
    "4. kombiniert beides zu einem finalen Score und zeigt **Top-K**.\n",
    "\n",
    "> Voraussetzungen:\n",
    "> - `TMDB_API_TOKEN` (v4 Bearer) als Umgebungsvariable (oder in `.env`),\n",
    "> - `data/kg/embeddings/entity_embeddings.csv` vorhanden,\n",
    "> - Python: `pandas`, `numpy`, `requests`."
   ],
   "id": "845adaa062b4a917"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ],
   "id": "bc6c828882c5fe52"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T21:21:21.379956Z",
     "start_time": "2025-09-02T21:21:21.377585Z"
    }
   },
   "source": [
    "# Optional: Falls nötig, lokal installieren\n",
    "# %pip install pandas numpy requests python-dotenv"
   ],
   "id": "a87aa352633e9c71",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T21:21:23.401863Z",
     "start_time": "2025-09-02T21:21:23.082670Z"
    }
   },
   "source": [
    "import os, re, time, math\n",
    "from typing import Dict, List, Set\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json, pathlib\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "assert os.getenv(\"TMDB_API_TOKEN\"), \"Bitte TMDB_API_TOKEN (v4 Bearer) als Umgebungsvariable oder in .env setzen!\""
   ],
   "id": "c300c997ed026ce0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pfade & Parameter"
   ],
   "id": "66d3a8be6c78f8de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T21:21:25.147497Z",
     "start_time": "2025-09-02T21:21:25.144288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_DIR = \"..\"\n",
    "CACHE_DIR = pathlib.Path(\"../.tmdb_cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Pfade\n",
    "ENRICHED_CSV = f\"{PROJECT_DIR}/data/enriched_merged.csv\"\n",
    "ENTITY_EMB   = f\"{PROJECT_DIR}/data/kg/embeddings/entity_embeddings.csv\"\n",
    "\n",
    "# Recommender-Parameter\n",
    "TOPK   = 5          # Anzahl Empfehlungen\n",
    "PAGES  = 1          # Anzahl Seiten von TMDB /similar je Seed (20 Einträge/Seite)\n",
    "ALPHA  = 0.6        # Mischung: alpha * Cosine + (1-alpha) * Metadaten\n",
    "WEIGHTS = {\n",
    "    \"genres\": 0.25, \"keywords\": 0.20,\n",
    "    \"cast\": 0.20, \"director\": 0.15,\n",
    "    \"runtime\": 0.05, \"language\": 0.05,\n",
    "    \"popularity\": 0.05, \"vote\": 0.05,\n",
    "}\n",
    "\n",
    "# Optional: explizite Seeds (nur Movies). Beispiel: [603, 238]\n",
    "EXPLICIT_SEED_MOVIE_IDS = None"
   ],
   "id": "6620418d6c7dde39",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) TMDB-API, Parser & Helper (nur Movie!)"
   ],
   "id": "8adfc2638e467e9a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T21:21:27.613434Z",
     "start_time": "2025-09-02T21:21:27.601716Z"
    }
   },
   "source": [
    "TMDB_API = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "def _cache_get(key: str):\n",
    "    p = CACHE_DIR / (re.sub(r'[^a-zA-Z0-9_.-]+','_', key) + \".json\")\n",
    "    if p.exists():\n",
    "        try:\n",
    "            return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "        except:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def _cache_set(key: str, data: dict):\n",
    "    p = CACHE_DIR / (re.sub(r'[^a-zA-Z0-9_.-]+','_', key) + \".json\")\n",
    "    p.write_text(json.dumps(data), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def _api_get(path: str, params: Dict | None = None, retries: int = 3):\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    bearer = os.getenv(\"TMDB_API_TOKEN\")\n",
    "    headers = {\"Authorization\": f\"Bearer {bearer}\", \"Content-Type\": \"application/json;charset=utf-8\"}\n",
    "\n",
    "    # Cache-Key bauen\n",
    "    key = path + \"?\" + \"&\".join(f\"{k}={v}\" for k,v in sorted(params.items()))\n",
    "    hit = _cache_get(key)\n",
    "    if hit is not None:\n",
    "        return hit\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        r = requests.get(f\"{TMDB_API}{path}\", headers=headers, params=params, timeout=20)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            _cache_set(key, data)\n",
    "            return data\n",
    "        if r.status_code in (429, 500, 502, 503, 504):\n",
    "            time.sleep(1.5 * (attempt + 1))\n",
    "            continue\n",
    "        raise RuntimeError(f\"TMDB error {r.status_code}: {r.text}\")\n",
    "    raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "def parse_tmdb_ref_movies_only(s: str):\n",
    "    \"\"\"\n",
    "    Extrahiert NUR Movie-IDs: return (\"movie\", id) oder (None, None).\n",
    "    - URLs mit /tv/… werden bewusst ignoriert.\n",
    "    - Reine Zahlen werden als Movie interpretiert.\n",
    "    \"\"\"\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)):\n",
    "        return None, None\n",
    "    s = str(s)\n",
    "    m = re.search(r\"/(movie|tv)/(\\d+)\", s)\n",
    "    if m:\n",
    "        kind, sid = m.group(1), int(m.group(2))\n",
    "        if kind == \"movie\":\n",
    "            return \"movie\", sid\n",
    "        return None, None  # tv ignorieren\n",
    "    if s.isdigit():\n",
    "        return \"movie\", int(s)\n",
    "    m = re.search(r\"(\\d+)\", s)\n",
    "    return (\"movie\", int(m.group(1))) if m else (None, None)\n",
    "\n",
    "@dataclass\n",
    "class MovieMeta:\n",
    "    id: int\n",
    "    title: str\n",
    "    original_title: str | None\n",
    "    release_year: int | None\n",
    "    genres: Set[int]\n",
    "    keywords: Set[int]\n",
    "    cast_ids: Set[int]\n",
    "    director_ids: Set[int]\n",
    "    runtime: int | None\n",
    "    language: str | None\n",
    "    popularity: float | None\n",
    "    vote_average: float | None\n",
    "\n",
    "def _year_from(s: str | None) -> int | None:\n",
    "    if not s: return None\n",
    "    try: return int(s[:4])\n",
    "    except: return None\n",
    "\n",
    "def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "    base = _api_get(f\"/movie/{movie_id}\", params={\"append_to_response\": \"credits,keywords\"})\n",
    "    genres   = {g[\"id\"] for g in (base.get(\"genres\") or [])}\n",
    "    # bei append_to_response liegen die Felder direkt im base:\n",
    "    credits  = base.get(\"credits\") or {}\n",
    "    kw       = base.get(\"keywords\") or {}\n",
    "    keywords = {k[\"id\"] for k in (kw.get(\"keywords\") or [])}\n",
    "    cast_ids = {c[\"id\"] for c in (credits.get(\"cast\") or [])[:20]}\n",
    "    director_ids = {c[\"id\"] for c in (credits.get(\"crew\") or []) if c.get(\"job\") == \"Director\"}\n",
    "\n",
    "    def _year(s):\n",
    "        return int(s[:4]) if s and len(s) >= 4 else None\n",
    "\n",
    "    return MovieMeta(\n",
    "        id=movie_id,\n",
    "        title=base.get(\"title\") or str(movie_id),\n",
    "        original_title=base.get(\"original_title\"),\n",
    "        release_year=_year(base.get(\"release_date\")),\n",
    "        genres=genres,\n",
    "        keywords=keywords,\n",
    "        cast_ids=cast_ids,\n",
    "        director_ids=director_ids,\n",
    "        runtime=base.get(\"runtime\"),\n",
    "        language=base.get(\"original_language\"),\n",
    "        popularity=base.get(\"popularity\"),\n",
    "        vote_average=base.get(\"vote_average\"),\n",
    "    )\n",
    "\n",
    "def gather_candidates_movies_only(seed_movie_ids: List[int], pages_per_seed: int=1,\n",
    "                                  per_seed_limit: int=10, global_limit: int=1500) -> set[int]:\n",
    "    cands: list[int] = []\n",
    "    seen = set()\n",
    "    for sid in seed_movie_ids:\n",
    "        added_for_seed = 0\n",
    "        for p in range(1, pages_per_seed+1):\n",
    "            data = _api_get(f\"/movie/{sid}/similar\", params={\"page\": p})\n",
    "            for m in data.get(\"results\", []):\n",
    "                mid = m.get(\"id\")\n",
    "                if not mid or mid in seen:\n",
    "                    continue\n",
    "                cands.append(int(mid))\n",
    "                seen.add(int(mid))\n",
    "                added_for_seed += 1\n",
    "                if per_seed_limit and added_for_seed >= per_seed_limit:\n",
    "                    break\n",
    "            if per_seed_limit and added_for_seed >= per_seed_limit:\n",
    "                break\n",
    "        if global_limit and len(cands) >= global_limit:\n",
    "            break\n",
    "    # Seeds entfernen\n",
    "    return set(cands) - set(seed_movie_ids)"
   ],
   "id": "8c458f01bae39f2e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Similarity & Embeddings (unverändert nützlich)"
   ],
   "id": "6474056a628dca3b"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T21:21:31.090790Z",
     "start_time": "2025-09-02T21:21:31.082989Z"
    }
   },
   "source": [
    "def jaccard(a: Set, b: Set) -> float:\n",
    "    if not a and not b:\n",
    "        return 0.0\n",
    "    return len(a & b) / (len(a | b) or 1)\n",
    "\n",
    "def sim_runtime(a: int | None, b: int | None) -> float:\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    return math.exp(-(abs(a-b)**2) / (2 * 30**2))\n",
    "\n",
    "def sim_numeric(a: float | None, b: float | None, maxdiff: float) -> float:\n",
    "    if a is None or b is None:\n",
    "        return 0.0\n",
    "    return max(0.0, 1.0 - abs(a-b)/maxdiff)\n",
    "\n",
    "def sim_language(a: str | None, b: str | None) -> float:\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    return 1.0 if a == b else 0.0\n",
    "\n",
    "def metadata_similarity(seed: MovieMeta, cand: MovieMeta, weights: Dict[str,float]):\n",
    "    comps = {\n",
    "        \"genres\": jaccard(seed.genres, cand.genres),\n",
    "        \"keywords\": jaccard(seed.keywords, cand.keywords),\n",
    "        \"cast\": jaccard(seed.cast_ids, cand.cast_ids),\n",
    "        \"director\": jaccard(seed.director_ids, cand.director_ids),\n",
    "        \"runtime\": sim_runtime(seed.runtime, cand.runtime),\n",
    "        \"language\": sim_language(seed.language, cand.language),\n",
    "        \"popularity\": sim_numeric(seed.popularity, cand.popularity, 50.0),\n",
    "        \"vote\": sim_numeric(seed.vote_average, cand.vote_average, 4.0),\n",
    "    }\n",
    "    return sum(weights[k]*comps[k] for k in comps), comps\n",
    "\n",
    "def load_entity_embeddings(path: str):\n",
    "    df = pd.read_csv(path)\n",
    "    name_col = \"Unnamed: 0\" if \"Unnamed: 0\" in df.columns else df.columns[0]\n",
    "    names = df[name_col].astype(str).tolist()\n",
    "    vecs = df.drop(columns=[name_col]).to_numpy(float)\n",
    "    vecs /= (np.linalg.norm(vecs, axis=1, keepdims=True)+1e-9)\n",
    "    return {names[i].strip(): vecs[i] for i in range(len(names))}, vecs\n",
    "\n",
    "def cosine(a, b):\n",
    "    return float(np.dot(a, b)) if a is not None and b is not None else 0.0\n",
    "\n",
    "def normalize_title(t: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (t or \"\").strip()).lower()\n",
    "\n",
    "def find_embedding_for_title(table, title, year=None):\n",
    "    if not title:\n",
    "        return None\n",
    "    if title in table:\n",
    "        return table[title]\n",
    "    norm = normalize_title(title)\n",
    "    for k,v in table.items():\n",
    "        if normalize_title(k) == norm:\n",
    "            return v\n",
    "    if year is not None:\n",
    "        key = f\"{title} ({year})\"\n",
    "        if key in table:\n",
    "            return table[key]\n",
    "    return None"
   ],
   "id": "efe3813af59e5300",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Seeds laden (nur Movies), Kandidaten holen, Scoring, Top-K anzeigen & speichern"
   ],
   "id": "f2bce8a390be0181"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T21:22:05.927534Z",
     "start_time": "2025-09-02T21:21:33.819913Z"
    }
   },
   "source": [
    "# 5.1 Seeds (nur Movies)\n",
    "if EXPLICIT_SEED_MOVIE_IDS:\n",
    "    seed_movie_ids = list(dict.fromkeys([int(x) for x in EXPLICIT_SEED_MOVIE_IDS]))\n",
    "else:\n",
    "    df_enr = pd.read_csv(ENRICHED_CSV)\n",
    "    raw = df_enr.get(\"tmdb_url\", pd.Series(dtype=str)).dropna().tolist()\n",
    "    seed_movie_ids = []\n",
    "    for s in raw:\n",
    "        kind, sid = parse_tmdb_ref_movies_only(s)\n",
    "        if kind == \"movie\" and sid:\n",
    "            seed_movie_ids.append(sid)\n",
    "    seed_movie_ids = list(dict.fromkeys(seed_movie_ids))\n",
    "\n",
    "assert seed_movie_ids, \"Keine Movie-Seeds gefunden (alle /tv/ wurden ignoriert).\"\n",
    "print(f\"Movie-Seeds: {len(seed_movie_ids)}\")\n",
    "\n",
    "# 5.2 Seed-Metadaten\n",
    "seeds_meta = []\n",
    "for sid in seed_movie_ids:\n",
    "    try:\n",
    "        seeds_meta.append(get_movie_meta(sid))\n",
    "    except RuntimeError as e:\n",
    "        print(f\"WARN: Seed /movie/{sid} übersprungen: {e}\")\n",
    "assert seeds_meta, \"Alle Seeds fielen raus. Prüfe tmdb_url und TMDB_API_TOKEN.\"\n",
    "\n",
    "# 5.3 Embedding laden & User-Zentroid\n",
    "emb_table, _ = load_entity_embeddings(ENTITY_EMB)\n",
    "seed_vecs = []\n",
    "for sm in seeds_meta:\n",
    "    v = find_embedding_for_title(emb_table, sm.title, sm.release_year)\n",
    "    if v is None:\n",
    "        v = find_embedding_for_title(emb_table, sm.original_title, sm.release_year)\n",
    "    if v is not None:\n",
    "        seed_vecs.append(v)\n",
    "user_vec = None\n",
    "if seed_vecs:\n",
    "    user_vec = np.mean(np.vstack(seed_vecs), axis=0)\n",
    "    user_vec /= (np.linalg.norm(user_vec)+1e-9)\n",
    "else:\n",
    "    print(\"WARN: Keine Seed-Embeddings gefunden – Cosine fällt auf 0.\")\n",
    "\n",
    "# 5.4 Kandidaten (nur Movies)\n",
    "cand_ids = gather_candidates_movies_only(seed_movie_ids, pages_per_seed=PAGES,\n",
    "                                         per_seed_limit=10, global_limit=1500)\n",
    "print(f\"Kandidaten-Pool (Movies): {len(cand_ids)}\")\n",
    "\n",
    "# 5.5 Scoring\n",
    "rows = []\n",
    "for cid in cand_ids:\n",
    "    try:\n",
    "        cm = get_movie_meta(cid)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"WARN: skip /movie/{cid}: {e}\")\n",
    "        continue\n",
    "    best_meta = 0.0\n",
    "    best_seed_title = None\n",
    "    comps_keep = None\n",
    "    for sm in seeds_meta:\n",
    "        s, comps = metadata_similarity(sm, cm, WEIGHTS)\n",
    "        if s > best_meta:\n",
    "            best_meta = s\n",
    "            best_seed_title = sm.title\n",
    "            comps_keep = comps\n",
    "    cand_vec = find_embedding_for_title(emb_table, cm.title, cm.release_year)\n",
    "    if cand_vec is None:\n",
    "        cand_vec = find_embedding_for_title(emb_table, cm.original_title, cm.release_year)\n",
    "    cos = cosine(user_vec, cand_vec) if (user_vec is not None and cand_vec is not None) else 0.0\n",
    "    final = ALPHA * cos + (1 - ALPHA) * best_meta\n",
    "    rows.append({\n",
    "        \"candidate_id\": cid,\n",
    "        \"candidate_title\": cm.title,\n",
    "        \"year\": cm.release_year,\n",
    "        \"cos\": round(cos,4),\n",
    "        \"meta\": round(best_meta,4),\n",
    "        \"final\": round(final,4),\n",
    "        \"seed\": best_seed_title,\n",
    "        **{f\"comp_{k}\": round(comps_keep[k],4) for k in (comps_keep or {})}\n",
    "    })\n",
    "\n",
    "df_out = pd.DataFrame(rows).sort_values(\"final\", ascending=False).head(TOPK)\n",
    "df_out"
   ],
   "id": "11ddc94f6e837e5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie-Seeds: 693\n",
      "Kandidaten-Pool (Movies): 1445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     candidate_id candidate_title    year     cos    meta   final  \\\n",
       "396          1924        Superman  1978.0  0.4339  0.4685  0.4477   \n",
       "100           841            Dune  1984.0  0.3683  0.4558  0.4033   \n",
       "547         10730       King Kong  1976.0  0.3074  0.4265  0.3550   \n",
       "58         262606        Talkback  1987.0  0.3445  0.3612  0.3512   \n",
       "147           929        Godzilla  1998.0  0.1888  0.5240  0.3229   \n",
       "\n",
       "                                          seed  comp_genres  comp_keywords  \\\n",
       "396                              Black Panther         1.00         0.1304   \n",
       "100  Star Wars: Episode I - The Phantom Menace         1.00         0.0625   \n",
       "547                                  King Kong         1.00         0.0800   \n",
       "58                                    Aftersun         1.00         0.0400   \n",
       "147                     The Day After Tomorrow         0.75         0.0189   \n",
       "\n",
       "     comp_cast  comp_director  comp_runtime  comp_language  comp_popularity  \\\n",
       "396        0.0            0.0        0.9560            1.0           0.9456   \n",
       "100        0.0            0.0        0.9994            1.0           0.9569   \n",
       "547        0.0            0.0        0.6065            1.0           0.9334   \n",
       "58         0.0            0.0        0.2100            1.0           0.8545   \n",
       "147        0.0            1.0        0.8825            1.0           0.9986   \n",
       "\n",
       "     comp_vote  \n",
       "396     0.9457  \n",
       "100     0.9090  \n",
       "547     0.6692  \n",
       "58      0.0000  \n",
       "147     0.7732  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>candidate_title</th>\n",
       "      <th>year</th>\n",
       "      <th>cos</th>\n",
       "      <th>meta</th>\n",
       "      <th>final</th>\n",
       "      <th>seed</th>\n",
       "      <th>comp_genres</th>\n",
       "      <th>comp_keywords</th>\n",
       "      <th>comp_cast</th>\n",
       "      <th>comp_director</th>\n",
       "      <th>comp_runtime</th>\n",
       "      <th>comp_language</th>\n",
       "      <th>comp_popularity</th>\n",
       "      <th>comp_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1924</td>\n",
       "      <td>Superman</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>0.4339</td>\n",
       "      <td>0.4685</td>\n",
       "      <td>0.4477</td>\n",
       "      <td>Black Panther</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>0.9457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>841</td>\n",
       "      <td>Dune</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>0.3683</td>\n",
       "      <td>0.4558</td>\n",
       "      <td>0.4033</td>\n",
       "      <td>Star Wars: Episode I - The Phantom Menace</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.9090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>10730</td>\n",
       "      <td>King Kong</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>0.3074</td>\n",
       "      <td>0.4265</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>King Kong</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.6692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>262606</td>\n",
       "      <td>Talkback</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>0.3445</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.3512</td>\n",
       "      <td>Aftersun</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>929</td>\n",
       "      <td>Godzilla</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>0.5240</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>The Day After Tomorrow</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.7732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Ergebnisse speichern"
   ],
   "id": "44742ff8924ef706"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T21:25:00.948176Z",
     "start_time": "2025-09-02T21:25:00.943803Z"
    }
   },
   "source": [
    "OUT_CSV = f\"{PROJECT_DIR}/data/kg/tmdb_rerank_with_embedding_results_movies_only.csv\"\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Gespeichert: {OUT_CSV}\")"
   ],
   "id": "8b7282c2ad879ada",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gespeichert: ../data/kg/tmdb_rerank_with_embedding_results_movies_only.csv\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "The code in the previous cells is in big parts AI generated by the free and paid version of ChatGPT and was afterwards adapted by me.\n",
    "These following prompts were used:\n",
    "\n",
    "\n",
    "    \"im file kg_recommender_from_pykeen möchte ich anstelle von selbst eingegeben daten nun ähnliche filme zu den filmen in den triplen aus der tmdb datenbank laden, und für diese filme einen similarity score erstellen. danach möchte ich 5 filme mit dem besten similarity score empfehlen\"\n",
    "\n",
    "    \"import re, time, math\n",
    "        from typing import Dict, List, Set\n",
    "        from dataclasses import dataclass\n",
    "        from dotenv import load_dotenv\n",
    "\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import requests\n",
    "\n",
    "        load_dotenv()\n",
    "\n",
    "        TMDB_API_TOKEN = \"https://api.themoviedb.org/3\"\n",
    "        HEADERS = {\n",
    "            \"Authorization\": \"Bearer \" + TMDB_API_TOKEN,\n",
    "            \"Content-Type\": \"application/json;charset=utf-8\"\n",
    "        }\n",
    "\n",
    "        def _api_get(path: str, params: Dict=None, retries: int=3):\n",
    "            if params is None:\n",
    "                params = {}\n",
    "            key = os.getenv(\"TMDB_API_TOKEN\")\n",
    "            if not key:\n",
    "                raise RuntimeError(\"TMDB_API_TOKEN ist nicht gesetzt.\")\n",
    "            params = {**params, \"api_key\": key}\n",
    "            for attempt in range(retries):\n",
    "                r = requests.get(f\"{TMDB_API_TOKEN}{path}\",headers=HEADERS, params=params, timeout=20)\n",
    "                if r.status_code == 200:\n",
    "                    return r.json()\n",
    "                if r.status_code in (429, 500, 502, 503, 504):\n",
    "                    time.sleep(1.5 * (attempt + 1))\n",
    "                    continue\n",
    "                raise RuntimeError(f\"TMDB error {r.status_code}: {r.text[:200]}\")\n",
    "            raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "        def parse_tmdb_id(s: str) -> int | None:\n",
    "            if pd.isna(s):\n",
    "                return None\n",
    "            s = str(s)\n",
    "            m = re.search(r\"/movie/(\\d+)\", s)\n",
    "            if m:\n",
    "                return int(m.group(1))\n",
    "            if s.isdigit():\n",
    "                return int(s)\n",
    "            m = re.search(r\"(\\d+)\", s)\n",
    "            return int(m.group(1)) if m else None\n",
    "\n",
    "        @dataclass\n",
    "        class MovieMeta:\n",
    "            id: int\n",
    "            title: str\n",
    "            original_title: str | None\n",
    "            release_year: int | None\n",
    "            genres: Set[int]\n",
    "            keywords: Set[int]\n",
    "            cast_ids: Set[int]\n",
    "            director_ids: Set[int]\n",
    "            runtime: int | None\n",
    "            language: str | None\n",
    "            popularity: float | None\n",
    "            vote_average: float | None\n",
    "\n",
    "        def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "            base = _api_get(f\"/movie/{movie_id}\")\n",
    "            credits = _api_get(f\"/movie/{movie_id}/credits\")\n",
    "            kw = _api_get(f\"/movie/{movie_id}/keywords\")\n",
    "            genres = {g[\"id\"] for g in (base.get(\"genres\") or [])}\n",
    "            keywords = {k[\"id\"] for k in (kw.get(\"keywords\") or [])}\n",
    "            cast_ids = {c[\"id\"] for c in (credits.get(\"cast\") or [])[:20]}\n",
    "            director_ids = {c[\"id\"] for c in (credits.get(\"crew\") or []) if c.get(\"job\") == \"Director\"}\n",
    "            y = None\n",
    "            if base.get(\"release_date\"):\n",
    "                try: y = int(base[\"release_date\"][:4])\n",
    "                except: pass\n",
    "            return MovieMeta(\n",
    "                id=movie_id,\n",
    "                title=base.get(\"title\") or str(movie_id),\n",
    "                original_title=base.get(\"original_title\"),\n",
    "                release_year=y,\n",
    "                genres=genres,\n",
    "                keywords=keywords,\n",
    "                cast_ids=cast_ids,\n",
    "                director_ids=director_ids,\n",
    "                runtime=base.get(\"runtime\"),\n",
    "                language=base.get(\"original_language\"),\n",
    "                popularity=base.get(\"popularity\"),\n",
    "                vote_average=base.get(\"vote_average\"),\n",
    "            )\n",
    "\n",
    "        def gather_candidates(seed_ids: List[int], pages_per_seed: int=2) -> Set[int]:\n",
    "            cands: Set[int] = set()\n",
    "            for sid in seed_ids:\n",
    "                for p in range(1, pages_per_seed+1):\n",
    "                    data = _api_get(f\"/movie/{sid}/similar\", params={\"page\": p})\n",
    "                    for m in data.get(\"results\", []):\n",
    "                        if m.get(\"id\"):\n",
    "                            cands.add(m[\"id\"])\n",
    "            return cands - set(seed_ids)\n",
    "\n",
    "        def jaccard(a: Set, b: Set) -> float:\n",
    "            if not a and not b:\n",
    "                return 0.0\n",
    "            return len(a & b) / (len(a | b) or 1)\n",
    "\n",
    "        def sim_runtime(a: int | None, b: int | None) -> float:\n",
    "            if not a or not b:\n",
    "                return 0.0\n",
    "            return math.exp(-(abs(a-b)**2) / (2 * 30**2))\n",
    "\n",
    "        def sim_numeric(a: float | None, b: float | None, maxdiff: float) -> float:\n",
    "            if a is None or b is None:\n",
    "                return 0.0\n",
    "            return max(0.0, 1.0 - abs(a-b)/maxdiff)\n",
    "\n",
    "        def sim_language(a: str | None, b: str | None) -> float:\n",
    "            if not a or not b:\n",
    "                return 0.0\n",
    "            return 1.0 if a == b else 0.0\n",
    "\n",
    "        def metadata_similarity(seed: MovieMeta, cand: MovieMeta, weights: Dict[str,float]):\n",
    "            comps = {\n",
    "                \"genres\": jaccard(seed.genres, cand.genres),\n",
    "                \"keywords\": jaccard(seed.keywords, cand.keywords),\n",
    "                \"cast\": jaccard(seed.cast_ids, cand.cast_ids),\n",
    "                \"director\": jaccard(seed.director_ids, cand.director_ids),\n",
    "                \"runtime\": sim_runtime(seed.runtime, cand.runtime),\n",
    "                \"language\": sim_language(seed.language, cand.language),\n",
    "                \"popularity\": sim_numeric(seed.popularity, cand.popularity, 50.0),\n",
    "                \"vote\": sim_numeric(seed.vote_average, cand.vote_average, 4.0),\n",
    "            }\n",
    "            return sum(weights[k]*comps[k] for k in comps), comps\n",
    "\n",
    "        def load_entity_embeddings(path: str):\n",
    "            df = pd.read_csv(path)\n",
    "            name_col = \"Unnamed: 0\" if \"Unnamed: 0\" in df.columns else df.columns[0]\n",
    "            names = df[name_col].astype(str).tolist()\n",
    "            vecs = df.drop(columns=[name_col]).to_numpy(float)\n",
    "            vecs /= (np.linalg.norm(vecs, axis=1, keepdims=True)+1e-9)\n",
    "            return {names[i].strip(): vecs[i] for i in range(len(names))}, vecs\n",
    "\n",
    "        def cosine(a, b):\n",
    "            return float(np.dot(a, b)) if a is not None and b is not None else 0.0\n",
    "\n",
    "        def normalize_title(t: str) -> str:\n",
    "            return re.sub(r\"\\s+\", \" \", (t or \"\").strip()).lower()\n",
    "\n",
    "        def find_embedding_for_title(table, title, year=None):\n",
    "            if not title:\n",
    "                return None\n",
    "            if title in table:\n",
    "                return table[title]\n",
    "            norm = normalize_title(title)\n",
    "            for k,v in table.items():\n",
    "                if normalize_title(k) == norm:\n",
    "                    return v\n",
    "            if year is not None:\n",
    "                key = f\"{title} ({year})\"\n",
    "                if key in table:\n",
    "                    return table[key]\n",
    "            return None\n",
    "\n",
    "        i altered this file slightly to try to resolve this error:\n",
    "        ---------------------------------------------------------------------------\n",
    "        RuntimeError                              Traceback (most recent call last)\n",
    "        Cell In[14], line 9\n",
    "              6 seed_ids = list(dict.fromkeys(seed_ids))\n",
    "              7 assert seed_ids, \"Keine Seeds gefunden.\"\n",
    "        ----> 9 seeds_meta = [get_movie_meta(sid) for sid in seed_ids]\n",
    "             11 emb_table,_ = load_entity_embeddings(ENTITY_EMB)\n",
    "             12 seed_vecs=[find_embedding_for_title(emb_table, sm.title, sm.release_year) for sm in seeds_meta]\n",
    "\n",
    "        Cell In[13], line 63, in get_movie_meta(movie_id)\n",
    "             62 def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "        ---> 63     base = _api_get(f\"/movie/{movie_id}\")\n",
    "             64     credits = _api_get(f\"/movie/{movie_id}/credits\")\n",
    "             65     kw = _api_get(f\"/movie/{movie_id}/keywords\")\n",
    "\n",
    "        Cell In[13], line 32, in _api_get(path, params, retries)\n",
    "             30         time.sleep(1.5 * (attempt + 1))\n",
    "             31         continue\n",
    "        ---> 32     raise RuntimeError(f\"TMDB error {r.status_code}: {r.text[:200]}\")\n",
    "             33 raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "        RuntimeError: TMDB error 401: {\"status_code\":7,\"status_message\":\"Invalid API key: You must be granted a valid key.\",\"success\":false}\n",
    "\n",
    "        unfortunately, it didnt work\"\n",
    "\n",
    "    \"---------------------------------------------------------------------------\n",
    "        RuntimeError                              Traceback (most recent call last)\n",
    "        Cell In[21], line 9\n",
    "              6 seed_ids = list(dict.fromkeys(seed_ids))\n",
    "              7 assert seed_ids, \"Keine Seeds gefunden.\"\n",
    "        ----> 9 seeds_meta = [get_movie_meta(sid) for sid in seed_ids]\n",
    "             11 emb_table,_ = load_entity_embeddings(ENTITY_EMB)\n",
    "             12 seed_vecs=[find_embedding_for_title(emb_table, sm.title, sm.release_year) for sm in seeds_meta]\n",
    "\n",
    "        Cell In[19], line 68, in get_movie_meta(movie_id)\n",
    "             67 def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "        ---> 68     base = _api_get(f\"/movie/{movie_id}\")\n",
    "             69     credits = _api_get(f\"/movie/{movie_id}/credits\")\n",
    "             70     kw = _api_get(f\"/movie/{movie_id}/keywords\")\n",
    "\n",
    "        Cell In[19], line 36, in _api_get(path, params, retries)\n",
    "             34         time.sleep(1.5 * (attempt + 1))\n",
    "             35         continue\n",
    "        ---> 36     raise RuntimeError(f\"TMDB error {r.status_code}: {r.text}\")\n",
    "             38 raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "        RuntimeError: TMDB error 404: {\"success\":false,\"status_code\":34,\"status_message\":\"The resource you requested could not be found.\"}\n",
    "\n",
    "        was tu ich mit dieser fehlermeldung?\n",
    "\n",
    "        das ist der aktuelle stand meines codes:\n",
    "        import re, time, math\n",
    "        from typing import Dict, List, Set\n",
    "        from dataclasses import dataclass\n",
    "        from dotenv import load_dotenv\n",
    "\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import requests\n",
    "        import os\n",
    "\n",
    "        load_dotenv()\n",
    "\n",
    "        TMDB_API = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "        def _api_get(path: str, params: Dict | None = None, retries: int = 3):\n",
    "            if params is None:\n",
    "                params = {}\n",
    "\n",
    "            bearer = os.getenv(\"TMDB_API_TOKEN\")  # <-- genau dein Name aus .env\n",
    "            if not bearer:\n",
    "                raise RuntimeError(\"TMDB_API_TOKEN ist nicht gesetzt (v4 Bearer-Token erwartet).\")\n",
    "\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {bearer}\",\n",
    "                \"Content-Type\": \"application/json;charset=utf-8\",\n",
    "            }\n",
    "            # WICHTIG: KEIN api_key Query-Parameter bei Bearer-Auth!\n",
    "\n",
    "            for attempt in range(retries):\n",
    "                r = requests.get(f\"{TMDB_API}{path}\", headers=headers, params=params, timeout=20)\n",
    "                if r.status_code == 200:\n",
    "                    return r.json()\n",
    "                if r.status_code in (429, 500, 502, 503, 504):\n",
    "                    time.sleep(1.5 * (attempt + 1))\n",
    "                    continue\n",
    "                raise RuntimeError(f\"TMDB error {r.status_code}: {r.text}\")\n",
    "\n",
    "            raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "        def parse_tmdb_id(s: str) -> int | None:\n",
    "            if pd.isna(s):\n",
    "                return None\n",
    "            s = str(s)\n",
    "            m = re.search(r\"/movie/(\\d+)\", s)\n",
    "            if m:\n",
    "                return int(m.group(1))\n",
    "            if s.isdigit():\n",
    "                return int(s)\n",
    "            m = re.search(r\"(\\d+)\", s)\n",
    "            return int(m.group(1)) if m else None\n",
    "\n",
    "        @dataclass\n",
    "        class MovieMeta:\n",
    "            id: int\n",
    "            title: str\n",
    "            original_title: str | None\n",
    "            release_year: int | None\n",
    "            genres: Set[int]\n",
    "            keywords: Set[int]\n",
    "            cast_ids: Set[int]\n",
    "            director_ids: Set[int]\n",
    "            runtime: int | None\n",
    "            language: str | None\n",
    "            popularity: float | None\n",
    "            vote_average: float | None\n",
    "\n",
    "        def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "            base = _api_get(f\"/movie/{movie_id}\")\n",
    "            credits = _api_get(f\"/movie/{movie_id}/credits\")\n",
    "            kw = _api_get(f\"/movie/{movie_id}/keywords\")\n",
    "            genres = {g[\"id\"] for g in (base.get(\"genres\") or [])}\n",
    "            keywords = {k[\"id\"] for k in (kw.get(\"keywords\") or [])}\n",
    "            cast_ids = {c[\"id\"] for c in (credits.get(\"cast\") or [])[:20]}\n",
    "            director_ids = {c[\"id\"] for c in (credits.get(\"crew\") or []) if c.get(\"job\") == \"Director\"}\n",
    "            y = None\n",
    "            if base.get(\"release_date\"):\n",
    "                try: y = int(base[\"release_date\"][:4])\n",
    "                except: pass\n",
    "            return MovieMeta(\n",
    "                id=movie_id,\n",
    "                title=base.get(\"title\") or str(movie_id),\n",
    "                original_title=base.get(\"original_title\"),\n",
    "                release_year=y,\n",
    "                genres=genres,\n",
    "                keywords=keywords,\n",
    "                cast_ids=cast_ids,\n",
    "                director_ids=director_ids,\n",
    "                runtime=base.get(\"runtime\"),\n",
    "                language=base.get(\"original_language\"),\n",
    "                popularity=base.get(\"popularity\"),\n",
    "                vote_average=base.get(\"vote_average\"),\n",
    "            )\n",
    "\n",
    "        def gather_candidates(seed_ids: List[int], pages_per_seed: int=2) -> Set[int]:\n",
    "            cands: Set[int] = set()\n",
    "            for sid in seed_ids:\n",
    "                for p in range(1, pages_per_seed+1):\n",
    "                    data = _api_get(f\"/movie/{sid}/similar\", params={\"page\": p})\n",
    "                    for m in data.get(\"results\", []):\n",
    "                        if m.get(\"id\"):\n",
    "                            cands.add(m[\"id\"])\n",
    "            return cands - set(seed_ids)\n",
    "\n",
    "        def jaccard(a: Set, b: Set) -> float:\n",
    "            if not a and not b:\n",
    "                return 0.0\n",
    "            return len(a & b) / (len(a | b) or 1)\n",
    "\n",
    "        def sim_runtime(a: int | None, b: int | None) -> float:\n",
    "            if not a or not b:\n",
    "                return 0.0\n",
    "            return math.exp(-(abs(a-b)**2) / (2 * 30**2))\n",
    "\n",
    "        def sim_numeric(a: float | None, b: float | None, maxdiff: float) -> float:\n",
    "            if a is None or b is None:\n",
    "                return 0.0\n",
    "            return max(0.0, 1.0 - abs(a-b)/maxdiff)\n",
    "\n",
    "        def sim_language(a: str | None, b: str | None) -> float:\n",
    "            if not a or not b:\n",
    "                return 0.0\n",
    "            return 1.0 if a == b else 0.0\n",
    "\n",
    "        def metadata_similarity(seed: MovieMeta, cand: MovieMeta, weights: Dict[str,float]):\n",
    "            comps = {\n",
    "                \"genres\": jaccard(seed.genres, cand.genres),\n",
    "                \"keywords\": jaccard(seed.keywords, cand.keywords),\n",
    "                \"cast\": jaccard(seed.cast_ids, cand.cast_ids),\n",
    "                \"director\": jaccard(seed.director_ids, cand.director_ids),\n",
    "                \"runtime\": sim_runtime(seed.runtime, cand.runtime),\n",
    "                \"language\": sim_language(seed.language, cand.language),\n",
    "                \"popularity\": sim_numeric(seed.popularity, cand.popularity, 50.0),\n",
    "                \"vote\": sim_numeric(seed.vote_average, cand.vote_average, 4.0),\n",
    "            }\n",
    "            return sum(weights[k]*comps[k] for k in comps), comps\n",
    "\n",
    "        def load_entity_embeddings(path: str):\n",
    "            df = pd.read_csv(path)\n",
    "            name_col = \"Unnamed: 0\" if \"Unnamed: 0\" in df.columns else df.columns[0]\n",
    "            names = df[name_col].astype(str).tolist()\n",
    "            vecs = df.drop(columns=[name_col]).to_numpy(float)\n",
    "            vecs /= (np.linalg.norm(vecs, axis=1, keepdims=True)+1e-9)\n",
    "            return {names[i].strip(): vecs[i] for i in range(len(names))}, vecs\n",
    "\n",
    "        def cosine(a, b):\n",
    "            return float(np.dot(a, b)) if a is not None and b is not None else 0.0\n",
    "\n",
    "        def normalize_title(t: str) -> str:\n",
    "            return re.sub(r\"\\s+\", \" \", (t or \"\").strip()).lower()\n",
    "\n",
    "        def find_embedding_for_title(table, title, year=None):\n",
    "            if not title:\n",
    "                return None\n",
    "            if title in table:\n",
    "                return table[title]\n",
    "            norm = normalize_title(title)\n",
    "            for k,v in table.items():\n",
    "                if normalize_title(k) == norm:\n",
    "                    return v\n",
    "            if year is not None:\n",
    "                key = f\"{title} ({year})\"\n",
    "                if key in table:\n",
    "                    return table[key]\n",
    "            return None\"\n",
    "\n",
    "    \"ich möchte folgende änderungen: für alle serien in tmdb_url soll einfach gar kein tmdb endpoint abgefragt werden\"\n",
    "\n",
    "    \"---------------------------------------------------------------------------\n",
    "        ValueError                                Traceback (most recent call last)\n",
    "        Cell In[7], line 30\n",
    "             28 seed_vecs = []\n",
    "             29 for sm in seeds_meta:\n",
    "        ---> 30     v = (find_embedding_for_title(emb_table, sm.title, sm.release_year) or\n",
    "             31          find_embedding_for_title(emb_table, sm.original_title, sm.release_year))\n",
    "             32     if v is not None:\n",
    "             33         seed_vecs.append(v)\n",
    "\n",
    "        ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\"\n",
    "\n",
    "    \"Movie-Seeds: 693\n",
    "        Kandidaten-Pool (Movies): 6200\n",
    "\n",
    "        wie kommt diese hohe anzahl an Kandiaten zustande? der code lief fast 2h lang\"\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ],
   "id": "9c4039ebe96bb33e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
