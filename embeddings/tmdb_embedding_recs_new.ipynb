{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMDB Similar Movies (nur Filme) ➜ Re-Ranking mit KG-Embedding\n",
    "\n",
    "Dieses Notebook:\n",
    "1. liest **nur Movie-Seeds** (alle `/tv/…` werden ignoriert) aus `data/enriched_merged.csv`,\n",
    "2. holt **ähnliche Filme** über TMDB `/movie/{id}/similar`,\n",
    "3. berechnet **Metadaten-Ähnlichkeit** und **Cosine mit deinem KG-Embedding**,\n",
    "4. kombiniert beides zu einem finalen Score und zeigt **Top-K**.\n",
    "\n",
    "> Voraussetzungen:\n",
    "> - `TMDB_API_TOKEN` (v4 Bearer) als Umgebungsvariable (oder in `.env`),\n",
    "> - `data/kg/embeddings/entity_embeddings.csv` vorhanden,\n",
    "> - Python: `pandas`, `numpy`, `requests`."
   ],
   "id": "845adaa062b4a917"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ],
   "id": "bc6c828882c5fe52"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T00:08:09.264534Z",
     "start_time": "2025-09-04T00:08:09.262126Z"
    }
   },
   "source": [
    "# Optional: Falls nötig, lokal installieren\n",
    "# %pip install pandas numpy requests python-dotenv"
   ],
   "id": "a87aa352633e9c71",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T00:08:13.509153Z",
     "start_time": "2025-09-04T00:08:11.970270Z"
    }
   },
   "source": [
    "import os, re, time, math\n",
    "from typing import Dict, List, Set\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json, pathlib\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "assert os.getenv(\"TMDB_API_TOKEN\"), \"Bitte TMDB_API_TOKEN (v4 Bearer) als Umgebungsvariable oder in .env setzen!\""
   ],
   "id": "c300c997ed026ce0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pfade & Parameter"
   ],
   "id": "66d3a8be6c78f8de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T00:08:14.509676Z",
     "start_time": "2025-09-04T00:08:14.502181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_DIR = \"..\"\n",
    "CACHE_DIR = pathlib.Path(\"../.tmdb_cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Pfade\n",
    "ENRICHED_CSV = f\"{PROJECT_DIR}/data/enriched_merged.csv\"\n",
    "ENTITY_EMB   = f\"{PROJECT_DIR}/data/kg/embeddings/entity_embeddings.csv\"\n",
    "\n",
    "# Recommender-Parameter\n",
    "TOPK   = 15          # Anzahl Empfehlungen\n",
    "PAGES  = 1          # Anzahl Seiten von TMDB /similar je Seed (20 Einträge/Seite)\n",
    "ALPHA  = 0.6        # Mischung: alpha * Cosine + (1-alpha) * Metadaten\n",
    "WEIGHTS = {\n",
    "    \"genres\": 0.25, \"keywords\": 0.20,\n",
    "    \"cast\": 0.20, \"director\": 0.15,\n",
    "    \"runtime\": 0.05, \"language\": 0.05,\n",
    "    \"popularity\": 0.05, \"vote\": 0.05,\n",
    "}\n",
    "\n",
    "# Optional: explizite Seeds (nur Movies). Beispiel: [603, 238]\n",
    "EXPLICIT_SEED_MOVIE_IDS = None"
   ],
   "id": "6620418d6c7dde39",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) TMDB-API, Parser & Helper (nur Movie!)"
   ],
   "id": "8adfc2638e467e9a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T00:08:20.899054Z",
     "start_time": "2025-09-04T00:08:20.884977Z"
    }
   },
   "source": [
    "TMDB_API = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "def _cache_get(key: str):\n",
    "    p = CACHE_DIR / (re.sub(r'[^a-zA-Z0-9_.-]+','_', key) + \".json\")\n",
    "    if p.exists():\n",
    "        try:\n",
    "            return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "        except:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def _cache_set(key: str, data: dict):\n",
    "    p = CACHE_DIR / (re.sub(r'[^a-zA-Z0-9_.-]+','_', key) + \".json\")\n",
    "    p.write_text(json.dumps(data), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def _api_get(path: str, params: Dict | None = None, retries: int = 3):\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    bearer = os.getenv(\"TMDB_API_TOKEN\")\n",
    "    headers = {\"Authorization\": f\"Bearer {bearer}\", \"Content-Type\": \"application/json;charset=utf-8\"}\n",
    "\n",
    "    # Cache-Key bauen\n",
    "    key = path + \"?\" + \"&\".join(f\"{k}={v}\" for k,v in sorted(params.items()))\n",
    "    hit = _cache_get(key)\n",
    "    if hit is not None:\n",
    "        return hit\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        r = requests.get(f\"{TMDB_API}{path}\", headers=headers, params=params, timeout=20)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            _cache_set(key, data)\n",
    "            return data\n",
    "        if r.status_code in (429, 500, 502, 503, 504):\n",
    "            time.sleep(1.5 * (attempt + 1))\n",
    "            continue\n",
    "        raise RuntimeError(f\"TMDB error {r.status_code}: {r.text}\")\n",
    "    raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "def parse_tmdb_ref_movies_only(s: str):\n",
    "    \"\"\"\n",
    "    Extrahiert NUR Movie-IDs: return (\"movie\", id) oder (None, None).\n",
    "    - URLs mit /tv/… werden bewusst ignoriert.\n",
    "    - Reine Zahlen werden als Movie interpretiert.\n",
    "    \"\"\"\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)):\n",
    "        return None, None\n",
    "    s = str(s)\n",
    "    m = re.search(r\"/(movie|tv)/(\\d+)\", s)\n",
    "    if m:\n",
    "        kind, sid = m.group(1), int(m.group(2))\n",
    "        if kind == \"movie\":\n",
    "            return \"movie\", sid\n",
    "        return None, None  # tv ignorieren\n",
    "    if s.isdigit():\n",
    "        return \"movie\", int(s)\n",
    "    m = re.search(r\"(\\d+)\", s)\n",
    "    return (\"movie\", int(m.group(1))) if m else (None, None)\n",
    "\n",
    "@dataclass\n",
    "class MovieMeta:\n",
    "    id: int\n",
    "    title: str\n",
    "    original_title: str | None\n",
    "    release_year: int | None\n",
    "    genres: Set[int]\n",
    "    keywords: Set[int]\n",
    "    cast_ids: Set[int]\n",
    "    director_ids: Set[int]\n",
    "    runtime: int | None\n",
    "    language: str | None\n",
    "    popularity: float | None\n",
    "    vote_average: float | None\n",
    "\n",
    "def _year_from(s: str | None) -> int | None:\n",
    "    if not s: return None\n",
    "    try: return int(s[:4])\n",
    "    except: return None\n",
    "\n",
    "def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "    base = _api_get(f\"/movie/{movie_id}\", params={\"append_to_response\": \"credits,keywords\"})\n",
    "    genres   = {g[\"id\"] for g in (base.get(\"genres\") or [])}\n",
    "    # bei append_to_response liegen die Felder direkt im base:\n",
    "    credits  = base.get(\"credits\") or {}\n",
    "    kw       = base.get(\"keywords\") or {}\n",
    "    keywords = {k[\"id\"] for k in (kw.get(\"keywords\") or [])}\n",
    "    cast_ids = {c[\"id\"] for c in (credits.get(\"cast\") or [])[:20]}\n",
    "    director_ids = {c[\"id\"] for c in (credits.get(\"crew\") or []) if c.get(\"job\") == \"Director\"}\n",
    "\n",
    "    def _year(s):\n",
    "        return int(s[:4]) if s and len(s) >= 4 else None\n",
    "\n",
    "    return MovieMeta(\n",
    "        id=movie_id,\n",
    "        title=base.get(\"title\") or str(movie_id),\n",
    "        original_title=base.get(\"original_title\"),\n",
    "        release_year=_year(base.get(\"release_date\")),\n",
    "        genres=genres,\n",
    "        keywords=keywords,\n",
    "        cast_ids=cast_ids,\n",
    "        director_ids=director_ids,\n",
    "        runtime=base.get(\"runtime\"),\n",
    "        language=base.get(\"original_language\"),\n",
    "        popularity=base.get(\"popularity\"),\n",
    "        vote_average=base.get(\"vote_average\"),\n",
    "    )\n",
    "\n",
    "def gather_candidates_movies_only(seed_movie_ids: List[int], pages_per_seed: int=1,\n",
    "                                  per_seed_limit: int=10, global_limit: int=1500) -> set[int]:\n",
    "    cands: list[int] = []\n",
    "    seen = set()\n",
    "    for sid in seed_movie_ids:\n",
    "        added_for_seed = 0\n",
    "        for p in range(1, pages_per_seed+1):\n",
    "            data = _api_get(f\"/movie/{sid}/similar\", params={\"page\": p})\n",
    "            for m in data.get(\"results\", []):\n",
    "                mid = m.get(\"id\")\n",
    "                if not mid or mid in seen:\n",
    "                    continue\n",
    "                cands.append(int(mid))\n",
    "                seen.add(int(mid))\n",
    "                added_for_seed += 1\n",
    "                if per_seed_limit and added_for_seed >= per_seed_limit:\n",
    "                    break\n",
    "            if per_seed_limit and added_for_seed >= per_seed_limit:\n",
    "                break\n",
    "        if global_limit and len(cands) >= global_limit:\n",
    "            break\n",
    "    # Seeds entfernen\n",
    "    return set(cands) - set(seed_movie_ids)"
   ],
   "id": "8c458f01bae39f2e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Similarity & Embeddings (unverändert nützlich)"
   ],
   "id": "6474056a628dca3b"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T00:08:26.083743Z",
     "start_time": "2025-09-04T00:08:26.072049Z"
    }
   },
   "source": [
    "def jaccard(a: Set, b: Set) -> float:\n",
    "    if not a and not b:\n",
    "        return 0.0\n",
    "    return len(a & b) / (len(a | b) or 1)\n",
    "\n",
    "def sim_runtime(a: int | None, b: int | None) -> float:\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    return math.exp(-(abs(a-b)**2) / (2 * 30**2))\n",
    "\n",
    "def sim_numeric(a: float | None, b: float | None, maxdiff: float) -> float:\n",
    "    if a is None or b is None:\n",
    "        return 0.0\n",
    "    return max(0.0, 1.0 - abs(a-b)/maxdiff)\n",
    "\n",
    "def sim_language(a: str | None, b: str | None) -> float:\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    return 1.0 if a == b else 0.0\n",
    "\n",
    "def metadata_similarity(seed: MovieMeta, cand: MovieMeta, weights: Dict[str,float]):\n",
    "    comps = {\n",
    "        \"genres\": jaccard(seed.genres, cand.genres),\n",
    "        \"keywords\": jaccard(seed.keywords, cand.keywords),\n",
    "        \"cast\": jaccard(seed.cast_ids, cand.cast_ids),\n",
    "        \"director\": jaccard(seed.director_ids, cand.director_ids),\n",
    "        \"runtime\": sim_runtime(seed.runtime, cand.runtime),\n",
    "        \"language\": sim_language(seed.language, cand.language),\n",
    "        \"popularity\": sim_numeric(seed.popularity, cand.popularity, 50.0),\n",
    "        \"vote\": sim_numeric(seed.vote_average, cand.vote_average, 4.0),\n",
    "    }\n",
    "    return sum(weights[k]*comps[k] for k in comps), comps\n",
    "\n",
    "def load_entity_embeddings(path: str):\n",
    "    df = pd.read_csv(path)\n",
    "    name_col = \"Unnamed: 0\" if \"Unnamed: 0\" in df.columns else df.columns[0]\n",
    "    names = df[name_col].astype(str).tolist()\n",
    "    vecs = df.drop(columns=[name_col]).to_numpy(float)\n",
    "    vecs /= (np.linalg.norm(vecs, axis=1, keepdims=True)+1e-9)\n",
    "    return {names[i].strip(): vecs[i] for i in range(len(names))}, vecs\n",
    "\n",
    "def cosine(a, b):\n",
    "    return float(np.dot(a, b)) if a is not None and b is not None else 0.0\n",
    "\n",
    "def normalize_title(t: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (t or \"\").strip()).lower()\n",
    "\n",
    "def find_embedding_for_title(table, title, year=None):\n",
    "    if not title:\n",
    "        return None\n",
    "    if title in table:\n",
    "        return table[title]\n",
    "    norm = normalize_title(title)\n",
    "    for k,v in table.items():\n",
    "        if normalize_title(k) == norm:\n",
    "            return v\n",
    "    if year is not None:\n",
    "        key = f\"{title} ({year})\"\n",
    "        if key in table:\n",
    "            return table[key]\n",
    "    return None"
   ],
   "id": "efe3813af59e5300",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Seeds laden (nur Movies), Kandidaten holen, Scoring, Top-K anzeigen & speichern"
   ],
   "id": "f2bce8a390be0181"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T00:16:41.503810Z",
     "start_time": "2025-09-04T00:08:29.141669Z"
    }
   },
   "source": [
    "# 5.1 Seeds (nur Movies)\n",
    "if EXPLICIT_SEED_MOVIE_IDS:\n",
    "    seed_movie_ids = list(dict.fromkeys([int(x) for x in EXPLICIT_SEED_MOVIE_IDS]))\n",
    "else:\n",
    "    df_enr = pd.read_csv(ENRICHED_CSV)\n",
    "    raw = df_enr.get(\"tmdb_url\", pd.Series(dtype=str)).dropna().tolist()\n",
    "    seed_movie_ids = []\n",
    "    for s in raw:\n",
    "        kind, sid = parse_tmdb_ref_movies_only(s)\n",
    "        if kind == \"movie\" and sid:\n",
    "            seed_movie_ids.append(sid)\n",
    "    seed_movie_ids = list(dict.fromkeys(seed_movie_ids))\n",
    "\n",
    "assert seed_movie_ids, \"Keine Movie-Seeds gefunden (alle /tv/ wurden ignoriert).\"\n",
    "print(f\"Movie-Seeds: {len(seed_movie_ids)}\")\n",
    "\n",
    "# 5.2 Seed-Metadaten\n",
    "seeds_meta = []\n",
    "for sid in seed_movie_ids:\n",
    "    try:\n",
    "        seeds_meta.append(get_movie_meta(sid))\n",
    "    except RuntimeError as e:\n",
    "        print(f\"WARN: Seed /movie/{sid} übersprungen: {e}\")\n",
    "assert seeds_meta, \"Alle Seeds fielen raus. Prüfe tmdb_url und TMDB_API_TOKEN.\"\n",
    "\n",
    "# 5.3 Embedding laden & User-Zentroid\n",
    "emb_table, _ = load_entity_embeddings(ENTITY_EMB)\n",
    "seed_vecs = []\n",
    "for sm in seeds_meta:\n",
    "    v = find_embedding_for_title(emb_table, sm.title, sm.release_year)\n",
    "    if v is None:\n",
    "        v = find_embedding_for_title(emb_table, sm.original_title, sm.release_year)\n",
    "    if v is not None:\n",
    "        seed_vecs.append(v)\n",
    "user_vec = None\n",
    "if seed_vecs:\n",
    "    user_vec = np.mean(np.vstack(seed_vecs), axis=0)\n",
    "    user_vec /= (np.linalg.norm(user_vec)+1e-9)\n",
    "else:\n",
    "    print(\"WARN: Keine Seed-Embeddings gefunden – Cosine fällt auf 0.\")\n",
    "\n",
    "# 5.4 Kandidaten (nur Movies)\n",
    "cand_ids = gather_candidates_movies_only(seed_movie_ids, pages_per_seed=PAGES,\n",
    "                                         per_seed_limit=10, global_limit=1500)\n",
    "print(f\"Kandidaten-Pool (Movies): {len(cand_ids)}\")\n",
    "\n",
    "# 5.5 Scoring\n",
    "rows = []\n",
    "for cid in cand_ids:\n",
    "    try:\n",
    "        cm = get_movie_meta(cid)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"WARN: skip /movie/{cid}: {e}\")\n",
    "        continue\n",
    "    best_meta = 0.0\n",
    "    best_seed_title = None\n",
    "    comps_keep = None\n",
    "    for sm in seeds_meta:\n",
    "        s, comps = metadata_similarity(sm, cm, WEIGHTS)\n",
    "        if s > best_meta:\n",
    "            best_meta = s\n",
    "            best_seed_title = sm.title\n",
    "            comps_keep = comps\n",
    "    cand_vec = find_embedding_for_title(emb_table, cm.title, cm.release_year)\n",
    "    if cand_vec is None:\n",
    "        cand_vec = find_embedding_for_title(emb_table, cm.original_title, cm.release_year)\n",
    "    cos = cosine(user_vec, cand_vec) if (user_vec is not None and cand_vec is not None) else 0.0\n",
    "    final = ALPHA * cos + (1 - ALPHA) * best_meta\n",
    "    rows.append({\n",
    "        \"candidate_id\": cid,\n",
    "        \"candidate_title\": cm.title,\n",
    "        \"year\": cm.release_year,\n",
    "        \"cos\": round(cos,4),\n",
    "        \"meta\": round(best_meta,4),\n",
    "        \"final\": round(final,4),\n",
    "        \"seed\": best_seed_title,\n",
    "        **{f\"comp_{k}\": round(comps_keep[k],4) for k in (comps_keep or {})}\n",
    "    })\n",
    "\n",
    "df_out = pd.DataFrame(rows).sort_values(\"final\", ascending=False).head(TOPK)\n",
    "df_out"
   ],
   "id": "11ddc94f6e837e5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie-Seeds: 693\n",
      "Kandidaten-Pool (Movies): 1467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      candidate_id                             candidate_title    year  \\\n",
       "488           1924                                    Superman  1978.0   \n",
       "343           1498                Teenage Mutant Ninja Turtles  1990.0   \n",
       "1120         11868                                     Dracula  1958.0   \n",
       "1101         11797                                Fright Night  1985.0   \n",
       "1460        262097                                        Trio  1997.0   \n",
       "918          11122                                       India  1993.0   \n",
       "807          10889                                      Gloria  1980.0   \n",
       "776           2661                                      Batman  1966.0   \n",
       "1397       1227770               Taylor Tomlinson: Have It All  2024.0   \n",
       "1452        671652       Taylor Tomlinson: Quarter-Life Crisis  2020.0   \n",
       "1309         13643             George Carlin: It's Bad for Ya!  2008.0   \n",
       "682         444706  Dave Chappelle: Deep in the Heart of Texas  2017.0   \n",
       "1345        620778                  Jim Gaffigan: Quality Time  2019.0   \n",
       "1005        806045          James Acaster: Make a New Tomorrow  2021.0   \n",
       "425          26280                          I Killed My Mother  2009.0   \n",
       "\n",
       "         cos    meta   final                            seed  comp_genres  \\\n",
       "488   0.4339  0.4698  0.4483                   Black Panther          1.0   \n",
       "343   0.3336  0.4414  0.3767    Teenage Mutant Ninja Turtles          0.8   \n",
       "1120  0.3113  0.4735  0.3762                         Dracula          1.0   \n",
       "1101  0.2880  0.4600  0.3568                    Fright Night          1.0   \n",
       "1460  0.3501  0.3630  0.3553               Seven Psychopaths          1.0   \n",
       "918   0.2222  0.4412  0.3098                    Summer Storm          1.0   \n",
       "807   0.1594  0.4452  0.2737                       Good Time          1.0   \n",
       "776   0.1428  0.4507  0.2660                  21 Jump Street          1.0   \n",
       "1397  0.0000  0.6468  0.2587          Hannah Gadsby: Douglas          1.0   \n",
       "1452  0.0000  0.6461  0.2584          Hannah Gadsby: Douglas          1.0   \n",
       "1309  0.0000  0.6460  0.2584               Bo Burnham: What.          1.0   \n",
       "682   0.0000  0.6449  0.2580               Bo Burnham: What.          1.0   \n",
       "1345  0.0000  0.6406  0.2562          Hannah Gadsby: Douglas          1.0   \n",
       "1005  0.0000  0.6330  0.2532               Bo Burnham: What.          1.0   \n",
       "425   0.0000  0.6267  0.2507  It's Only the End of the World          1.0   \n",
       "\n",
       "      comp_keywords  comp_cast  comp_director  comp_runtime  comp_language  \\\n",
       "488          0.1304     0.0000            0.0        0.9560            1.0   \n",
       "343          0.3182     0.0000            0.0        0.9651            1.0   \n",
       "1120         0.1364     0.0000            0.0        0.9651            1.0   \n",
       "1101         0.0769     0.0278            0.0        0.9994            1.0   \n",
       "1460         0.0000     0.0000            0.0        0.9731            0.0   \n",
       "918          0.0370     0.0000            0.0        0.9651            1.0   \n",
       "807          0.0526     0.0000            0.0        0.7827            1.0   \n",
       "776          0.0606     0.0000            0.0        0.9912            1.0   \n",
       "1397         1.0000     0.0000            0.0        0.9802            1.0   \n",
       "1452         1.0000     0.0000            0.0        0.9350            1.0   \n",
       "1309         1.0000     0.0000            0.0        0.9460            1.0   \n",
       "682          1.0000     0.0000            0.0        0.9802            1.0   \n",
       "1345         1.0000     0.0000            0.0        0.9950            1.0   \n",
       "1005         1.0000     0.0000            0.0        0.8007            1.0   \n",
       "425          0.1200     0.0312            1.0        0.9950            1.0   \n",
       "\n",
       "      comp_popularity  comp_vote  \n",
       "488            0.9719     0.9457  \n",
       "343            0.7857     0.8055  \n",
       "1120           0.9900     0.9695  \n",
       "1101           0.9916     0.7908  \n",
       "1460           0.9183     0.3692  \n",
       "918            0.9614     0.7500  \n",
       "807            0.9956     0.9152  \n",
       "776            0.8997     0.8805  \n",
       "1397           0.9857     0.9695  \n",
       "1452           0.9966     0.9895  \n",
       "1309           0.9859     0.9890  \n",
       "682            0.9755     0.9427  \n",
       "1345           0.9545     0.8625  \n",
       "1005           0.9805     0.8798  \n",
       "425            0.9978     0.9367  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>candidate_title</th>\n",
       "      <th>year</th>\n",
       "      <th>cos</th>\n",
       "      <th>meta</th>\n",
       "      <th>final</th>\n",
       "      <th>seed</th>\n",
       "      <th>comp_genres</th>\n",
       "      <th>comp_keywords</th>\n",
       "      <th>comp_cast</th>\n",
       "      <th>comp_director</th>\n",
       "      <th>comp_runtime</th>\n",
       "      <th>comp_language</th>\n",
       "      <th>comp_popularity</th>\n",
       "      <th>comp_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1924</td>\n",
       "      <td>Superman</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>0.4339</td>\n",
       "      <td>0.4698</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>Black Panther</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>1498</td>\n",
       "      <td>Teenage Mutant Ninja Turtles</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>0.3336</td>\n",
       "      <td>0.4414</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>Teenage Mutant Ninja Turtles</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.8055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>11868</td>\n",
       "      <td>Dracula</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.3113</td>\n",
       "      <td>0.4735</td>\n",
       "      <td>0.3762</td>\n",
       "      <td>Dracula</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>11797</td>\n",
       "      <td>Fright Night</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>0.2880</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.3568</td>\n",
       "      <td>Fright Night</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.7908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>262097</td>\n",
       "      <td>Trio</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.3501</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.3553</td>\n",
       "      <td>Seven Psychopaths</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>0.3692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>11122</td>\n",
       "      <td>India</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.4412</td>\n",
       "      <td>0.3098</td>\n",
       "      <td>Summer Storm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>10889</td>\n",
       "      <td>Gloria</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>0.1594</td>\n",
       "      <td>0.4452</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>Good Time</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7827</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.9152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>2661</td>\n",
       "      <td>Batman</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.4507</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>21 Jump Street</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.8805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1227770</td>\n",
       "      <td>Taylor Tomlinson: Have It All</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>Hannah Gadsby: Douglas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>0.9695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>671652</td>\n",
       "      <td>Taylor Tomlinson: Quarter-Life Crisis</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6461</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>Hannah Gadsby: Douglas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.9895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>13643</td>\n",
       "      <td>George Carlin: It's Bad for Ya!</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>Bo Burnham: What.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>0.9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>444706</td>\n",
       "      <td>Dave Chappelle: Deep in the Heart of Texas</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6449</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>Bo Burnham: What.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.9427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>620778</td>\n",
       "      <td>Jim Gaffigan: Quality Time</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6406</td>\n",
       "      <td>0.2562</td>\n",
       "      <td>Hannah Gadsby: Douglas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.8625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>806045</td>\n",
       "      <td>James Acaster: Make a New Tomorrow</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.2532</td>\n",
       "      <td>Bo Burnham: What.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.8798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>26280</td>\n",
       "      <td>I Killed My Mother</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6267</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>It's Only the End of the World</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.9367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Ergebnisse speichern"
   ],
   "id": "44742ff8924ef706"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T00:19:41.223463Z",
     "start_time": "2025-09-04T00:19:41.185346Z"
    }
   },
   "source": [
    "OUT_CSV = f\"{PROJECT_DIR}/data/kg/tmdb_rerank_with_embedding_results_movies_only.csv\"\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Gespeichert: {OUT_CSV}\")"
   ],
   "id": "8b7282c2ad879ada",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gespeichert: ../data/kg/tmdb_rerank_with_embedding_results_movies_only.csv\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "The code in the previous cells is in big parts AI generated by the free and paid version of ChatGPT and was afterwards adapted by me.\n",
    "These following prompts were used:\n",
    "\n",
    "\n",
    "    \"im file kg_recommender_from_pykeen möchte ich anstelle von selbst eingegeben daten nun ähnliche filme zu den filmen in den triplen aus der tmdb datenbank laden, und für diese filme einen similarity score erstellen. danach möchte ich 5 filme mit dem besten similarity score empfehlen\"\n",
    "\n",
    "    \"import re, time, math\n",
    "        from typing import Dict, List, Set\n",
    "        from dataclasses import dataclass\n",
    "        from dotenv import load_dotenv\n",
    "\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import requests\n",
    "\n",
    "        load_dotenv()\n",
    "\n",
    "        TMDB_API_TOKEN = \"https://api.themoviedb.org/3\"\n",
    "        HEADERS = {\n",
    "            \"Authorization\": \"Bearer \" + TMDB_API_TOKEN,\n",
    "            \"Content-Type\": \"application/json;charset=utf-8\"\n",
    "        }\n",
    "\n",
    "        def _api_get(path: str, params: Dict=None, retries: int=3):\n",
    "            if params is None:\n",
    "                params = {}\n",
    "            key = os.getenv(\"TMDB_API_TOKEN\")\n",
    "            if not key:\n",
    "                raise RuntimeError(\"TMDB_API_TOKEN ist nicht gesetzt.\")\n",
    "            params = {**params, \"api_key\": key}\n",
    "            for attempt in range(retries):\n",
    "                r = requests.get(f\"{TMDB_API_TOKEN}{path}\",headers=HEADERS, params=params, timeout=20)\n",
    "                if r.status_code == 200:\n",
    "                    return r.json()\n",
    "                if r.status_code in (429, 500, 502, 503, 504):\n",
    "                    time.sleep(1.5 * (attempt + 1))\n",
    "                    continue\n",
    "                raise RuntimeError(f\"TMDB error {r.status_code}: {r.text[:200]}\")\n",
    "            raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "        def parse_tmdb_id(s: str) -> int | None:\n",
    "            if pd.isna(s):\n",
    "                return None\n",
    "            s = str(s)\n",
    "            m = re.search(r\"/movie/(\\d+)\", s)\n",
    "            if m:\n",
    "                return int(m.group(1))\n",
    "            if s.isdigit():\n",
    "                return int(s)\n",
    "            m = re.search(r\"(\\d+)\", s)\n",
    "            return int(m.group(1)) if m else None\n",
    "\n",
    "        @dataclass\n",
    "        class MovieMeta:\n",
    "            id: int\n",
    "            title: str\n",
    "            original_title: str | None\n",
    "            release_year: int | None\n",
    "            genres: Set[int]\n",
    "            keywords: Set[int]\n",
    "            cast_ids: Set[int]\n",
    "            director_ids: Set[int]\n",
    "            runtime: int | None\n",
    "            language: str | None\n",
    "            popularity: float | None\n",
    "            vote_average: float | None\n",
    "\n",
    "        def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "            base = _api_get(f\"/movie/{movie_id}\")\n",
    "            credits = _api_get(f\"/movie/{movie_id}/credits\")\n",
    "            kw = _api_get(f\"/movie/{movie_id}/keywords\")\n",
    "            genres = {g[\"id\"] for g in (base.get(\"genres\") or [])}\n",
    "            keywords = {k[\"id\"] for k in (kw.get(\"keywords\") or [])}\n",
    "            cast_ids = {c[\"id\"] for c in (credits.get(\"cast\") or [])[:20]}\n",
    "            director_ids = {c[\"id\"] for c in (credits.get(\"crew\") or []) if c.get(\"job\") == \"Director\"}\n",
    "            y = None\n",
    "            if base.get(\"release_date\"):\n",
    "                try: y = int(base[\"release_date\"][:4])\n",
    "                except: pass\n",
    "            return MovieMeta(\n",
    "                id=movie_id,\n",
    "                title=base.get(\"title\") or str(movie_id),\n",
    "                original_title=base.get(\"original_title\"),\n",
    "                release_year=y,\n",
    "                genres=genres,\n",
    "                keywords=keywords,\n",
    "                cast_ids=cast_ids,\n",
    "                director_ids=director_ids,\n",
    "                runtime=base.get(\"runtime\"),\n",
    "                language=base.get(\"original_language\"),\n",
    "                popularity=base.get(\"popularity\"),\n",
    "                vote_average=base.get(\"vote_average\"),\n",
    "            )\n",
    "\n",
    "        def gather_candidates(seed_ids: List[int], pages_per_seed: int=2) -> Set[int]:\n",
    "            cands: Set[int] = set()\n",
    "            for sid in seed_ids:\n",
    "                for p in range(1, pages_per_seed+1):\n",
    "                    data = _api_get(f\"/movie/{sid}/similar\", params={\"page\": p})\n",
    "                    for m in data.get(\"results\", []):\n",
    "                        if m.get(\"id\"):\n",
    "                            cands.add(m[\"id\"])\n",
    "            return cands - set(seed_ids)\n",
    "\n",
    "        def jaccard(a: Set, b: Set) -> float:\n",
    "            if not a and not b:\n",
    "                return 0.0\n",
    "            return len(a & b) / (len(a | b) or 1)\n",
    "\n",
    "        def sim_runtime(a: int | None, b: int | None) -> float:\n",
    "            if not a or not b:\n",
    "                return 0.0\n",
    "            return math.exp(-(abs(a-b)**2) / (2 * 30**2))\n",
    "\n",
    "        def sim_numeric(a: float | None, b: float | None, maxdiff: float) -> float:\n",
    "            if a is None or b is None:\n",
    "                return 0.0\n",
    "            return max(0.0, 1.0 - abs(a-b)/maxdiff)\n",
    "\n",
    "        def sim_language(a: str | None, b: str | None) -> float:\n",
    "            if not a or not b:\n",
    "                return 0.0\n",
    "            return 1.0 if a == b else 0.0\n",
    "\n",
    "        def metadata_similarity(seed: MovieMeta, cand: MovieMeta, weights: Dict[str,float]):\n",
    "            comps = {\n",
    "                \"genres\": jaccard(seed.genres, cand.genres),\n",
    "                \"keywords\": jaccard(seed.keywords, cand.keywords),\n",
    "                \"cast\": jaccard(seed.cast_ids, cand.cast_ids),\n",
    "                \"director\": jaccard(seed.director_ids, cand.director_ids),\n",
    "                \"runtime\": sim_runtime(seed.runtime, cand.runtime),\n",
    "                \"language\": sim_language(seed.language, cand.language),\n",
    "                \"popularity\": sim_numeric(seed.popularity, cand.popularity, 50.0),\n",
    "                \"vote\": sim_numeric(seed.vote_average, cand.vote_average, 4.0),\n",
    "            }\n",
    "            return sum(weights[k]*comps[k] for k in comps), comps\n",
    "\n",
    "        def load_entity_embeddings(path: str):\n",
    "            df = pd.read_csv(path)\n",
    "            name_col = \"Unnamed: 0\" if \"Unnamed: 0\" in df.columns else df.columns[0]\n",
    "            names = df[name_col].astype(str).tolist()\n",
    "            vecs = df.drop(columns=[name_col]).to_numpy(float)\n",
    "            vecs /= (np.linalg.norm(vecs, axis=1, keepdims=True)+1e-9)\n",
    "            return {names[i].strip(): vecs[i] for i in range(len(names))}, vecs\n",
    "\n",
    "        def cosine(a, b):\n",
    "            return float(np.dot(a, b)) if a is not None and b is not None else 0.0\n",
    "\n",
    "        def normalize_title(t: str) -> str:\n",
    "            return re.sub(r\"\\s+\", \" \", (t or \"\").strip()).lower()\n",
    "\n",
    "        def find_embedding_for_title(table, title, year=None):\n",
    "            if not title:\n",
    "                return None\n",
    "            if title in table:\n",
    "                return table[title]\n",
    "            norm = normalize_title(title)\n",
    "            for k,v in table.items():\n",
    "                if normalize_title(k) == norm:\n",
    "                    return v\n",
    "            if year is not None:\n",
    "                key = f\"{title} ({year})\"\n",
    "                if key in table:\n",
    "                    return table[key]\n",
    "            return None\n",
    "\n",
    "        i altered this file slightly to try to resolve this error:\n",
    "        ---------------------------------------------------------------------------\n",
    "        RuntimeError                              Traceback (most recent call last)\n",
    "        Cell In[14], line 9\n",
    "              6 seed_ids = list(dict.fromkeys(seed_ids))\n",
    "              7 assert seed_ids, \"Keine Seeds gefunden.\"\n",
    "        ----> 9 seeds_meta = [get_movie_meta(sid) for sid in seed_ids]\n",
    "             11 emb_table,_ = load_entity_embeddings(ENTITY_EMB)\n",
    "             12 seed_vecs=[find_embedding_for_title(emb_table, sm.title, sm.release_year) for sm in seeds_meta]\n",
    "\n",
    "        Cell In[13], line 63, in get_movie_meta(movie_id)\n",
    "             62 def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "        ---> 63     base = _api_get(f\"/movie/{movie_id}\")\n",
    "             64     credits = _api_get(f\"/movie/{movie_id}/credits\")\n",
    "             65     kw = _api_get(f\"/movie/{movie_id}/keywords\")\n",
    "\n",
    "        Cell In[13], line 32, in _api_get(path, params, retries)\n",
    "             30         time.sleep(1.5 * (attempt + 1))\n",
    "             31         continue\n",
    "        ---> 32     raise RuntimeError(f\"TMDB error {r.status_code}: {r.text[:200]}\")\n",
    "             33 raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "        RuntimeError: TMDB error 401: {\"status_code\":7,\"status_message\":\"Invalid API key: You must be granted a valid key.\",\"success\":false}\n",
    "\n",
    "        unfortunately, it didnt work\"\n",
    "\n",
    "    \"---------------------------------------------------------------------------\n",
    "        RuntimeError                              Traceback (most recent call last)\n",
    "        Cell In[21], line 9\n",
    "              6 seed_ids = list(dict.fromkeys(seed_ids))\n",
    "              7 assert seed_ids, \"Keine Seeds gefunden.\"\n",
    "        ----> 9 seeds_meta = [get_movie_meta(sid) for sid in seed_ids]\n",
    "             11 emb_table,_ = load_entity_embeddings(ENTITY_EMB)\n",
    "             12 seed_vecs=[find_embedding_for_title(emb_table, sm.title, sm.release_year) for sm in seeds_meta]\n",
    "\n",
    "        Cell In[19], line 68, in get_movie_meta(movie_id)\n",
    "             67 def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "        ---> 68     base = _api_get(f\"/movie/{movie_id}\")\n",
    "             69     credits = _api_get(f\"/movie/{movie_id}/credits\")\n",
    "             70     kw = _api_get(f\"/movie/{movie_id}/keywords\")\n",
    "\n",
    "        Cell In[19], line 36, in _api_get(path, params, retries)\n",
    "             34         time.sleep(1.5 * (attempt + 1))\n",
    "             35         continue\n",
    "        ---> 36     raise RuntimeError(f\"TMDB error {r.status_code}: {r.text}\")\n",
    "             38 raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "        RuntimeError: TMDB error 404: {\"success\":false,\"status_code\":34,\"status_message\":\"The resource you requested could not be found.\"}\n",
    "\n",
    "        was tu ich mit dieser fehlermeldung?\n",
    "\n",
    "        das ist der aktuelle stand meines codes:\n",
    "        import re, time, math\n",
    "        from typing import Dict, List, Set\n",
    "        from dataclasses import dataclass\n",
    "        from dotenv import load_dotenv\n",
    "\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import requests\n",
    "        import os\n",
    "\n",
    "        load_dotenv()\n",
    "\n",
    "        TMDB_API = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "        def _api_get(path: str, params: Dict | None = None, retries: int = 3):\n",
    "            if params is None:\n",
    "                params = {}\n",
    "\n",
    "            bearer = os.getenv(\"TMDB_API_TOKEN\")  # <-- genau dein Name aus .env\n",
    "            if not bearer:\n",
    "                raise RuntimeError(\"TMDB_API_TOKEN ist nicht gesetzt (v4 Bearer-Token erwartet).\")\n",
    "\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {bearer}\",\n",
    "                \"Content-Type\": \"application/json;charset=utf-8\",\n",
    "            }\n",
    "            # WICHTIG: KEIN api_key Query-Parameter bei Bearer-Auth!\n",
    "\n",
    "            for attempt in range(retries):\n",
    "                r = requests.get(f\"{TMDB_API}{path}\", headers=headers, params=params, timeout=20)\n",
    "                if r.status_code == 200:\n",
    "                    return r.json()\n",
    "                if r.status_code in (429, 500, 502, 503, 504):\n",
    "                    time.sleep(1.5 * (attempt + 1))\n",
    "                    continue\n",
    "                raise RuntimeError(f\"TMDB error {r.status_code}: {r.text}\")\n",
    "\n",
    "            raise RuntimeError(\"TMDB temporäre Fehler nach Retries.\")\n",
    "\n",
    "        def parse_tmdb_id(s: str) -> int | None:\n",
    "            if pd.isna(s):\n",
    "                return None\n",
    "            s = str(s)\n",
    "            m = re.search(r\"/movie/(\\d+)\", s)\n",
    "            if m:\n",
    "                return int(m.group(1))\n",
    "            if s.isdigit():\n",
    "                return int(s)\n",
    "            m = re.search(r\"(\\d+)\", s)\n",
    "            return int(m.group(1)) if m else None\n",
    "\n",
    "        @dataclass\n",
    "        class MovieMeta:\n",
    "            id: int\n",
    "            title: str\n",
    "            original_title: str | None\n",
    "            release_year: int | None\n",
    "            genres: Set[int]\n",
    "            keywords: Set[int]\n",
    "            cast_ids: Set[int]\n",
    "            director_ids: Set[int]\n",
    "            runtime: int | None\n",
    "            language: str | None\n",
    "            popularity: float | None\n",
    "            vote_average: float | None\n",
    "\n",
    "        def get_movie_meta(movie_id: int) -> MovieMeta:\n",
    "            base = _api_get(f\"/movie/{movie_id}\")\n",
    "            credits = _api_get(f\"/movie/{movie_id}/credits\")\n",
    "            kw = _api_get(f\"/movie/{movie_id}/keywords\")\n",
    "            genres = {g[\"id\"] for g in (base.get(\"genres\") or [])}\n",
    "            keywords = {k[\"id\"] for k in (kw.get(\"keywords\") or [])}\n",
    "            cast_ids = {c[\"id\"] for c in (credits.get(\"cast\") or [])[:20]}\n",
    "            director_ids = {c[\"id\"] for c in (credits.get(\"crew\") or []) if c.get(\"job\") == \"Director\"}\n",
    "            y = None\n",
    "            if base.get(\"release_date\"):\n",
    "                try: y = int(base[\"release_date\"][:4])\n",
    "                except: pass\n",
    "            return MovieMeta(\n",
    "                id=movie_id,\n",
    "                title=base.get(\"title\") or str(movie_id),\n",
    "                original_title=base.get(\"original_title\"),\n",
    "                release_year=y,\n",
    "                genres=genres,\n",
    "                keywords=keywords,\n",
    "                cast_ids=cast_ids,\n",
    "                director_ids=director_ids,\n",
    "                runtime=base.get(\"runtime\"),\n",
    "                language=base.get(\"original_language\"),\n",
    "                popularity=base.get(\"popularity\"),\n",
    "                vote_average=base.get(\"vote_average\"),\n",
    "            )\n",
    "\n",
    "        def gather_candidates(seed_ids: List[int], pages_per_seed: int=2) -> Set[int]:\n",
    "            cands: Set[int] = set()\n",
    "            for sid in seed_ids:\n",
    "                for p in range(1, pages_per_seed+1):\n",
    "                    data = _api_get(f\"/movie/{sid}/similar\", params={\"page\": p})\n",
    "                    for m in data.get(\"results\", []):\n",
    "                        if m.get(\"id\"):\n",
    "                            cands.add(m[\"id\"])\n",
    "            return cands - set(seed_ids)\n",
    "\n",
    "        def jaccard(a: Set, b: Set) -> float:\n",
    "            if not a and not b:\n",
    "                return 0.0\n",
    "            return len(a & b) / (len(a | b) or 1)\n",
    "\n",
    "        def sim_runtime(a: int | None, b: int | None) -> float:\n",
    "            if not a or not b:\n",
    "                return 0.0\n",
    "            return math.exp(-(abs(a-b)**2) / (2 * 30**2))\n",
    "\n",
    "        def sim_numeric(a: float | None, b: float | None, maxdiff: float) -> float:\n",
    "            if a is None or b is None:\n",
    "                return 0.0\n",
    "            return max(0.0, 1.0 - abs(a-b)/maxdiff)\n",
    "\n",
    "        def sim_language(a: str | None, b: str | None) -> float:\n",
    "            if not a or not b:\n",
    "                return 0.0\n",
    "            return 1.0 if a == b else 0.0\n",
    "\n",
    "        def metadata_similarity(seed: MovieMeta, cand: MovieMeta, weights: Dict[str,float]):\n",
    "            comps = {\n",
    "                \"genres\": jaccard(seed.genres, cand.genres),\n",
    "                \"keywords\": jaccard(seed.keywords, cand.keywords),\n",
    "                \"cast\": jaccard(seed.cast_ids, cand.cast_ids),\n",
    "                \"director\": jaccard(seed.director_ids, cand.director_ids),\n",
    "                \"runtime\": sim_runtime(seed.runtime, cand.runtime),\n",
    "                \"language\": sim_language(seed.language, cand.language),\n",
    "                \"popularity\": sim_numeric(seed.popularity, cand.popularity, 50.0),\n",
    "                \"vote\": sim_numeric(seed.vote_average, cand.vote_average, 4.0),\n",
    "            }\n",
    "            return sum(weights[k]*comps[k] for k in comps), comps\n",
    "\n",
    "        def load_entity_embeddings(path: str):\n",
    "            df = pd.read_csv(path)\n",
    "            name_col = \"Unnamed: 0\" if \"Unnamed: 0\" in df.columns else df.columns[0]\n",
    "            names = df[name_col].astype(str).tolist()\n",
    "            vecs = df.drop(columns=[name_col]).to_numpy(float)\n",
    "            vecs /= (np.linalg.norm(vecs, axis=1, keepdims=True)+1e-9)\n",
    "            return {names[i].strip(): vecs[i] for i in range(len(names))}, vecs\n",
    "\n",
    "        def cosine(a, b):\n",
    "            return float(np.dot(a, b)) if a is not None and b is not None else 0.0\n",
    "\n",
    "        def normalize_title(t: str) -> str:\n",
    "            return re.sub(r\"\\s+\", \" \", (t or \"\").strip()).lower()\n",
    "\n",
    "        def find_embedding_for_title(table, title, year=None):\n",
    "            if not title:\n",
    "                return None\n",
    "            if title in table:\n",
    "                return table[title]\n",
    "            norm = normalize_title(title)\n",
    "            for k,v in table.items():\n",
    "                if normalize_title(k) == norm:\n",
    "                    return v\n",
    "            if year is not None:\n",
    "                key = f\"{title} ({year})\"\n",
    "                if key in table:\n",
    "                    return table[key]\n",
    "            return None\"\n",
    "\n",
    "    \"ich möchte folgende änderungen: für alle serien in tmdb_url soll einfach gar kein tmdb endpoint abgefragt werden\"\n",
    "\n",
    "    \"---------------------------------------------------------------------------\n",
    "        ValueError                                Traceback (most recent call last)\n",
    "        Cell In[7], line 30\n",
    "             28 seed_vecs = []\n",
    "             29 for sm in seeds_meta:\n",
    "        ---> 30     v = (find_embedding_for_title(emb_table, sm.title, sm.release_year) or\n",
    "             31          find_embedding_for_title(emb_table, sm.original_title, sm.release_year))\n",
    "             32     if v is not None:\n",
    "             33         seed_vecs.append(v)\n",
    "\n",
    "        ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\"\n",
    "\n",
    "    \"Movie-Seeds: 693\n",
    "        Kandidaten-Pool (Movies): 6200\n",
    "\n",
    "        wie kommt diese hohe anzahl an Kandiaten zustande? der code lief fast 2h lang\"\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ],
   "id": "9c4039ebe96bb33e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
